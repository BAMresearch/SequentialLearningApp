{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Learning App for Materials Discovery - *SLAMD*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from ipywidgets import Box,Label,Text,FloatText,BoundedFloatText,Checkbox,ToggleButtons,Dropdown,VBox,HBox,Accordion,BoundedIntText,SelectMultiple,RadioButtons,FloatRangeSlider,Button,IntSlider,Label,Tab,Output,FileUpload,Layout,FloatSlider\n",
    "from IPython.display import display,Markdown,HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance_matrix\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor as SKRFR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn import preprocessing\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tab\n",
    "tab =Tab() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs\n",
    "out=Output()\n",
    "out_plotting=Output()\n",
    "out_settings=Output()\n",
    "out_algo=Output()\n",
    "out_perform_experiment=Output()\n",
    "out_input_space=Output()\n",
    "out_res=Output()\n",
    "out_iter_aut=Output()\n",
    "out_results_SL=Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Upload\n",
    "up = FileUpload(accept=\"\", multiple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload Properties \n",
    "delim =RadioButtons(\n",
    "    options=[';', ','],\n",
    "    description='Separator: ',\n",
    "    disabled=False)\n",
    "delim_dec = RadioButtons(\n",
    "    options=[',', '.'],\n",
    "    description='Decimal delim: ',\n",
    "    disabled=False)\n",
    "\n",
    "eraser = SelectMultiple(\n",
    "    options=['tab','\"',\"%\"],\n",
    "    value=['tab'],\n",
    "    #rows=10,\n",
    "    description='Eraser: ',\n",
    "    disabled=False)\n",
    "rows = IntSlider(\n",
    "    value=0,\n",
    "    step=1,\n",
    "    description='# of lines:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Info \n",
    "toggle = ToggleButtons(\n",
    "    options=['Preview  ', 'Info  ', 'Stats  '],\n",
    "    description='Options',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    icons=['search', 'info', 'tachometer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of Targets and Features\n",
    "feature_selector=SelectMultiple(\n",
    "    options=[],\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')) \n",
    "target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "fixed_target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "selector_plot_variable=SelectMultiple(\n",
    "    options=[],\n",
    "    description='Features',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "graph_type = Dropdown(\n",
    "    options=['Choose graph type','Scatter', 'Scatter Matrix', 'Correlation Heatmap'],\n",
    "    value='Choose graph type',\n",
    "    description='Graph type:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "x_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='X-Axis:',\n",
    "    disabled=False)\n",
    "y_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False)\n",
    "\n",
    "select_x=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select X-axis',\n",
    "    description='X-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_y=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select Y-axis',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_hue=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the hue',\n",
    "    description='Hue:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_size=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the size',\n",
    "    description='Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "container_checkboxes_targets=VBox([])\n",
    "container_checkboxes_fixed_targets=VBox([])\n",
    "\n",
    "container_slider_targets=VBox([])\n",
    "container_slider_fixed_targets=VBox([])\n",
    "\n",
    "box_targets=VBox([])\n",
    "box_fixed_targets=VBox([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Learning Properties\n",
    "select_strategy=Dropdown(\n",
    "    options=['MEI (exploit)','MU (explore)','MLI (explore & exploit)','MEID (exploit)','MLID (explore & exploit)'],\n",
    "    value='MEI (exploit)',\n",
    "    placeholder='select the strategy',\n",
    "    description='Strategy:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_model=Dropdown(\n",
    "    options=['lolo Random Forrest (RF) - quick (requ. min 8 init. samples)','Decision Trees (DT) - quick','Random Forrest (RFscikit) - quick','Gaussian Process Regression (GPR) - quick'],\n",
    "    value='Decision Trees (DT) - quick',\n",
    "    placeholder='select the Model',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Buttons\n",
    "button_confirm_strategy=Button(\n",
    "    description='Confirm strategy ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm selected strategy',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_upload =Button(\n",
    "    description='Upload',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Click to Upload',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_preview = Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to preview',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_plot = Button(\n",
    "    description='Plot',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Click to Plot',\n",
    "    icon='pencil',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "button_show_DS=Button(\n",
    "    description='Visualize settings',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Plots Design space in TSNE coordinates with candidates and colored targets',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_confirm_plot_var=Button(\n",
    "    description='Confirm selection',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm the selected target variable',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_plot_comparision=Button(\n",
    "    description='Compare',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Simplify the Columns',\n",
    "    icon='fa-bar-chart',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_confirm_options=Button(\n",
    "    description='Confirm options ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm options',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "                           \n",
    "button_perform_experiment=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "run_button_aut=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform Experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "run_button_aut_template=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform Experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "confirm_import_button=Button(\n",
    "    description='Confirm import ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm selected Strategy',\n",
    "    icon='check',\n",
    "layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "preview_settings_button=Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to Preview',\n",
    "    icon='search',\n",
    "layout=Layout(width='50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Layout File Upload Tab\n",
    "\n",
    "accordion = Accordion(children=[\n",
    "    up, \n",
    "    HBox([delim, delim_dec, eraser]), \n",
    "    rows])\n",
    "\n",
    "accordion.set_title(0, 'File Selection')\n",
    "accordion.set_title(1, 'Delimiter')\n",
    "accordion.set_title(2, 'Skip Rows')\n",
    "\n",
    "\n",
    "accordion_box = VBox([\n",
    "    accordion, \n",
    "    HBox([button_preview, button_upload ]),\n",
    "    out\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Tab\n",
    "\n",
    "container_plot_options= VBox([])\n",
    "button_container=HBox([button_plot])\n",
    "\n",
    "plotting=VBox(children=[VBox( [\n",
    "        HBox([graph_type]),\n",
    "        container_plot_options,\n",
    "        button_container,\n",
    "        out_plotting\n",
    "        ]\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sequential Learning Tab \n",
    "\n",
    "slider_of_for_dist=FloatSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Prediction quantile for distance-based utility (smaller values recommended for weak predictors).:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "slider_of_for_std=FloatSlider(\n",
    "    value=1,\n",
    "    min=0.1,\n",
    "    max=5,\n",
    "    step=0.1,\n",
    "    description='Ïƒ Factor (to controll the weigth of uncertainty):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "quantile_tar_slider= FloatSlider(\n",
    "    value=100,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Target threshold (Quantile):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "\n",
    "quantile_sample_slider= FloatSlider(\n",
    "    value=50,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Sample threshold (Quantile):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "initial_sample_size_text=BoundedIntText(\n",
    "    value=4,\n",
    "    min=2,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Initial Sample Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "box_features_slider=VBox([])\n",
    "\n",
    "\n",
    "plottingDS=VBox(children=[VBox( [\n",
    "        \n",
    "        out_input_space\n",
    "    ]\n",
    ")])\n",
    "\n",
    "DataPre_sl=VBox([\n",
    "        HBox([Label('Feature Selection',layout=Layout(width='50%', height='80px')),(feature_selector)]),\n",
    "        HBox([Label('Target Selection',layout=Layout(width='50%', height='80px')),target_selection]),\n",
    "        box_targets,\n",
    "        HBox([Label('Fixed Target Selection',layout=Layout(width='50%', height='80px')),fixed_target_selection]),\n",
    "        box_fixed_targets,\n",
    "        HBox([quantile_tar_slider,quantile_sample_slider]),\n",
    "        HBox([initial_sample_size_text,button_show_DS]),\n",
    "        plottingDS    \n",
    "])\n",
    "\n",
    "\n",
    "    \n",
    "DataPre=VBox([\n",
    "        HBox([feature_selector]),\n",
    "        HBox([target_selection]),\n",
    "        box_targets,\n",
    "        HBox([fixed_target_selection]),\n",
    "        box_fixed_targets,\n",
    "       ])\n",
    "\n",
    "iterations=IntSlider(\n",
    "    value=30,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='# of SL runs:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "custom_container=VBox([HBox([])])\n",
    "results_container=VBox([HBox([])])\n",
    "strategy_container=HBox([select_strategy, button_confirm_strategy ])\n",
    "\n",
    "start_and_stop_sl_container=HBox([button_perform_experiment])\n",
    "\n",
    "sl_settings= VBox([\n",
    "    strategy_container,\n",
    "    custom_container,\n",
    "    HBox([select_model,iterations]),\n",
    "    start_and_stop_sl_container,\n",
    "    out_perform_experiment,\n",
    "\n",
    "    \n",
    "])\n",
    "\n",
    "sl_results= VBox([\n",
    "    out_results_SL\n",
    "])\n",
    "\n",
    "\n",
    "sl_accordion=Accordion(children=[DataPre_sl,sl_settings,sl_results])\n",
    "sl_accordion.set_title(0,\"Settings\")\n",
    "sl_accordion.set_title(1,\"Sequential Learning Parameters\")\n",
    "sl_accordion.set_title(2,\"Results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automation Components\n",
    "\n",
    "sl_runs_for_sl_arena=BoundedIntText(\n",
    "    value=5,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='SL-Runs:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "checkbox_gp=Checkbox(\n",
    "    value=False,\n",
    "    description='Gaussian Process Regression (GPR) - quick',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "checkbox_dt=Checkbox(\n",
    "    value=False,\n",
    "    description='Decision Trees (DT) - quick',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "checkbox_rf=Checkbox(\n",
    "    value=False,\n",
    "    description='lolo Random Forrest (RF) - quick (requ. min 8 init. samples)',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "checkbox_rf_scikit=Checkbox(\n",
    "    value=False,\n",
    "    description='Random Forrest (RFscikit) - quick',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "specify_target_treshhold=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "specify_sample_threshold=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "specify_sigma=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "specify_distance=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "specify_init_sample_size=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "#refactor idee : Specification class mit checkbox und textfield\n",
    "all_specify_checkboxes=[specify_target_treshhold,specify_sample_threshold,specify_sigma,specify_distance,specify_init_sample_size]\n",
    "\n",
    "\n",
    "\n",
    "start_sigma=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_sigma=BoundedFloatText(\n",
    "    value=5,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "step_sigma=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Step Size:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_tar_tresh=BoundedFloatText(\n",
    "    value=95,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=0.5,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_tar_tresh=BoundedFloatText(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=0.5,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "step_tar_tresh=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.5,\n",
    "    description='Step:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_samp_tresh=BoundedFloatText(\n",
    "    value=50,\n",
    "    min=0,\n",
    "    max=100.0,\n",
    "    step=0.5,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_samp_tresh=BoundedFloatText(\n",
    "    value=55,\n",
    "    min=0,\n",
    "    max=100.0,\n",
    "    step=0.5,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "step_samp_tresh=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.5,\n",
    "    description='Step:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_init_samp=BoundedIntText(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "stop_init_samp=BoundedIntText(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "step_init_samp=BoundedIntText(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Step: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "#\n",
    "start_distance=BoundedFloatText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_distance=BoundedFloatText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "step_distance=BoundedFloatText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Step Size:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_tar_tresh=Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 89;92;96',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_samp_tresh=Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 51;67',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_init_samp=Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 2;8;9  ',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_sigma_factor =Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 1;2 ',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_utility_distance =Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 90;95 ',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "start_utility_distance=BoundedFloatText(\n",
    "    value=90,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_utility_distance=BoundedFloatText(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "step_utility_distance=BoundedFloatText(\n",
    "    value=5,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Step Size:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layout Tabs\n",
    "\n",
    "children = [\n",
    "    accordion_box, \n",
    "    VBox([toggle, out]),\n",
    "    plotting,\n",
    "    sl_accordion,\n",
    "    \n",
    "    \n",
    "   ]\n",
    "\n",
    "tab.children = children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Naming Tabs\n",
    "\n",
    "tab.set_title(0, \"Upload\")\n",
    "tab.set_title(1, \"Data Info\")\n",
    "tab.set_title(2, \"Design Space Explorer\")\n",
    "tab.set_title(3, \"Sequential Learning\")\n",
    "tab.set_title(4, \"Automation ðŸ¤–\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Utility Methods\n",
    "def decide_max_or_min(source,columns,dataframe):\n",
    "        row_list=[source.children[decide].children[0].value for decide in range(len(columns))]\n",
    "        for goal in row_list:\n",
    "                        for column in columns:\n",
    "                            if (goal == \"minimize\"):\n",
    "                                dataframe[column]=dataframe[column]*(-1)\n",
    "                              \n",
    "                                \n",
    "                                \n",
    "def extend(list_of_2dms_arrays_to_extend):\n",
    "    np_array=np.array(list_of_2dms_arrays_to_extend)\n",
    "    max_cols=max(map(len,np_array))\n",
    "    result_list=[]\n",
    "    for i in np_array:\n",
    "                    if(len(i) == max_cols):\n",
    "                        result_list.append(i)\n",
    "                    elif (len(i) != max_cols):\n",
    "                        how_often=max_cols-len(i)\n",
    "                        matrix_to_extend=np.tile(i[:][-1], (how_often, 1))\n",
    "                        i=np.concatenate((i, matrix_to_extend))\n",
    "                        result_list.append(i)\n",
    "                    \n",
    "   \n",
    "    return result_list\n",
    "\n",
    "    \n",
    "           \n",
    "def flatten_list(nested_list):\n",
    "    for sublist in nested_list:\n",
    "        flatlist=[element for element in sublist]  \n",
    "    return flatlist\n",
    "\n",
    "\n",
    "def import_settings():\n",
    "    content= content_parser(import_button)\n",
    "    settings = pd.read_csv(content, sep=',', index_col=False, decimal='.')\n",
    "         \n",
    "    return settings\n",
    "\n",
    "\n",
    "def content_parser(source):\n",
    "    if source.value == {}:\n",
    "        \"\"\"with out:\n",
    "            out.clear_output\n",
    "            display(Markdown('No CSV loaded'))\n",
    "            #print('No CSV loaded')    \"\"\"\n",
    "    else:\n",
    "        from io import StringIO\n",
    "        typ, content = \"\", \"\"\n",
    "        up_value = source.value\n",
    "        for i in up_value.keys():\n",
    "            typ = up_value[i][\"metadata\"][\"type\"]\n",
    "            if typ == \"text/csv\" or typ == \"application/vnd.ms-excel\":\n",
    "                content = up_value[i][\"content\"]\n",
    "                content_str = str(content, 'utf-8')\n",
    "\n",
    "                if eraser.value != {}: \n",
    "                    for val in eraser.value:\n",
    "                        if val == \"tab\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        elif val ==\"%\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        else:\n",
    "                            content_str = content_str.replace(val,\"\")\n",
    "                if content_str != \"\":\n",
    "                    str_io = StringIO(content_str) \n",
    "                    return str_io\n",
    "def df_converter():\n",
    "    content = content_parser(up)\n",
    "    if content is not None:\n",
    "            df = pd.read_csv(content, sep=delim.value, index_col=False, skiprows=rows.value,decimal=delim_dec.value)\n",
    "            df=df.apply(pd.to_numeric,errors=\"ignore\")\n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "            return df\n",
    "    else:\n",
    "        return None\n",
    "def preview():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is your data:'))\n",
    "        \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "            \n",
    "def upload():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is how your uploaded data looks like:'))\n",
    "       \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "            x_axis.options = df.columns\n",
    "            y_axis.options = df.columns\n",
    "            feature_selector.options= df.columns\n",
    "            \n",
    "            select_x.options=df.columns\n",
    "            select_y.options=df.columns\n",
    "            select_size.options=df.columns\n",
    "            select_hue.options=df.columns\n",
    "            selector_plot_variable.options=df.columns\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "            \n",
    "            \n",
    "def create_download_link( df, title, filename): \n",
    "    import base64\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = html_buttons = '''<html>\n",
    "    <head>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    </head>\n",
    "    <body>\n",
    "    <a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-warning\">{title}</button>\n",
    "    </a>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    html_button = html_buttons.format(payload=payload,filename=filename,title=title)\n",
    "    return HTML(html_button)\n",
    "\n",
    "            \n",
    "            \n",
    "def desc():\n",
    "    info_level = toggle.value\n",
    "    if info_level != {}:\n",
    "        df = df_converter()\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            \n",
    "            display(Markdown('\\n Data {} \\n'.format(\n",
    "                info_level)))\n",
    "            if df is not None:\n",
    "                if info_level == 'Info  ':\n",
    "                    df.info()\n",
    "                elif info_level == 'Stats  ':\n",
    "                    display(Markdown(df.describe().to_markdown()))\n",
    "                elif info_level == 'Preview  ':\n",
    "                    display(Markdown(df.head(10).to_markdown()))\n",
    "                else:\n",
    "                    display(Markdown('Configuration is wrong/missing...'))\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Methods\n",
    "import seaborn as sns\n",
    "\n",
    "def plot():\n",
    "    graph = graph_type.value\n",
    "    if graph==\"Scatter\":\n",
    "        plot_scatter()\n",
    "    elif graph==\"Correlation Heatmap\":\n",
    "            plot_heat()\n",
    "    elif graph==\"Scatter Matrix\":\n",
    "            plot_pairwise()\n",
    "          \n",
    "        \n",
    "def plot_pairwise():\n",
    "    df =confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        sns.pairplot(df)\n",
    "        plt.show()\n",
    "\n",
    "def plot_heat():\n",
    "    df = confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        corr = df.corr()\n",
    "        plt.figure(figsize=(12,7))\n",
    "        sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "        b, t = plt.ylim()\n",
    "        plt.ylim(b+0.5, t-0.5)\n",
    "        plt.title(\"Feature Correlation Heatmap\")\n",
    "        plt.show()\n",
    "            \n",
    "def plot_scatter():\n",
    "    data=df_converter()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        fig, ax = plt.subplots(figsize=(12,7))\n",
    "        #not generic\n",
    "        sns.scatterplot(y=select_y.value, x=select_x.value, hue=select_hue.value, size=select_size.value, data=data, ax=ax, sizes=(50, 300))\n",
    "        ax.set_title(select_y.value+ \"vs\"+ select_x.value)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "        plt.show()\n",
    "        plt.close(fig)  \n",
    "\n",
    "        \n",
    "def plot_TSNE_input_space():\n",
    "    \n",
    "            from sklearn.manifold import TSNE\n",
    "        \n",
    "            features_df=(df_converter()[confirm_features()]-df_converter()[confirm_features()].mean())/df_converter()[confirm_features()].std()\n",
    "            target_df=(df_converter()[confirm_target()]-df_converter()[confirm_target()].mean())/df_converter()[confirm_target()].std()       \n",
    "            fixed_target_df=(df_converter()[confirm_fixed_target()]-df_converter()[confirm_fixed_target()].mean())/df_converter()[confirm_fixed_target()].std()               \n",
    "            \n",
    "            decide_max_or_min(box_targets,confirm_target(),target_df)\n",
    "            decide_max_or_min(box_fixed_targets,confirm_fixed_target(),fixed_target_df)\n",
    "        \n",
    "            tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300,random_state=1000)\n",
    "            tsne_results = tsne.fit_transform(features_df)\n",
    "\n",
    "            \n",
    "            with out_input_space:\n",
    "                # Plot Results in reduced FS\n",
    "                out_input_space.clear_output(wait=True)\n",
    "                fig3= plt.figure(figsize=(10, 6))\n",
    "                targ_q = quantile_tar_slider.value/100\n",
    "                samp_q = quantile_sample_slider.value/100\n",
    "                sum_ = target_df.sum(axis=1).to_frame()+fixed_target_df.sum(axis=1).to_frame()\n",
    "                targ_q_t= sum_.quantile(targ_q)\n",
    "                samp_q_t=sum_.quantile(samp_q)\n",
    "                \n",
    "                cmap = plt.get_cmap('cool', 200)\n",
    "                cmap.set_under('dimgray') \n",
    "                cmap.set_over('lawngreen')\n",
    "                sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, cmap=cmap, vmin=samp_q_t.values, vmax=targ_q_t.values-0.0001)\n",
    "                cbar=plt.colorbar(sc,extend='both')\n",
    "                #ticklabs = cbar.ax.get_yticklabels()\n",
    "                cbar.ax.set_yticklabels([ ]) \n",
    "                cbar.ax.set_ylabel('targets (green)                to be explored            initial candidate pool (gray)', rotation=270 ,va='center')\n",
    "\n",
    "                plt.title(\"Design space in TSNE-coordinates: candidate pool and targets\")\n",
    "                plt.show()\n",
    "                        \n",
    "                plt.close(fig3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def confirm_options():\n",
    "    items=box_features_slider.children\n",
    "    df = df_converter()\n",
    "    Y = df.loc[:,df.columns.isin(target_selection.value)]\n",
    "    \n",
    "    for slider in items:\n",
    "            unt_grenz= slider.value[0]/100\n",
    "            ob_grenz= slider.value[1]/100\n",
    "            Y = Y[(Y >= Y.quantile(unt_grenz) ) & (Y <= Y.quantile(ob_grenz))]\n",
    "            Y= Y.dropna()\n",
    "    \n",
    "    return Y   \n",
    "\n",
    "\n",
    "def confirm_features():\n",
    "    df = df_converter()\n",
    "    train = feature_selector.value\n",
    "    target_selection.options=df.columns[~df.columns.isin(feature_selector.value)]\n",
    "    fixed_target_selection.options=df.columns[~df.columns.isin(target_selection.value)& ~df.columns.isin(feature_selector.value)]\n",
    "    train = df.columns[df.columns.isin(feature_selector.value)]\n",
    "    return train\n",
    "\n",
    "\n",
    "def confirm_var():\n",
    "    df= df_converter()\n",
    "    selection = list(selector_plot_variable.value)\n",
    "    var = df[selection]\n",
    " \n",
    "    return var\n",
    "\n",
    "  \n",
    "def confirm_target():\n",
    "    \n",
    "    df = df_converter()\n",
    "    target = df.columns[df.columns.isin(target_selection.value)]\n",
    "    fixed_target_selection.options=df.columns[~df.columns.isin(target_selection.value)& ~df.columns.isin(feature_selector.value)]\n",
    "\n",
    "    \n",
    "    return target \n",
    "\n",
    "def confirm_fixed_target():\n",
    "    df = df_converter()\n",
    "    fixed_target = df.columns[df.columns.isin(fixed_target_selection.value)]\n",
    "    return fixed_target\n",
    "\n",
    "def confirm_strategy():\n",
    "    strategy= select_strategy.value\n",
    "    if strategy != {}:\n",
    "            custom_container.children=[]\n",
    "            return select_strategy.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slider_for_dist_quantile():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist,  button_confirm_strategy]\n",
    "    \n",
    "def create_slider_for_dist_quantile_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist, slider_of_for_std,  button_confirm_strategy]\n",
    "        \n",
    "def create_slider_for_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_std,  button_confirm_strategy]\n",
    "    \n",
    "def create_dynamically_checkboxes(targets):\n",
    "    radiobuttons = [RadioButtons(\n",
    "    options=['maximize', 'minimize'],\n",
    "    value='maximize', \n",
    "    description=feature,\n",
    "    disabled=False\n",
    "    )\n",
    "    for feature in targets]\n",
    "    \n",
    "    checkboxes = [Checkbox(\n",
    "    value=False,\n",
    "    description='Check to use treshhold',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "    \n",
    "    for feature in targets]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    slider = [FloatText(\n",
    "    value=np.mean(df_converter()[feature].to_numpy()),\n",
    "    description=feature,\n",
    "    disabled=False)\n",
    "    \n",
    "    for feature in targets]\n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    slider_np=np.array(slider)\n",
    "    radiobuttons_np=np.array(radiobuttons)\n",
    "    checkboxes_np=np.array(checkboxes)\n",
    "    \n",
    "    return radiobuttons_np,slider_np,checkboxes_np\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Requ. experiments (mean)','Requ. experiments (std)','Requ. experiments (90%)',\n",
    "                                  'Requ. experiments (max)','Algorithm','Utlity Function','Ïƒ Factor','5 cycle perf.','10 cycle perf.',\n",
    "                                  'qant. (distance utility)','# SL runs','Initial Sample','# of samples in the DS',\n",
    "                                  '# Features','# Targets', 'Target threshold','Sample threshold','Features name','Targets name',\n",
    "                                  'Req. experiments (all)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "class targets():\n",
    "    checkboxes=None\n",
    "    radiobuttons=None\n",
    "    slider=None\n",
    "    not_stand_df=None\n",
    "    idx=None\n",
    "\n",
    "    def __init__(self,container,selection):\n",
    "        self.container=container\n",
    "        self.selection=selection\n",
    "        \n",
    "    def on_selection_change(self,change):\n",
    "        confirm_target()\n",
    "        self.not_stand_df=df_converter()\n",
    "        self.container.children=()\n",
    "        selection_as_list=list(self.selection.value)\n",
    "        self.radiobuttons,self.slider,self.checkboxes=create_dynamically_checkboxes(selection_as_list)\n",
    "        \n",
    "        for row in range(len(self.radiobuttons)):\n",
    "            \n",
    "            self.container.children=(*self.container.children,HBox([self.radiobuttons[row],self.checkboxes[row],self.slider[row]]))\n",
    "            self.checkboxes[row].observe(functools.partial(self.on_checkbox_checked,row),names='value')\n",
    "            self.slider[row].observe(functools.partial(self.on_texfield_typed,row),names='value')\n",
    "     \n",
    "    def on_texfield_typed(self,row,change):\n",
    "        self.checkboxes[row].value=False\n",
    "    def on_checkbox_checked(self,row,change):\n",
    "        if(self.checkboxes[row].value==True):\n",
    "            selection_as_list=list(self.selection.value)\n",
    "            print(selection_as_list[row])\n",
    "            print(self.slider[row].value)\n",
    "            df_mask=self.not_stand_df[selection_as_list[row]]>self.slider[row].value\n",
    "            temp=self.not_stand_df\n",
    "            \n",
    "            if(len(temp[df_mask])==0):\n",
    "                print(\"selection false,max min for this feature in this combination is: or change other targets\")\n",
    "            else:\n",
    "                self.not_stand_df = self.not_stand_df[df_mask]\n",
    "                self.idx = self.not_stand_df[df_mask].index\n",
    "                print(len(self.not_stand_df)==len(self.idx))\n",
    "        \n",
    "\n",
    "class fixed_targets(targets):\n",
    "    \"\"\"def on_selection_change(self,change):\n",
    "        confirm_fixed_target()\n",
    "        self.container.children=()\n",
    "        self.checkboxes,self.slider=create_dynamically_checkboxes(list(self.selection.value))\n",
    "        for row in range(len(self.checkboxes)):\n",
    "            self.container.children=(*self.container.children,HBox([self.checkboxes[row],self.slider[row]]))\n",
    "            self.slider[row].observe(self.on_slider_change,names='value')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sequential_learning:\n",
    "    \n",
    "    xlabel=\"Sequential Learning Iteration\"\n",
    "    dataframe = df_converter()\n",
    "    features_df=df_converter()\n",
    "    target_df=df_converter()\n",
    "    \n",
    "    min_distances_list=[]\n",
    "    \n",
    "    y_pred_dtr_mean=None\n",
    "    y_pred_dtr_std=None\n",
    "    y_pred_dtr=None\n",
    "    SampIdx=None\n",
    "    PredIdx=None\n",
    "    count=0\n",
    "    index_sum_randomized=None\n",
    "    rand_tars=[]\n",
    "    rand_fixed_tars=[]\n",
    "   \n",
    "    def __init__(self,dataframe,init_sample_size,target_treshhold,\n",
    "                 number_of_executions,sample_treshold,sigma,distance,\n",
    "                 model,strategy,targets_idx):  #constructor\n",
    "        \n",
    "        self.dataframe= dataframe\n",
    "        self.init_sample_size=init_sample_size\n",
    "        self.target_treshhold = target_treshhold/100\n",
    "        self.sample_treshold=sample_treshold/100\n",
    "        self.number_of_executions=number_of_executions\n",
    "        self.tries_list=np.empty(number_of_executions)\n",
    "        self.tries_list_rand_pick=np.empty(number_of_executions)\n",
    "        self.sigma=sigma\n",
    "        self.distance=distance\n",
    "        self.model=model\n",
    "        self.strategy = strategy\n",
    "        self.targets_idx=targets_idx\n",
    "        \n",
    "    def apply_feature_selection_to_df(self,dataframe):\n",
    "        self.features_df = self.dataframe[confirm_features()]    \n",
    "    \n",
    "    def apply_target_selection_to_df(self,dataframe):\n",
    "        self.target_df= self.dataframe[confirm_target()]    \n",
    "\n",
    "    #self werte return macht wenig sinn\n",
    "    def standardize_data(self):\n",
    "        dataframe_norm=(self.dataframe-self.dataframe.mean())/self.dataframe.std()\n",
    "        target_df_norm=(self.target_df-self.target_df.mean())/self.target_df.std()\n",
    "        features_df_norm=(self.features_df-self.features_df.mean())/self.features_df.std()\n",
    "        self.features_df=features_df_norm\n",
    "        self.target_df=target_df_norm\n",
    "        self.dataframe=dataframe_norm\n",
    "        return self.features_df, self.target_df, self.dataframe\n",
    "        \n",
    "\n",
    "\n",
    "    def init_sampling(self):\n",
    "        targets = confirm_target()\n",
    "        fixed_targets=confirm_fixed_target()\n",
    "        \n",
    "        sum_ = self.dataframe[targets].sum(axis=1).to_frame()+self.dataframe[fixed_targets].sum(axis=1).to_frame()\n",
    "    \n",
    "        samp_q_t=sum_.quantile(self.sample_treshold)\n",
    "        Index_label=np.where(sum_ < samp_q_t )\n",
    "        Index_label=Index_label[0]\n",
    "        init_sample_set = np.ones((0,self.init_sample_size))\n",
    "        \n",
    "        for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    init_sample_set=np.vstack([init_sample_set, random.choice(Index_label,self.init_sample_size)])\n",
    "       \n",
    "        return init_sample_set\n",
    "                                         \n",
    "    def start_sequential_learning(self):\n",
    "            self.tries_list=np.empty(self.number_of_executions)\n",
    "            self.tries_list.fill(np.nan)\n",
    "            self.tries_list_rand_pick=np.empty(self.number_of_executions)\n",
    "            self.tries_list_rand_pick.fill(np.nan)\n",
    "            self.count=0\n",
    "            distances=[]\n",
    "            targt_perfs=[]\n",
    "            \n",
    "            fixed_targets=[]\n",
    "            targets=[]\n",
    "            \n",
    "            current_distances_list=[]   \n",
    "            current_targt_perf_list=[]\n",
    "            \n",
    "            \n",
    "            with out_perform_experiment:\n",
    "                    display(Markdown('Sequential Learning is running...'))\n",
    "\n",
    "\n",
    "            \n",
    "            global result_df   \n",
    "            \n",
    "            decide_max_or_min(box_targets,confirm_target(),self.dataframe)\n",
    "            decide_max_or_min(box_fixed_targets,confirm_fixed_target(),self.dataframe)\n",
    "            \n",
    "            \n",
    "            init_sample_set=self.init_sampling()\n",
    "            fixed_targets_index=confirm_fixed_target()\n",
    "            self.dataframe.iloc[self.targets_idx]\n",
    "            sum_ = self.dataframe[confirm_target()].sum(axis=1).to_frame()+self.dataframe[fixed_targets_index].sum(axis=1).to_frame()\n",
    "                        \n",
    "            targ_q_t= sum_.quantile(self.target_treshhold) \n",
    "            schwellwert=sum_.quantile(self.target_treshhold)\n",
    "            Index_c=np.where(sum_ >= schwellwert )\n",
    "            Index_c=Index_c[0]\n",
    "\n",
    "\n",
    "            for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    self.perform_random_pick(i)\n",
    "                    self.SampIdx=init_sample_set[i].astype(int)\n",
    "                    self.PredIdx=self.dataframe\n",
    "                    self.PredIdx = self.PredIdx.drop(self.PredIdx.index[self.SampIdx]).index\n",
    "                    self.decide_model(self.model)\n",
    "                    self.tries_list[i]=self.init_sample_size\n",
    "                    distance=distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_c])\n",
    "                    distance=distance.min()\n",
    "                    current_distances_list=[distance]\n",
    "                    \n",
    "                    #max value summe\n",
    "                    targt_perf=sum_.loc[self.SampIdx].max().item()\n",
    "                    current_targt_perf_list=[targt_perf] \n",
    "\n",
    "                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                    \n",
    "                    \n",
    "                    current_fixed_target_list=np.array(best_value[confirm_fixed_target()].to_numpy()[0])\n",
    "                    current_prediction_target=np.array(best_value[confirm_target()].to_numpy()[0])\n",
    "                    \n",
    "                    \"\"\"tempLab=Labels\n",
    "                    tempLab(tempLab>PredTresh)=PredTresh\n",
    "                    tempLab(tempLab<PredTresh)=-100\n",
    "                    while \n",
    "                    \"\"\"\n",
    "                    #sum_=sum_.loc[self.targets_idx]\n",
    "                    while sum_.loc[self.SampIdx].max().values < targ_q_t.values:\n",
    "                                    \n",
    "                                    self.update_strategy(self.strategy)\n",
    "\n",
    "                                    #Train Model\n",
    "                                    self.decide_model(self.model)\n",
    "\n",
    "                                    schwellwert=sum_.quantile(self.target_treshhold)\n",
    "                                    Index_c=np.where(sum_ >= schwellwert )\n",
    "                                    Index_c=Index_c[0]\n",
    "                                    distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_c])\n",
    "                                    distance=distance.min()\n",
    "                                    current_distances_list.append(distance)\n",
    "\n",
    "                                    targt_perf=sum_.loc[self.SampIdx].max().values.tolist()\n",
    "                                    targt_perf=max(targt_perf)\n",
    "\n",
    "                                    current_targt_perf_list.append(targt_perf)\n",
    "                                    \n",
    "                                    \n",
    "                                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                                    \n",
    "                                    current_prediction_target=np.vstack([current_prediction_target,best_value[confirm_target()].to_numpy()[0]])\n",
    "                                    current_fixed_target_list=np.vstack([current_fixed_target_list,best_value[confirm_fixed_target()].to_numpy()[0]])\n",
    "                                    \n",
    "        \n",
    "                                    self.tries_list[i]=self.tries_list[i]+1   \n",
    "\n",
    "                    distances.append(current_distances_list)\n",
    "                    targt_perfs.append(current_targt_perf_list)\n",
    "                    fixed_targets.append(current_fixed_target_list)\n",
    "                    targets.append(current_prediction_target)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                ##Distance Plot\n",
    "                \n",
    "                    with out_perform_experiment:\n",
    "                        fig1,axs = plt.subplots(1,2,figsize=(15, 6))\n",
    "                        axs[0].set_title('Optimization progress in input space')\n",
    "                        axs[0].set_xlabel('development cycles')\n",
    "                        axs[0].set_ylabel(\"Minimum distance from sampled data to target\")\n",
    "                        axs[0].axhline(y=0, color='k', linestyle=':',label='Target')\n",
    "                        axs[0].legend()\n",
    "\n",
    "                        axs[1].set_title('Optimization progress in output space')\n",
    "                        axs[1].set_xlabel('development cycles')\n",
    "                        axs[1].set_ylabel(\"Maximum sampled property\")\n",
    "                        axs[1].axhline(y=targ_q_t.values, color='k', linestyle=':',label='Target (normalized)')\n",
    "                        axs[1].legend()\n",
    "\n",
    "                        #Extend values of perfs\n",
    "                        #lengths_of_perfs=[]\n",
    "                        #for runs in range(len(targt_perfs)):\n",
    "                        #                current_len_of_perf=len(targt_perfs[runs])\n",
    "                        #                lengths_of_perfs.append(current_len_of_perf)\n",
    "\n",
    "                        #for runs in range(len(targt_perfs)):\n",
    "                        #        if(len(targt_perfs[runs])!=max(lengths_of_perfs)):\n",
    "                        #            size_of_values_to_add =max(lengths_of_perfs)-len(targt_perfs[runs])\n",
    "                        #            targt_perfs[runs].extend(np.full(size_of_values_to_add, max(targt_perfs[runs])))\n",
    "\n",
    "                        #Plotting\n",
    "                        for runs in range(len(distances)):\n",
    "                            axs[0].plot(distances[runs],linewidth=8, alpha=0.4)\n",
    "\n",
    "                    for runs in range(len(targt_perfs)):\n",
    "                        #print(\" type targ perfs\",type(targt_perfs[runs]))\n",
    "                        axs[1].plot(targt_perfs[runs],linewidth=8, alpha=0.4)\n",
    "                        #plt.close(fig1)\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "                        \n",
    "                                    \n",
    "                        \n",
    "                    with out_perform_experiment:\n",
    "                            out_perform_experiment.clear_output(wait=True)\n",
    "                            time.sleep(1.0)\n",
    "                            fig2=plt.figure(figsize=(15, 5))\n",
    "                            plt.xlabel('Number of required Experiments')\n",
    "                            plt.ylabel(\"Frequency\")\n",
    "                            plt.title(\"Performance histogram for %s with strategy %s \"%(self.model,self.strategy))\n",
    "                            #plt.hist([self.tries_list,self.tries_list_rand_pick],bins=len(self.tries_list),label=['SL Tries', 'Random Pick Tries'])         \n",
    "                            plt.hist([self.tries_list_rand_pick],range=(1, len(self.features_df)),label=['Random Process'],alpha=0.4)         \n",
    "                            plt.hist([self.tries_list],label=['SL'],range=(1, len(self.features_df)),alpha=0.4)         \n",
    "                            plt.legend()\n",
    "\n",
    "                            plt.show()\n",
    "                            #plt.close(fig2)\n",
    "                            \n",
    "                            \n",
    "        #Extend values of perfs\n",
    "            lengths_of_perfs=[]\n",
    "            for runs in range(len(targt_perfs)):\n",
    "                            current_len_of_perf=len(targt_perfs[runs])\n",
    "                            lengths_of_perfs.append(current_len_of_perf)\n",
    "\n",
    "            for runs in range(len(targt_perfs)):\n",
    "                                    if(len(targt_perfs[runs])!=max(lengths_of_perfs)):\n",
    "                                        size_of_values_to_add =max(lengths_of_perfs)-len(targt_perfs[runs])\n",
    "                                        targt_perfs[runs].extend(np.full(size_of_values_to_add, max(targt_perfs[runs])))\n",
    "\n",
    "            targt_perfs_as_array=np.array(targt_perfs)\n",
    "            mean_performances=np.mean(targt_perfs_as_array,axis=0)\n",
    "            \n",
    "            rel_perform_after_5=1.0\n",
    "            rel_perform_after_10=1.0\n",
    "            \n",
    "            max_performance=np.max(sum_)\n",
    "            \n",
    "            min_performance=np.min(sum_)\n",
    "        \n",
    "            \n",
    "            print(len(mean_performances))\n",
    "            \n",
    "            if(len(mean_performances) > 5 and len(mean_performances) <10):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                \n",
    "            if(len(mean_performances)==5):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                \n",
    "            if(len(mean_performances)>=10):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                perform_after_10=mean_performances[9]\n",
    "                print(perform_after_10/max_performance)\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                rel_perform_after_10=(perform_after_10-min_performance)/(max_performance-min_performance)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            if self.strategy=='MEI (exploit)':\n",
    "                self.sigma=0\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MU (explore)':\n",
    "                self.sigma=1\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MLI (explore & exploit)':\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MEID (exploit)':\n",
    "                self.sigma=0\n",
    "            \n",
    "                \n",
    "            ##Appending Performance intensiv --> List comprehension\n",
    "            to_append=([np.mean(self.tries_list),np.std(self.tries_list),np.quantile(self.tries_list,0.90),\n",
    "                        np.quantile(self.tries_list,1),self.model, self.strategy,self.sigma,rel_perform_after_5,rel_perform_after_10,self.distance,\n",
    "                        self.number_of_executions,self.init_sample_size,len(self.dataframe.index),len(confirm_features()),\n",
    "                        len(confirm_target()),self.target_treshhold,self.sample_treshold,\n",
    "                        confirm_features().tolist(),confirm_target().tolist(),self.tries_list])\n",
    "\n",
    "####SL-Results\n",
    "            with out_results_SL: \n",
    "                    out_results_SL.clear_output(wait=True)\n",
    "                    display(Markdown('### Performance summary:'))\n",
    "                    display(Markdown('requ. experiments with optimzation (mean):  {} '.format(\n",
    "                    np.mean(self.tries_list))))\n",
    "                    display(Markdown(\"requ. experiments without optimzation (mean): {}\".format(np.mean(self.tries_list_rand_pick))))\n",
    "                    display(Markdown(\" \"))\n",
    "                    display(Markdown('### Result plots:'))\n",
    "\n",
    "\n",
    "#Plot targets\n",
    "### Fixed Targets\n",
    "            if(len(confirm_fixed_target().values.tolist())>0):\n",
    "                    anzahl_plots=len(fixed_target_selection.value)\n",
    "                    fig3,axs_fixed = plt.subplots(anzahl_plots,figsize=(8,5*anzahl_plots),squeeze=False)\n",
    "                    axs_fixed=axs_fixed.flatten()\n",
    "                    \n",
    "                    fixed_targets_extended=extend(fixed_targets)\n",
    "                    \n",
    "                    mean_fixed_targets_extended=np.mean(fixed_targets_extended,axis=0)\n",
    "                \n",
    "                    \n",
    "                    fixed_rand_extended=extend(self.rand_fixed_tars)\n",
    "                    \n",
    "                    mean_fixed_rand_extended=np.mean(fixed_rand_extended,axis=0)\n",
    "                    \n",
    "#Plot fixed targets\n",
    "                    for fixed_target in range(anzahl_plots):\n",
    "                            axs_fixed[fixed_target].set_title('Created value for %s'%(confirm_fixed_target()[fixed_target]))\n",
    "                            axs_fixed[fixed_target].set_xlabel('development cycles')\n",
    "                            axs_fixed[fixed_target].set_ylabel(\"Best sampled property\")\n",
    "                            axs_fixed[fixed_target].set_xlim([0,len(mean_fixed_targets_extended[:,0])])\n",
    "\n",
    "                    for one_tar in range(anzahl_plots):  \n",
    "       \n",
    "                        axs_fixed[one_tar].plot(mean_fixed_targets_extended[:,one_tar],linewidth=8, alpha=0.9, color='k',label='With optimization')\n",
    "                        axs_fixed[one_tar].plot(mean_fixed_rand_extended[:,one_tar],linewidth=8, alpha=0.9, color='g',label='Without optimization')\n",
    "                        axs_fixed[one_tar].axvline(x=round(np.mean(self.tries_list)-self.init_sample_size), color='k', linestyle=':',label='Average SL cycles to success')\n",
    "                        axs_fixed[one_tar].legend()\n",
    "                        \n",
    "                    for sl_run in range(len(targets)):                            \n",
    "                            for one_tar in range(anzahl_plots):\n",
    "                                        axs_fixed[one_tar].plot(fixed_targets[sl_run][:,one_tar],linewidth=2, alpha=0.1,color='k')\n",
    "                                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "            with out_results_SL:\n",
    "                anzahl_plots=len(target_selection.value)\n",
    "                fig4,axs_pred = plt.subplots(anzahl_plots,figsize=(8,5*anzahl_plots), squeeze=False)\n",
    "                axs_pred=axs_pred.flatten()\n",
    "                targets_extended=extend(targets)\n",
    "                mean_targets_extended=np.mean(targets_extended,axis=0)\n",
    "                rand_extended=extend(self.rand_tars)\n",
    "                mean_rand_extended=np.mean(rand_extended,axis=0)\n",
    "                \n",
    "                \n",
    "                for pred_target in range(anzahl_plots):\n",
    "                            axs_pred[pred_target].set_title('Created value for %s'%(confirm_target()[pred_target]))\n",
    "                            axs_pred[pred_target].set_xlabel('development cycles')\n",
    "                            axs_pred[pred_target].set_ylabel(\"Best sampled property\")\n",
    "                            axs_pred[pred_target].set_xlim([0,len(mean_targets_extended[:,0])])\n",
    "\n",
    "                           \n",
    "                for pred_target in range(anzahl_plots):  \n",
    "    \n",
    "                        axs_pred[pred_target].plot(mean_targets_extended[:,pred_target],linewidth=8, alpha=0.9, color='k',label='With optimization')\n",
    "                        axs_pred[pred_target].plot(mean_rand_extended[:,pred_target],linewidth=8, alpha=0.9, color='g',label='Without optimization')\n",
    "                        axs_pred[pred_target].axvline(x=round(np.mean(self.tries_list)-self.init_sample_size), color='k', linestyle=':',label='Average SL cycles to success')\n",
    "                        axs_pred[pred_target].legend()\n",
    "                        \n",
    "               \n",
    "                for sl_run in range(len(targets)):                            \n",
    "                            for one_tar in range(anzahl_plots):\n",
    "                                        axs_pred[one_tar].plot(targets[sl_run][:,one_tar],linewidth=2, alpha=0.1,color='k')      \n",
    "                                        plt.xlim([0,len(mean_targets_extended[:,one_tar])])\n",
    "                \n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "\n",
    "    \n",
    "    \n",
    "            with out_results_SL:\n",
    "                    \n",
    "                    display(Markdown(\" \"))\n",
    "                    display(Markdown('### History:'))\n",
    "                    display(Markdown(\" \"))\n",
    "                    a_series = pd.Series(to_append, index = result_df.columns)\n",
    "                    result_df= result_df.append(a_series, ignore_index=True)\n",
    "                    display(Markdown(result_df.to_markdown()))\n",
    "                    display((create_download_link(result_df,'Download history','results_sl')))\n",
    "\n",
    "                    \n",
    "            \n",
    "            ###a\n",
    "            with out_perform_experiment:\n",
    "                        display(Markdown('done âœ…'))\n",
    "                        display(Markdown(\" \"))\n",
    "                        \n",
    "            \n",
    "            \n",
    "                           \n",
    "    def perform_random_pick(self,acutal_iter):\n",
    "        sum_ = self.dataframe[confirm_target()].sum(axis=1).to_frame()+self.dataframe[confirm_fixed_target()].sum(axis=1).to_frame()\n",
    "        index_sum=sum_.index.to_numpy()\n",
    "        index_sum_randomized=np.random.choice(index_sum,len(index_sum),False)\n",
    "        targ_q_t= sum_.quantile(self.target_treshhold)\n",
    "        self.tries_list_rand_pick[acutal_iter]=1\n",
    "\n",
    "        \n",
    "        run=0\n",
    "        \n",
    "        best_value=df_converter().iloc[index_sum_randomized[run]]\n",
    "        \n",
    "        current_fixed_rand_tars=np.array(best_value[confirm_fixed_target()].to_numpy())\n",
    "        current_pred_rand_tars=np.array(best_value[confirm_target()].to_numpy())\n",
    "        \n",
    "        \n",
    "        \n",
    "        while sum_.iloc[index_sum_randomized[run]].values[0].astype(float).item() < targ_q_t.item():\n",
    "            self.tries_list_rand_pick[acutal_iter]=self.tries_list_rand_pick[acutal_iter]+1 \n",
    "            \n",
    "            \n",
    "            temp_index=np.argmax(sum_.iloc[index_sum_randomized[0:run+1]]) \n",
    "            max_index=index_sum_randomized[temp_index]\n",
    "            best_value=df_converter().iloc[max_index]\n",
    "            current_pred_rand_tars=np.vstack([current_pred_rand_tars,best_value[confirm_target()].to_numpy()])\n",
    "            current_fixed_rand_tars=np.vstack([current_fixed_rand_tars,best_value[confirm_fixed_target()].to_numpy()])\n",
    "            run=run+1\n",
    "        \n",
    "        temp_index=np.argmax(sum_.iloc[index_sum_randomized[0:run+1]]) \n",
    "        max_index=index_sum_randomized[temp_index]\n",
    "        best_value=df_converter().iloc[max_index]\n",
    "        current_pred_rand_tars=np.vstack([current_pred_rand_tars,best_value[confirm_target()].to_numpy()])\n",
    "        current_fixed_rand_tars=np.vstack([current_fixed_rand_tars,best_value[confirm_fixed_target()].to_numpy()])\n",
    "        \n",
    "        self.rand_fixed_tars.append(current_fixed_rand_tars)\n",
    "        self.rand_tars.append(current_pred_rand_tars)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #Refactor idee: Model klasse mit name und checkbox description\n",
    "    def decide_model(self,model):\n",
    "        if model== 'lolo Random Forrest (RF) - quick (requ. min 8 init. samples)':\n",
    "                    Expected_Pred, Uncertainty=  self.fit_RF_wJK()\n",
    "        elif model == 'Decision Trees (DT) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_DT_wJK()\n",
    "        elif model == 'Random Forrest (RFscikit) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_TE_wJK()\n",
    "        elif model == 'Gaussian Process Regression (GPR) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_GP()\n",
    "                    \n",
    "            \n",
    "    def update_strategy(self, strategy):\n",
    "        if strategy=='MEI (exploit)':\n",
    "            self.updateIndexMEI()\n",
    "        elif strategy=='MU (explore)':\n",
    "            self.updateIndexMU()\n",
    "        elif strategy=='MLI (explore & exploit)':\n",
    "            self.updateIndexMLI()\n",
    "        elif strategy=='MEID (exploit)':\n",
    "            self.updateIndexMEID()        \n",
    "        elif strategy=='MLID (explore & exploit)':\n",
    "            self.updateIndexMLID()\n",
    "        \n",
    "    \n",
    "    def updateIndexMEI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            index_max = np.argmax(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze())\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "            \n",
    "    def updateIndexMEID(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            schwellwert=np.quantile(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze(),self.distance/100)\n",
    "            Index_=np.where(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            \n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "\n",
    " \n",
    "\n",
    "    def updateIndexMLID(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            schwellwert=np.quantile((fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()),self.distance/100)\n",
    "            Index_=np.where(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx              \n",
    "            \n",
    "            \n",
    "    def updateIndexMU(self):\n",
    "            index_max = np.argmax(self.Uncertainty)\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "            \n",
    "    def updateIndexMLI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            index_max = np.argmax(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze())    \n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "                        \n",
    "            \n",
    "    def fit_DT_wJK(self):        \n",
    "        td,tl=self.jk_resampling()\n",
    "        self.y_pred_dtr=[]\n",
    "        for i in range(len(td)):\n",
    "            dtr = DecisionTreeRegressor()\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "        \n",
    "       \n",
    "        #quick bug fix\n",
    "        if(self.strategy==\"MEID (exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        elif(self.strategy==\"MLID (explore & exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        else:\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.y_pred_dtr=self.y_pred_dtr.T\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=1)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=1)\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "        \n",
    "    def fit_TE_wJK(self):\n",
    "        td,tl=self.jk_resampling()\n",
    "        self.y_pred_dtr=[]\n",
    "        for i in range(len(td)):\n",
    "            ## alternative Ensamble Learners below:\n",
    "            dtr = SKRFR (n_estimators=10)\n",
    "            #dtr =AdaBoostRegressor(n_estimators = 10)\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "                \n",
    "        \n",
    "        #quick bug fix\n",
    "        if(self.strategy==\"MEID (exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        elif(self.strategy==\"MLID (explore & exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        else:\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.y_pred_dtr=self.y_pred_dtr.T\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=1)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=1)\n",
    "\n",
    "\n",
    "        return self.Expected_Pred, self.Uncertainty        \n",
    "\n",
    "    def jk_resampling(self):\n",
    "        from resample.jackknife import resample as b_resample\n",
    "        td=[x for x in b_resample(self.features_df.iloc[self.SampIdx])]\n",
    "        tl=[x for x in b_resample(self.dataframe[confirm_target()].iloc[self.SampIdx].sum(axis=1).to_frame())]\n",
    "        td=np.array(td)\n",
    "        tl=np.array(tl)\n",
    "        return td,tl\n",
    "                   \n",
    "    def fit_RF_wJK(self):\n",
    "        dtr = RandomForestRegressor()\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.dataframe[confirm_target()].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx].to_numpy(), return_std=True)\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "    \n",
    "    def fit_GP(self):\n",
    "        \n",
    "        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "        dtr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.dataframe[confirm_target()].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty= dtr.predict(self.features_df.iloc[self.PredIdx], return_std=True)      \n",
    "        return self.Expected_Pred.squeeze(), self.Uncertainty.squeeze()\n",
    "\n",
    "        \n",
    "    def main(self):\n",
    "        self.apply_feature_selection_to_df(self.dataframe)\n",
    "        self.apply_target_selection_to_df(self.dataframe)\n",
    "        if(len(confirm_fixed_target().values.tolist())>0):\n",
    "            self.target_df=self.target_df.join(self.dataframe[confirm_fixed_target()])\n",
    "        self.standardize_data()\n",
    "        init_sample_set=self.init_sampling()\n",
    "        self.start_sequential_learning()\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = targets(box_targets,target_selection) \n",
    "ft = fixed_targets(box_fixed_targets,fixed_target_selection)\n",
    "\n",
    "s = sequential_learning(df_converter(),initial_sample_size_text.value,quantile_tar_slider.value,\n",
    "                        iterations.value,quantile_sample_slider.value,slider_of_for_std.value,\n",
    "                        slider_of_for_dist.value,select_model.value,confirm_strategy(),t.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_clicked(b):\n",
    "    try:\n",
    "        preview()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def upload_clicked(b):\n",
    "    if(up._counter>1):\n",
    "        up.value.clear()\n",
    "        up._counter = 1\n",
    "    try:\n",
    "        upload()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def desc_clicked(b):\n",
    "    desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_settings_button_clicked(b):\n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        display(Markdown(settings.to_markdown()))\n",
    "        \n",
    "def confirm_import_clicked(b):\n",
    "    if(import_button._counter>1):\n",
    "        up.value.clear()\n",
    "        import_button._counter=1\n",
    "    \n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        out_settings.clear_output(wait=True)\n",
    "        display(Markdown('Your Settings got importet and look like:'))\n",
    "        display(Markdown(settings.to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter_clicked(b):\n",
    "    plot()\n",
    "\n",
    "def pairwise_clicked(b):\n",
    "    plot_pairwise()\n",
    "def heat_clicked(b):\n",
    "    plot_heat()\n",
    "def scatter_clicked(b):\n",
    "    plot_scatter()\n",
    "    \n",
    "def plotterDS_clicked(b):\n",
    "    plot_TSNE_input_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment_clicked(b):\n",
    "    df=df_converter()\n",
    "    s = sequential_learning(df,initial_sample_size_text.value,quantile_tar_slider.value,iterations.value,quantile_sample_slider.value,slider_of_for_std.value,slider_of_for_dist.value,select_model.value,confirm_strategy(),t.idx)\n",
    "    start_and_stop_sl_container.children=[button_perform_experiment]\n",
    "    s.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_value_change(change):\n",
    "    quantile_sample_slider.max=quantile_tar_slider.value\n",
    "    \n",
    "def on_strategy_changes(change):\n",
    "    if select_strategy.value==\"MEID (exploit)\":\n",
    "        create_slider_for_dist_quantile()\n",
    "    elif select_strategy.value==\"MLID (explore & exploit)\":  \n",
    "        create_slider_for_dist_quantile_std()\n",
    "    elif select_strategy.value==\"MLI (explore & exploit)\":\n",
    "        create_slider_for_std()\n",
    "        \n",
    "def display_progess_automation(actual_iter,all_comb):\n",
    "    with out_iter_aut:\n",
    "            time.sleep(0.1)\n",
    "            out_iter_aut.clear_output()\n",
    "            display(Markdown('\\n Status  {}/{} \\n'.format(\n",
    "                        actual_iter+1,all_comb)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confirm_features_clicked(b):\n",
    "    confirm_features()\n",
    "    \n",
    "def on_feature_selection_change(change):\n",
    "    confirm_features()\n",
    "    \n",
    "def on_graph_type_change(change):\n",
    "        \n",
    "    if graph_type.value ==\"Scatter\":\n",
    "        container_plot_options.children= [HBox([select_x,select_y]),\n",
    "        HBox([select_hue,select_size])]\n",
    "    elif graph_type.value ==\"Scatter Matrix\":\n",
    "        \n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "                                          \n",
    "    elif graph_type.value =='Correlation Heatmap':\n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "        \n",
    "    else: container_plot_options.children=[]\n",
    "\n",
    "\n",
    "def confirm_var_clicked(b):\n",
    "    confirm_var()\n",
    "\n",
    "def confirm_options_clicked(b):\n",
    "    confirm_options()\n",
    "\n",
    "def confirm_strategy_clicked(b):\n",
    "    confirm_strategy()\n",
    "    \n",
    "    \n",
    "def on_graph_type_change(change):\n",
    "        \n",
    "    if graph_type.value ==\"Scatter\":\n",
    "        container_plot_options.children= [HBox([select_x,select_y]),\n",
    "        HBox([select_hue,select_size])]\n",
    "    elif graph_type.value ==\"Scatter Matrix\":\n",
    "        \n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "                                          \n",
    "    elif graph_type.value =='Correlation Heatmap':\n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "        \n",
    "    else: container_plot_options.children=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "button_upload.on_click(upload_clicked)\n",
    "toggle.observe(desc_clicked, 'value')\n",
    "button_preview.on_click(preview_clicked)\n",
    "\n",
    "button_confirm_plot_var.on_click(confirm_var_clicked)\n",
    "\n",
    "feature_selector.observe(on_feature_selection_change,names='value')\n",
    "target_selection.observe(t.on_selection_change,names='value')\n",
    "fixed_target_selection.observe(ft.on_selection_change,names='value')\n",
    "\n",
    "\n",
    "graph_type.observe(on_graph_type_change,names='value')\n",
    "quantile_tar_slider.observe(on_value_change,names='value')\n",
    "\n",
    "\n",
    "\n",
    "button_show_DS.on_click(confirm_target,confirm_fixed_target)\n",
    "select_strategy.observe(on_strategy_changes,names=\"value\")\n",
    "\n",
    "button_confirm_options.on_click(confirm_options_clicked)\n",
    "button_confirm_strategy.on_click(confirm_strategy_clicked)\n",
    "\n",
    "preview_settings_button.on_click(preview_settings_button_clicked) \n",
    "button_perform_experiment.on_click(perform_experiment_clicked)\n",
    "confirm_import_button.on_click(confirm_import_clicked)\n",
    "\n",
    "button_plot.on_click(plotter_clicked)\n",
    "button_show_DS.on_click(plotterDS_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b2b9e6c88b452bbae8db369605a903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Accordion(children=(FileUpload(value={}, description='Upload'), HBox(children=(Raâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture CO2 (Na2SiO3 as solution)\n",
      "140.77240615384616\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-b2f840d73d1e>:40: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  self.idx = self.not_stand_df[df_mask].index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slump (mm)\n",
      "133.44230769230768\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-b2f840d73d1e>:40: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  self.idx = self.not_stand_df[df_mask].index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28-d Cubic compressive strength (MPa)\n",
      "43.337444230769236\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-b2f840d73d1e>:40: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  self.idx = self.not_stand_df[df_mask].index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 156 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 156 samples in 0.002s...\n",
      "[t-SNE] Computed conditional probabilities for sample 156 / 156\n",
      "[t-SNE] Mean sigma: 2.066000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 55.303764\n",
      "[t-SNE] KL divergence after 300 iterations: 0.375863\n",
      "22\n",
      "0    0.8739\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
