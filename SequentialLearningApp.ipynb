{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Learning App for Materials Discovery - *SLAMD*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from ipywidgets import Box,Label,Text,FloatText,BoundedFloatText,Checkbox,ToggleButtons,Dropdown,VBox,HBox,Accordion,BoundedIntText,SelectMultiple,RadioButtons,FloatRangeSlider,Button,IntSlider,Label,Tab,Output,FileUpload,Layout,FloatSlider\n",
    "from IPython.display import display,Markdown,HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance_matrix\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor as SKRFR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn import preprocessing\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "from operator import add\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)   \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tab\n",
    "tab =Tab() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs\n",
    "out=Output()\n",
    "out_plotting=Output()\n",
    "out_settings=Output()\n",
    "out_algo=Output()\n",
    "out_perform_experiment=Output()\n",
    "out_input_space=Output()\n",
    "out_res=Output()\n",
    "out_iter_aut=Output()\n",
    "out_results_SL=Output()\n",
    "out_app=Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Upload\n",
    "up = FileUpload(accept=\"\", multiple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload Properties \n",
    "delim =RadioButtons(\n",
    "    options=[',', ';',' '],\n",
    "    description='Separator: ',\n",
    "    disabled=False)\n",
    "delim_dec = RadioButtons(\n",
    "    options=['.', ','],\n",
    "    description='Decimal delim: ',\n",
    "    disabled=False)\n",
    "\n",
    "eraser = SelectMultiple(\n",
    "    options=['tab','\"',\"%\"],\n",
    "    value=['tab'],\n",
    "    #rows=10,\n",
    "    description='Eraser: ',\n",
    "    disabled=False)\n",
    "rows = IntSlider(\n",
    "    value=0,\n",
    "    step=1,\n",
    "    description='# of lines:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Info \n",
    "toggle = ToggleButtons(\n",
    "    options=['Preview  ', 'Info  ', 'Stats  '],\n",
    "    description='Options',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    icons=['search', 'info', 'tachometer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of Targets and Features\n",
    "feature_selector=SelectMultiple(\n",
    "    options=[],\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')) \n",
    "\n",
    "feature_selector_application=SelectMultiple(\n",
    "    options=[],\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')) \n",
    "\n",
    "target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "target_selection_application=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "\n",
    "fixed_target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "fixed_target_selection_application=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "selector_plot_variable=SelectMultiple(\n",
    "    options=[],\n",
    "    description='Features',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "graph_type = Dropdown(\n",
    "    options=['Choose graph type','Scatter', 'Scatter Matrix', 'Correlation Heatmap'],\n",
    "    value='Choose graph type',\n",
    "    description='Graph type:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "x_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='X-Axis:',\n",
    "    disabled=False)\n",
    "y_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False)\n",
    "\n",
    "select_x=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select X-axis',\n",
    "    description='X-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_y=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select Y-axis',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_hue=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the hue',\n",
    "    description='Hue:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_size=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the size',\n",
    "    description='Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "container_checkboxes_targets=VBox([])\n",
    "container_checkboxes_fixed_targets=VBox([])\n",
    "\n",
    "container_slider_targets=VBox([])\n",
    "container_slider_fixed_targets=VBox([])\n",
    "\n",
    "box_targets=VBox([])\n",
    "box_fixed_targets=VBox([])\n",
    "\n",
    "\n",
    "\n",
    "container_checkboxes_targets=VBox([])\n",
    "container_checkboxes_fixed_targets=VBox([])\n",
    "\n",
    "container_slider_targets=VBox([])\n",
    "container_slider_fixed_targets=VBox([])\n",
    "\n",
    "box_targets=VBox([])\n",
    "box_fixed_targets=VBox([])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Learning Properties\n",
    "select_strategy=Dropdown(\n",
    "    options=['MEI (exploit)','MU (explore)','MLI (explore & exploit)','MEID (exploit)','MLID (explore & exploit)'],\n",
    "    value='MEI (exploit)',\n",
    "    placeholder='select the strategy',\n",
    "    description='Strategy:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "slider_of_for_std_App=FloatSlider(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.1,\n",
    "    #description='curiosity (to controll the weigth of uncertainty):',\n",
    "    tooltip='To controll the weigth of model uncertainty',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "\n",
    "select_model=Dropdown(\n",
    "    options=['AI-Model (lolo Random Forrest)','Statistics based model (Gaussian Process Regression)'],\n",
    "    value='Statistics based model (Gaussian Process Regression)',\n",
    "    placeholder='select the Model',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "Model_containerOne=HBox([slider_of_for_std_App])\n",
    "Model_containerTwo=HBox([select_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Buttons\n",
    "\n",
    "\n",
    "button_upload =Button(\n",
    "    description='Upload',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Click to Upload',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_preview = Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to preview',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_plot = Button(\n",
    "    description='Plot',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Click to Plot',\n",
    "    icon='pencil',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "button_show_DS=Button(\n",
    "    description='Visualize settings',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Plots materials data in TSNE coordinates and colored targets',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_confirm_plot_var=Button(\n",
    "    description='Confirm selection',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm the selected target variable',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_plot_comparision=Button(\n",
    "    description='Compare',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Simplify the Columns',\n",
    "    icon='fa-bar-chart',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_confirm_options=Button(\n",
    "    description='Confirm options ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm options',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "                           \n",
    "button_perform_experiment=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "button_application=Button(\n",
    "    description='Make Prediction',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "\n",
    "confirm_import_button=Button(\n",
    "    description='Confirm import ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm selected Strategy',\n",
    "    icon='check',\n",
    "layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "preview_settings_button=Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to Preview',\n",
    "    icon='search',\n",
    "layout=Layout(width='50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Layout File Upload Tab\n",
    "\n",
    "accordion = Accordion(children=[\n",
    "    up, \n",
    "    HBox([delim, delim_dec, eraser]), \n",
    "    rows])\n",
    "\n",
    "accordion.set_title(0, 'File Selection')\n",
    "accordion.set_title(1, 'Delimiter')\n",
    "accordion.set_title(2, 'Skip Rows')\n",
    "\n",
    "\n",
    "accordion_box = VBox([\n",
    "    accordion, \n",
    "    HBox([button_preview, button_upload ]),\n",
    "    out\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Tab\n",
    "\n",
    "container_plot_options= VBox([])\n",
    "button_container=HBox([button_plot])\n",
    "\n",
    "plotting=VBox(children=[VBox( [\n",
    "        HBox([graph_type]),\n",
    "        container_plot_options,\n",
    "        button_container,\n",
    "        out_plotting\n",
    "        ]\n",
    ")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sequential Learning Tab \n",
    "\n",
    "slider_of_for_dist=FloatSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Prediction quantile for distance-based utility (smaller values recommended for weak predictors).:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "slider_of_for_std=FloatSlider(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=5,\n",
    "    step=0.1,\n",
    "    description='œÉ Factor (to controll the weigth of uncertainty):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "quantile_tar_slider= FloatSlider(\n",
    "    value=100,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Target Quantile:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "\n",
    "initial_sample_size_text=BoundedIntText(\n",
    "    value=8,\n",
    "    min=2,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Initial Sample Set Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    "\n",
    ")\n",
    "\n",
    "batch_size_text=BoundedIntText(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Batch Size',\n",
    "    tooltip='# of simultanious experiments',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    "\n",
    ")\n",
    "\n",
    "box_features_slider=VBox([])\n",
    "\n",
    "\n",
    "plottingDS=VBox(children=[VBox( [\n",
    "        \n",
    "        out_input_space\n",
    "    ]\n",
    ")])\n",
    "\n",
    "DataPre_sl=VBox([\n",
    "        HBox([Label('Materials Data (Input)', font=('bold'), layout=Layout(width='50%', height='80px')),(feature_selector)]),\n",
    "        HBox([Label('Target Properties', font=('bold'),layout=Layout(width='50%', height='80px')),target_selection]),\n",
    "        box_targets,\n",
    "        HBox([Label('A-priori Information', font=('bold'),layout=Layout(width='50%', height='80px')),fixed_target_selection]),\n",
    "        box_fixed_targets,\n",
    "        HBox([quantile_tar_slider,button_show_DS]),\n",
    "        plottingDS    \n",
    "])\n",
    "\n",
    "\n",
    "    \n",
    "DataPre=VBox([\n",
    "        HBox([feature_selector]),\n",
    "        HBox([target_selection]),\n",
    "        box_targets,\n",
    "        HBox([fixed_target_selection]),\n",
    "        box_fixed_targets,\n",
    "       ])\n",
    "\n",
    "iterations=IntSlider(\n",
    "    value=25,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='# of SL runs:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "custom_container=VBox([HBox([])])\n",
    "results_container=VBox([HBox([])])\n",
    "InitSampCon_container=HBox([initial_sample_size_text,batch_size_text])\n",
    "\n",
    "strategy_container=HBox([select_strategy])\n",
    "\n",
    "\n",
    "start_and_stop_sl_container=HBox([button_perform_experiment])\n",
    "\n",
    "sl_settings= VBox([Label('Configure Experiments'),\n",
    "                   Label(' '),\n",
    "                   iterations,\n",
    "                   InitSampCon_container,\n",
    "                   Label(' '),\n",
    "                   Label(' '),\n",
    "                   Label('Configure Algorithm'),\n",
    "                   Label(' '),\n",
    "                   custom_container,\n",
    "                   select_model,\n",
    "                   strategy_container,\n",
    "                   start_and_stop_sl_container,\n",
    "                   Label(' '),\n",
    "                   Label(' '),\n",
    "                   Label('SL Status'),\n",
    "                   out_perform_experiment,\n",
    "    \n",
    "])\n",
    "\n",
    "#initial_sample_size_text\n",
    "\n",
    "sl_results= VBox([\n",
    "    out_results_SL\n",
    "])\n",
    "\n",
    "\n",
    "sl_accordion=Accordion(children=[DataPre_sl,sl_settings,sl_results])\n",
    "sl_accordion.set_title(0,\"Configure Optimization\")\n",
    "sl_accordion.set_title(1,\"Sequential Learning\")\n",
    "sl_accordion.set_title(2,\"Results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Materials discovery tab \n",
    "#Plotting Results\n",
    "\n",
    "\n",
    "\n",
    "custom_container=VBox([HBox([])])\n",
    "results_container=VBox([HBox([])])\n",
    "\n",
    "DataPre_slA=VBox([\n",
    "        HBox([Label('Materials Data (Input)', font=('bold'), layout=Layout(width='50%', height='80px')),(feature_selector_application)]),\n",
    "        HBox([Label('Target Properties', font=('bold'),layout=Layout(width='50%', height='80px')),target_selection_application]),\n",
    "        box_targets,\n",
    "        HBox([Label('A-priori Information', font=('bold'),layout=Layout(width='50%', height='80px')),fixed_target_selection_application]),\n",
    "        box_fixed_targets,\n",
    "        #plottingDS,\n",
    "        custom_container,\n",
    "        Label(' '),\n",
    "        Label('Curiosity (to control the weight of model uncertainty on predicted utility)'),\n",
    "        Model_containerOne,\n",
    "        Model_containerTwo,\n",
    "        Label(' '),\n",
    "        Label('Click \"Make Prediction\" to sort materials by predicted utility'),\n",
    "        HBox([button_application]),\n",
    "        out_app,\n",
    "    \n",
    "])\n",
    "\n",
    "slA_accordion=Accordion(children=[DataPre_slA])\n",
    "slA_accordion.set_title(0,\"Configure Optimization\")\n",
    "# slA_accordion.set_title(1,\"Sequential Learning\")\n",
    "#slA_accordion.set_title(2,\"Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layout Tabs\n",
    "\n",
    "children = [\n",
    "    accordion_box, \n",
    "    VBox([toggle, out]),\n",
    "    plotting,\n",
    "    sl_accordion,\n",
    "    slA_accordion,\n",
    "    \n",
    "   ]\n",
    "\n",
    "tab.children = children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Naming Tabs\n",
    "\n",
    "tab.set_title(0, \"üóÇ Upload\")\n",
    "tab.set_title(1, \"üîé Data Info\")\n",
    "tab.set_title(2, \"üìä Design Space Explorer\")\n",
    "tab.set_title(3, \"ü§ñ Benchmarking\")\n",
    "tab.set_title(4, \"üë©‚Äçüî¨ Materials Discovery\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Utility Methods\n",
    "def decide_max_or_min(source,columns,dataframe):\n",
    "        row_list=[source.children[decide].children[0].value for decide in range(len(columns))]\n",
    "        \n",
    "    \n",
    "        for column in range(len(columns)):\n",
    "                            if (row_list[column] == \"minimize\"):\n",
    "                                \n",
    "                                dataframe[columns[column]]=dataframe[columns[column]]*(-1)\n",
    "                            \n",
    "        return dataframe\n",
    "                                \n",
    "                                \n",
    "        \n",
    "        \n",
    "                              \n",
    "                                \n",
    "                                \n",
    "def extend(list_of_2dms_arrays_to_extend):\n",
    "    np_array=np.array(list_of_2dms_arrays_to_extend)\n",
    "    max_cols=max(map(len,np_array))\n",
    "    result_list=[]\n",
    "    for i in np_array:\n",
    "                    if(len(i) == max_cols):\n",
    "                        result_list.append(i)\n",
    "                    elif (len(i) != max_cols):\n",
    "                        how_often=max_cols-len(i)\n",
    "                        matrix_to_extend=np.tile(i[:][-1], (how_often, 1))\n",
    "                        i=np.concatenate((i, matrix_to_extend))\n",
    "                        result_list.append(i)\n",
    "                    \n",
    "   \n",
    "    return result_list\n",
    "\n",
    "    \n",
    "           \n",
    "def flatten_list(nested_list):\n",
    "    for sublist in nested_list:\n",
    "        flatlist=[element for element in sublist]  \n",
    "    return flatlis\n",
    "\n",
    "\n",
    "\n",
    "def content_parser(source):\n",
    "    if source.value == {}:\n",
    "        \"\"\"with out:\n",
    "            out.clear_output\n",
    "            display(Markdown('No CSV loaded'))\n",
    "            #print('No CSV loaded')    \"\"\"\n",
    "    else:\n",
    "        from io import StringIO\n",
    "        typ, content = \"\", \"\"\n",
    "        up_value = source.value\n",
    "        for i in up_value.keys():\n",
    "            typ = up_value[i][\"metadata\"][\"type\"]\n",
    "            \n",
    "            if typ == \"text/csv\" or typ == \"application/vnd.ms-excel\":\n",
    "                content = up_value[i][\"content\"]\n",
    "                content_str = str(content, 'utf-8')\n",
    "\n",
    "                if eraser.value != {}: \n",
    "                    for val in eraser.value:\n",
    "                        if val == \"tab\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        elif val ==\"%\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        else:\n",
    "                            content_str = content_str.replace(val,\"\")\n",
    "                if content_str != \"\":\n",
    "                    str_io = StringIO(content_str) \n",
    "                    return str_io\n",
    "            \n",
    "                \n",
    "            \n",
    "def df_converter():\n",
    "    content = content_parser(up)\n",
    "    \n",
    "    up_value = up.value\n",
    "    for i in up_value.keys():\n",
    "            typ = up_value[i][\"metadata\"][\"type\"]\n",
    "            if(typ==\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"):\n",
    "                main_key=list(up.value.keys())\n",
    "                if(main_key):\n",
    "                    return pd.read_excel(up.value.get(main_key[0]).get('content'))\n",
    "        \n",
    "            else:\n",
    "                if content is not None:\n",
    "                        df = pd.read_csv(content, sep=delim.value, index_col=False, skiprows=rows.value,decimal=delim_dec.value)\n",
    "                        df=df.apply(pd.to_numeric,errors=\"ignore\")\n",
    "                        return df\n",
    "                else:\n",
    "                    return None\n",
    "def preview():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('Selected Targets'))\n",
    "        \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "            \n",
    "def upload():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is how your uploaded data looks like:'))\n",
    "       \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "            x_axis.options = df.columns\n",
    "            y_axis.options = df.columns\n",
    "            feature_selector.options= df.columns\n",
    "            feature_selector_application.options= df.columns\n",
    "            \n",
    "            select_x.options=df.columns\n",
    "            select_y.options=df.columns\n",
    "            select_size.options=df.columns\n",
    "            select_hue.options=df.columns\n",
    "            selector_plot_variable.options=df.columns\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "            \n",
    "            \n",
    "def create_download_link( df, title, filename): \n",
    "    import base64\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = html_buttons = '''<html>\n",
    "    <head>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    </head>\n",
    "    <body>\n",
    "    <a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-warning\">{title}</button>\n",
    "    </a>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    html_button = html_buttons.format(payload=payload,filename=filename,title=title)\n",
    "    return HTML(html_button)\n",
    "\n",
    "            \n",
    "            \n",
    "def desc():\n",
    "    info_level = toggle.value\n",
    "    if info_level != {}:\n",
    "        df = df_converter()\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown('\\n Data {} \\n'.format(\n",
    "                info_level)))\n",
    "            if df is not None:\n",
    "                if info_level == 'Info  ':\n",
    "                    df.info()\n",
    "                elif info_level == 'Stats  ':\n",
    "                    display(Markdown(df.describe().to_markdown()))\n",
    "                elif info_level == 'Preview  ':\n",
    "                    display(Markdown(df.head(10).to_markdown()))\n",
    "                else:\n",
    "                    display(Markdown('Configuration is wrong/missing...'))\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Methods\n",
    "import seaborn as sns\n",
    "\n",
    "def plot():\n",
    "    graph = graph_type.value\n",
    "    if graph==\"Scatter\":\n",
    "        plot_scatter()\n",
    "    elif graph==\"Correlation Heatmap\":\n",
    "            plot_heat()\n",
    "    elif graph==\"Scatter Matrix\":\n",
    "            plot_pairwise()\n",
    "          \n",
    "        \n",
    "def plot_pairwise():\n",
    "    df =confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        sns.pairplot(df)\n",
    "        plt.show()\n",
    "\n",
    "def plot_heat():\n",
    "    df = confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        corr = df.corr()\n",
    "        plt.figure(figsize=(12,7))\n",
    "        sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "        b, t = plt.ylim()\n",
    "        plt.ylim(b+0.5, t-0.5)\n",
    "        plt.title(\"Feature Correlation Heatmap\")\n",
    "        plt.show()\n",
    "            \n",
    "def plot_scatter():\n",
    "    data=df_converter()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        fig, ax = plt.subplots(figsize=(12,7))\n",
    "        #not generic\n",
    "        sns.scatterplot(y=select_y.value, x=select_x.value, hue=select_hue.value, size=select_size.value, data=data, ax=ax, sizes=(50, 300))\n",
    "        ax.set_title(select_y.value+ \"vs\"+ select_x.value)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "        plt.show()\n",
    "        plt.close(fig)  \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def confirm_options():\n",
    "    items=box_features_slider.children\n",
    "    df = df_converter()\n",
    "    Y = df.loc[:,df.columns.isin(target_selection.value)]\n",
    "    \n",
    "    for slider in items:\n",
    "            unt_grenz= slider.value[0]/100\n",
    "            ob_grenz= slider.value[1]/100\n",
    "            Y = Y[(Y >= Y.quantile(unt_grenz) ) & (Y <= Y.quantile(ob_grenz))]\n",
    "            Y= Y.dropna()\n",
    "    \n",
    "    return Y   \n",
    "\n",
    "\n",
    "def confirm_features(source):\n",
    "    df = df_converter()\n",
    "    train = source.value\n",
    "    \n",
    "    target_selection.options=df.columns[~df.columns.isin(feature_selector.value)]\n",
    "    \n",
    "    target_selection_application.options=df.columns[~df.columns.isin(feature_selector_application.value)]\n",
    "    \n",
    "    fixed_target_selection.options=df.columns[~df.columns.isin(target_selection.value)& ~df.columns.isin(feature_selector.value)]\n",
    "    fixed_target_selection_application.options=df.columns[~df.columns.isin(target_selection_application.value)& ~df.columns.isin(feature_selector_application.value)]\n",
    "    \n",
    "    train = df.columns[df.columns.isin(source.value)]\n",
    "    \n",
    "    return train\n",
    "\n",
    "\n",
    "def confirm_var():\n",
    "    df= df_converter()\n",
    "    selection = list(selector_plot_variable.value)\n",
    "    var = df[selection]\n",
    " \n",
    "    return var\n",
    "\n",
    "  \n",
    "def confirm_target(source):\n",
    "    #target_selection\n",
    "    df = df_converter()\n",
    "    target = df.columns[df.columns.isin(source.value)]\n",
    "    \n",
    "    fixed_target_selection.options=df.columns[~df.columns.isin(source.value)& ~df.columns.isin(feature_selector.value)]\n",
    "    \n",
    "    fixed_target_selection_application.options=df.columns[~df.columns.isin(target_selection_application.value)& ~df.columns.isin(feature_selector_application.value)]\n",
    "    \n",
    "    \n",
    "    return target \n",
    "\n",
    "\n",
    "\n",
    "def confirm_fixed_target(source):\n",
    "    df = df_converter()\n",
    "    fixed_target = df.columns[df.columns.isin(source.value)]\n",
    "    \n",
    "    return fixed_target\n",
    "\n",
    "def confirm_strategy():\n",
    "    strategy= select_strategy.value\n",
    "    if strategy != {}:\n",
    "            custom_container.children=[]\n",
    "            return select_strategy.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slider_for_dist_quantile():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist]\n",
    "    \n",
    "def create_slider_for_dist_quantile_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist, slider_of_for_std]\n",
    "        \n",
    "def create_slider_for_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_std]\n",
    "      \n",
    "    \n",
    "def create_dynamically_elems(targets):\n",
    "    \n",
    "    radiobuttons = [RadioButtons(\n",
    "    options=['maximize', 'minimize'],\n",
    "    value='maximize', \n",
    "    description=feature,\n",
    "    disabled=False\n",
    "    )\n",
    "    for feature in targets]\n",
    "    \n",
    "    \n",
    "    \n",
    "    weights = [FloatText(\n",
    "    value=1.,\n",
    "    continuous_update=True,\n",
    "    description=\"weight \"+feature,\n",
    "    disabled=False)\n",
    "    for feature in targets]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    weights_np=np.array(weights)\n",
    "    \n",
    "    radiobuttons_np=np.array(radiobuttons)\n",
    "\n",
    "    return radiobuttons_np,weights_np\n",
    "    \n",
    "    \n",
    "    \n",
    "def create_dynamically_checkboxes(targets):\n",
    "    radiobuttons = [RadioButtons(\n",
    "    options=['maximize', 'minimize'],\n",
    "    value='maximize', \n",
    "    description=feature,\n",
    "    disabled=False\n",
    "    )\n",
    "    for feature in targets]\n",
    "    \n",
    "    checkboxes = [Checkbox(\n",
    "    value=False,\n",
    "    description='Check to use treshhold',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "    \n",
    "    for feature in targets]\n",
    "    \n",
    "    \n",
    "    slider = [FloatText(\n",
    "    value=np.max(df_converter()[feature].to_numpy()),\n",
    "    continuous_update=True,\n",
    "    description=feature,\n",
    "    disabled=False)\n",
    "    \n",
    "    for feature in targets]\n",
    "    \n",
    "    \n",
    "    weights = [FloatText(\n",
    "    value=1.,\n",
    "    continuous_update=True,\n",
    "    description=\"weight \"+feature,\n",
    "    disabled=False)\n",
    "    for feature in targets]\n",
    "    \n",
    "    weights_np=np.array(weights)\n",
    "    slider_np=np.array(slider)\n",
    "    radiobuttons_np=np.array(radiobuttons)\n",
    "    checkboxes_np=np.array(checkboxes)\n",
    "    \n",
    "    return radiobuttons_np,slider_np,checkboxes_np,weights_np\n",
    "    \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Req. dev. cycle (mean)','Req. dev. cycle (std)','Req. dev. cycle (90%)',\n",
    "                                  'Req. dev. cycle (max)','5 cycle perf.','10 cycle perf.','Batch size','Algorithm','Utlity function','œÉ factor',\n",
    "                                  'qant. (distance utility)','# SL runs','Initial sample','# of samples in the DS',\n",
    "                                  '# Features','# Targets', 'Target threshold','Features name','Targets name','A-priori information',\n",
    "                                  'Req. experiments (list)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "class targets():\n",
    "    checkboxes=None\n",
    "    radiobuttons=None\n",
    "    slider=None\n",
    "    not_stand_df=None\n",
    "    idx=None\n",
    "    min_at=set()\n",
    "    minimize=False\n",
    "    idxs=[]\n",
    "    \n",
    "    def __init__(self,container,selection,confirm_func,create_elem_func):\n",
    "        self.container=container\n",
    "        self.selection=selection\n",
    "        \n",
    "        self.confirm_func=confirm_func\n",
    "        self.create_elem_func=create_elem_func\n",
    "        \n",
    "        \n",
    "    def on_selection_change(self,change):\n",
    "        self.confirm_func(self.selection)\n",
    "        self.not_stand_df=df_converter()\n",
    "        self.container.children=()\n",
    "        selection_as_list=list(self.selection.value)\n",
    "        \n",
    "        if(self.create_elem_func==create_dynamically_checkboxes):\n",
    "            \n",
    "            self.radiobuttons,self.slider,self.checkboxes,self.weights=self.create_elem_func(selection_as_list)\n",
    "            for row in range(len(self.radiobuttons)):\n",
    "            \n",
    "                self.container.children=(*self.container.children,HBox([self.radiobuttons[row],self.checkboxes[row],self.slider[row],self.weights[row]]))\n",
    "                self.radiobuttons[row].observe(functools.partial(self.on_radiobutton_changed,row),names='value')\n",
    "                self.checkboxes[row].observe(functools.partial(self.on_checkbox_checked,row),names='value')\n",
    "                self.slider[row].observe(functools.partial(self.on_texfield_typed,row),names='value')\n",
    "        else:\n",
    "            \n",
    "            self.radiobuttons,self.weights=self.create_elem_func(selection_as_list)\n",
    "            \n",
    "            for row in range(len(self.radiobuttons)):\n",
    "                \n",
    "                self.container.children=(*self.container.children,HBox([self.radiobuttons[row],self.weights[row]]))\n",
    "                self.radiobuttons[row].observe(functools.partial(self.on_radiobutton_changed,row),names='value')\n",
    "\n",
    "\n",
    "     \n",
    "    def on_radiobutton_changed(self,row,change):\n",
    "                \n",
    "        if(self.radiobuttons[row].value==\"minimize\"):\n",
    "            \n",
    "            self.min_at.add(list(self.selection.value)[row])\n",
    "            \n",
    "            self.minimize=True\n",
    "            \n",
    "        else:\n",
    "            self.min_at.remove(list(self.selection.value)[row])\n",
    "            \n",
    "            self.minimize=False\n",
    "            \n",
    "        if(self.create_elem_func==create_dynamically_checkboxes):\n",
    "            self.on_checkbox_checked(row,change)\n",
    "        \n",
    "    def on_texfield_typed(self,row,change):\n",
    "        self.checkboxes[row].value=False\n",
    "        \n",
    "    def on_checkbox_checked(self,row,change):\n",
    "       \n",
    "        selection_as_list=list(self.selection.value)\n",
    "        if(self.checkboxes[row].value==True):\n",
    "            \n",
    "            idx=None\n",
    "            \n",
    "            max_df=np.max(df_converter()[selection_as_list[row]].to_numpy())\n",
    "            min_df=np.min(df_converter()[selection_as_list[row]].to_numpy())\n",
    "               \n",
    "            \n",
    "            if(self.slider[row].value>max_df):\n",
    "                self.slider[row].value=max_df\n",
    "            \n",
    "            if(self.slider[row].value < min_df):\n",
    "                self.slider[row].value=min_df\n",
    "            \n",
    "            \n",
    "            if(self.minimize==True):\n",
    "                df_mask=self.not_stand_df[selection_as_list[row]]<self.slider[row].value\n",
    "            else:\n",
    "                df_mask=self.not_stand_df[selection_as_list[row]]>=self.slider[row].value\n",
    "                \n",
    "                \n",
    "            temp=self.not_stand_df\n",
    "            \n",
    "            if(len(temp[df_mask])==0):\n",
    "                print(\"selection false,max min for this feature in this combination is: or change other targets\")\n",
    "            else:\n",
    "                temp = self.not_stand_df[df_mask]\n",
    "                idx = temp[df_mask].index\n",
    "                \n",
    "            #check if there is an old idx for this feature  \n",
    "            \n",
    "            for idx_tuples in self.idxs:\n",
    "                if(idx_tuples[0]==selection_as_list[row]):\n",
    "                    self.idxs.remove(idx_tuples)\n",
    "            \n",
    "            #append new idx in list\n",
    "            \n",
    "            self.idxs.append((selection_as_list[row],idx))\n",
    "            \n",
    "        \n",
    "        \n",
    "        if(self.checkboxes[row].value==False):\n",
    "             for idx_tuples in self.idxs:\n",
    "                if(idx_tuples[0]==selection_as_list[row]):\n",
    "                    self.idxs.remove(idx_tuples)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = targets(box_targets,target_selection,confirm_target,create_dynamically_checkboxes) \n",
    "ft = targets(box_fixed_targets,fixed_target_selection,confirm_fixed_target,create_dynamically_checkboxes)\n",
    "\n",
    "\n",
    "tA = targets(box_targets,target_selection_application,confirm_target,create_dynamically_elems) \n",
    "ftA = targets(box_fixed_targets,fixed_target_selection_application,confirm_fixed_target,create_dynamically_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Benchmarking\n",
    "class sequential_learning:\n",
    "    \n",
    "    \n",
    "    dataframe = df_converter()\n",
    "    features_df=df_converter()\n",
    "    target_df=df_converter()\n",
    "    \n",
    "    min_distances_list=[]\n",
    "    \n",
    "    y_pred_dtr_mean=None\n",
    "    y_pred_dtr_std=None\n",
    "    y_pred_dtr=None\n",
    "    SampIdx=None\n",
    "    PredIdx=None\n",
    "    treshIdx=None\n",
    "    \n",
    "    index_sum_randomized=None\n",
    "    rand_tars=[]\n",
    "    rand_fixed_tars=[]\n",
    "   \n",
    "    def __init__(self,dataframe,init_sample_size,batch_size, target_treshhold,\n",
    "                 number_of_executions,sigma,distance,\n",
    "                 model,strategy,targets_idx,fixed_targets_idx):  #constructor\n",
    "        \n",
    "        self.dataframe= dataframe\n",
    "        self.init_sample_size=init_sample_size\n",
    "        self.batch_size=batch_size\n",
    "        self.target_treshhold = target_treshhold/100\n",
    "        self.number_of_executions=number_of_executions\n",
    "        self.tries_list=np.empty(number_of_executions)\n",
    "        self.tries_list_rand_pick=np.empty(number_of_executions)\n",
    "        self.sigma=sigma\n",
    "        self.distance=distance\n",
    "        self.model=model\n",
    "        self.strategy = strategy\n",
    "        self.targets_idx=targets_idx\n",
    "        self.fixed_targets_idx=fixed_targets_idx\n",
    "        \n",
    "        \n",
    "        \n",
    "    def apply_feature_selection_to_df(self,dataframe):\n",
    "        self.features_df = self.dataframe[confirm_features(feature_selector)]    \n",
    "    \n",
    "    def apply_target_selection_to_df(self,dataframe):\n",
    "        self.target_df= self.dataframe[confirm_target(target_selection)]    \n",
    "\n",
    "    #self werte return macht wenig sinn\n",
    "    def standardize_data(self):\n",
    "        dataframe_norm=(self.dataframe-self.dataframe.mean())/self.dataframe.std()\n",
    "        target_df_norm=(self.target_df-self.target_df.mean())/self.target_df.std()\n",
    "        features_df_norm=(self.features_df-self.features_df.mean())/self.features_df.std()\n",
    "        self.features_df=features_df_norm\n",
    "        self.target_df=target_df_norm\n",
    "        self.dataframe=dataframe_norm\n",
    "        return self.features_df, self.target_df, self.dataframe\n",
    "        \n",
    "\n",
    "\n",
    "    def init_sampling(self):\n",
    "        \n",
    "        targets = confirm_target(target_selection)\n",
    "\n",
    "        fixed_targets=confirm_fixed_target(fixed_target_selection)\n",
    "\n",
    "        df_unnorm=df_converter()\n",
    "        df=(df_unnorm-df_unnorm.mean())/(df_unnorm.std())\n",
    "        \n",
    "        sum_ = self.dataframe[targets].sum(axis=1).to_frame()+self.dataframe[fixed_targets].sum(axis=1).to_frame()\n",
    "                \n",
    "        treshholded_idx=self.check_input_variables()\n",
    "        \n",
    "        checked_targets=[]\n",
    "        \n",
    "           \n",
    "        if(treshholded_idx):\n",
    "                    \n",
    "                    \n",
    "                    for row in range(len(t.checkboxes)) :\n",
    "                        \n",
    "                        if (t.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(t.radiobuttons[row].description)\n",
    "                    \n",
    "                    for row in range(len(ft.checkboxes)):\n",
    "                        if (ft.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(ft.radiobuttons[row].description)\n",
    "                    \n",
    "                    if not(len(checked_targets)==len(t.checkboxes)+len(ft.checkboxes)):\n",
    "                       \n",
    "                \n",
    "                        sum_without_checked_targets=df.drop(columns=checked_targets).sum(axis=1)\n",
    "        \n",
    "                        targ_q = quantile_tar_slider.value/100\n",
    "                        targ_q_t= sum_without_checked_targets.iloc[treshholded_idx].quantile(targ_q)\n",
    "                        \n",
    "                        \n",
    "                        tempIndex=np.where(sum_without_checked_targets.iloc[treshholded_idx] >= targ_q_t )\n",
    "                        tempIndex=tempIndex[0]\n",
    "                        \n",
    "                        \n",
    "                        Index_c=sum_without_checked_targets.iloc[treshholded_idx].iloc[tempIndex].index\n",
    "                        \n",
    "                        #Sample IDX\n",
    "                        Index_samp=np.delete(sum_.index, Index_c)\n",
    "                        \n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        Index_c=treshholded_idx\n",
    "                        Index_samp=np.delete(sum_.index, treshholded_idx)\n",
    "\n",
    "                    \n",
    "                   \n",
    "        else:\n",
    "            targ_q = quantile_tar_slider.value/100\n",
    "            targ_q_t= sum_.quantile(targ_q)\n",
    "                    \n",
    "            Index_samp=np.where(sum_ < targ_q_t )\n",
    "            Index_samp=Index_samp[0]\n",
    "                    \n",
    "            Index_c=np.where(sum_ >= targ_q_t )\n",
    "            Index_c=Index_samp[0]\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        init_sample_set = np.ones((0,self.init_sample_size))\n",
    "        \n",
    "        for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    init_sample_set=np.vstack([init_sample_set, random.choice(Index_samp,self.init_sample_size)])\n",
    "\n",
    "        return init_sample_set\n",
    "                                         \n",
    "    def start_sequential_learning(self):\n",
    "            \n",
    "            self.tries_list=np.empty(self.number_of_executions)\n",
    "            self.tries_list.fill(np.nan)\n",
    "            self.tries_list_rand_pick=np.empty(self.number_of_executions)\n",
    "            self.tries_list_rand_pick.fill(np.nan)\n",
    "            \n",
    "            \n",
    "            distances=[]\n",
    "            targt_perfs=[]\n",
    "            \n",
    "            fixed_targets=[]\n",
    "            targets=[]\n",
    "            \n",
    "            current_distances_list=[]   \n",
    "            current_targt_perf_list=[]\n",
    "            \n",
    "            \n",
    "            with out_perform_experiment:\n",
    "                    display(Markdown('Sequential Learning is running...'))\n",
    "\n",
    "\n",
    "            \n",
    "            global result_df   \n",
    "            \n",
    "            \n",
    "            self.dataframe=decide_max_or_min(box_targets,confirm_target(target_selection),self.dataframe)\n",
    "            self.dataframe=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),self.dataframe)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            init_sample_set=self.init_sampling()\n",
    "            fixed_targets_index=confirm_fixed_target(fixed_target_selection)\n",
    "            \n",
    "            \n",
    "            sum_ = self.dataframe[confirm_target(target_selection)].sum(axis=1).to_frame()+self.dataframe[fixed_targets_index].sum(axis=1).to_frame()\n",
    "            \n",
    "            targ_q_t= sum_.quantile(self.target_treshhold) \n",
    "            schwellwert=sum_.quantile(self.target_treshhold)\n",
    "            Index_c=np.where(sum_ >= schwellwert )\n",
    "            \n",
    "            Index_c=Index_c[0]\n",
    "            \n",
    "            \n",
    "\n",
    "            for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    self.perform_random_pick(i)\n",
    "                    \n",
    "                    self.SampIdx=init_sample_set[i].astype(int)\n",
    "                    \n",
    "                    self.PredIdx=self.dataframe\n",
    "                    \n",
    "                    self.PredIdx = self.PredIdx.drop(self.PredIdx.index[self.SampIdx]).index\n",
    "                    \n",
    "                    self.decide_model(self.model)\n",
    "                    \n",
    "                    self.tries_list[i]=0\n",
    "                    #self.init_sample_size\n",
    "                    \n",
    "                    distance=distance_matrix(self.dataframe.iloc[self.SampIdx],self.dataframe.iloc[self.treshIdx])\n",
    "                    \n",
    "                    distance=distance.min()\n",
    "                    \n",
    "                    current_distances_list=[distance]\n",
    "                    \n",
    "                    #max value summe\n",
    "                    targt_perf=sum_.loc[self.SampIdx].max().item()\n",
    "                    current_targt_perf_list=[targt_perf] \n",
    "\n",
    "                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                    \n",
    "                    \n",
    "                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                    \n",
    "                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                    \n",
    "                    current_fixed_target_list=np.array(best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()[0])\n",
    "                    current_prediction_target=np.array(best_value[confirm_target(target_selection)].to_numpy()[0])\n",
    "                    \n",
    "                    \n",
    "                    while np.any(np.in1d(self.SampIdx,self.treshIdx ))== False:\n",
    "                                     \n",
    "                                   \n",
    "                                    batch_size=self.batch_size\n",
    "                                    \n",
    "                                    for batch in range(batch_size):\n",
    "                                        \n",
    "                                        if(self.SampIdx.size<batch_size):\n",
    "                                            batch_size=self.SampIdx.size\n",
    "                                            \n",
    "                                            self.update_strategy(self.strategy)\n",
    "                                        else:\n",
    "                                            self.update_strategy(self.strategy)\n",
    "                                    \n",
    "                                    \n",
    "                                    #Train Model\n",
    "                                    self.decide_model(self.model)\n",
    "\n",
    "                                    distance= distance_matrix(self.dataframe.iloc[self.SampIdx],self.dataframe.iloc[self.treshIdx])\n",
    "                                    \n",
    "                                    distance=distance.min()\n",
    "                                    \n",
    "                                    current_distances_list.append(distance)\n",
    "                                    \n",
    "                                    targt_perf=sum_.loc[self.SampIdx].max().values.tolist()\n",
    "                                    targt_perf=max(targt_perf)\n",
    "\n",
    "                                    current_targt_perf_list.append(targt_perf)\n",
    "                                    \n",
    "                                    \n",
    "                                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                                    \n",
    "                                    current_prediction_target=np.vstack([current_prediction_target,best_value[confirm_target(target_selection)].to_numpy()[0]])\n",
    "                                    current_fixed_target_list=np.vstack([current_fixed_target_list,best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()[0]])\n",
    "                                    \n",
    "        \n",
    "                                    self.tries_list[i]=self.tries_list[i]+1   \n",
    "\n",
    "                    distances.append(current_distances_list)\n",
    "                    targt_perfs.append(current_targt_perf_list)\n",
    "                    \n",
    "                    \n",
    "                    best_value=df_converter().iloc[self.treshIdx] \n",
    "                    \n",
    "                    current_prediction_target=np.vstack([current_prediction_target,best_value[confirm_target(target_selection)].to_numpy()[0]])\n",
    "                    current_fixed_target_list=np.vstack([current_fixed_target_list,best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()[0]])\n",
    "\n",
    "                    \n",
    "                    targets.append(current_prediction_target)\n",
    "                    fixed_targets.append(current_fixed_target_list)\n",
    "                    \n",
    "\n",
    "## Live Plots \n",
    "                \n",
    "                    with out_perform_experiment:\n",
    "                        fig1,axs = plt.subplots(1,2,figsize=(15, 6))\n",
    "                        axs[0].set_title('Optimization progress in input space')\n",
    "                        axs[0].set_xlabel('development cycles')\n",
    "                        axs[0].set_ylabel(\"Minimum distance from sampled data to target\")\n",
    "                        axs[0].axhline(y=0, color='k', linestyle=':',label='Target')\n",
    "                        axs[0].legend()\n",
    "\n",
    "                        axs[1].set_title('Optimization progress in output space')\n",
    "                        axs[1].set_xlabel('development cycles')\n",
    "                        axs[1].set_ylabel(\"Maximum sampled property\")\n",
    "                        axs[1].axhline(y=targ_q_t.values, color='k', linestyle=':',label='Target (normalized)')\n",
    "                        axs[1].legend()\n",
    "\n",
    "                    \n",
    "                        #Plotting\n",
    "                        for runs in range(len(distances)):\n",
    "                         \n",
    "                            axs[0].plot(distances[runs],linewidth=8, alpha=0.4)\n",
    "\n",
    "                    for runs in range(len(targt_perfs)):\n",
    "                        \n",
    "                        \n",
    "                        axs[1].plot(targt_perfs[runs],linewidth=8, alpha=0.4)\n",
    "                       \n",
    "                        \n",
    "                    with out_perform_experiment:\n",
    "                            out_perform_experiment.clear_output(wait=True)\n",
    "                            time.sleep(1.0)\n",
    "                            fig2=plt.figure(figsize=(15, 5))\n",
    "                            plt.xlabel('Number of required Experiments')\n",
    "                            plt.ylabel(\"Frequency\")\n",
    "                            plt.title(\"Performance histogram for %s with strategy %s \"%(self.model,self.strategy))\n",
    "                            #plt.hist([self.tries_list,self.tries_list_rand_pick],bins=len(self.tries_list),label=['SL Tries', 'Random Pick Tries'])         \n",
    "                            plt.hist([self.tries_list_rand_pick],range=(1, len(self.features_df)),label=['Random Process'],alpha=0.4)         \n",
    "                            plt.hist([self.tries_list],label=['SL'],range=(1, len(self.features_df)),alpha=0.4)         \n",
    "                            plt.legend()\n",
    "\n",
    "                            plt.show()\n",
    "                            #plt.close(fig2)\n",
    "                            \n",
    "                    with out_perform_experiment:\n",
    "                        display(Markdown('current iteration {}'.format(i)))\n",
    "                        display(Markdown(\" \"))\n",
    "                               \n",
    "                            #self.number_of_executions\n",
    "        #Extend values of perfs\n",
    "            lengths_of_perfs=[]\n",
    "            for runs in range(len(targt_perfs)):\n",
    "                            current_len_of_perf=len(targt_perfs[runs])\n",
    "                            lengths_of_perfs.append(current_len_of_perf)\n",
    "\n",
    "            for runs in range(len(targt_perfs)):\n",
    "                                    if(len(targt_perfs[runs])!=max(lengths_of_perfs)):\n",
    "                                        size_of_values_to_add =max(lengths_of_perfs)-len(targt_perfs[runs])\n",
    "                                        targt_perfs[runs].extend(np.full(size_of_values_to_add, max(targt_perfs[runs])))\n",
    "\n",
    "            targt_perfs_as_array=np.array(targt_perfs)\n",
    "            mean_performances=np.mean(targt_perfs_as_array,axis=0)\n",
    "            \n",
    "            rel_perform_after_5=1.0\n",
    "            rel_perform_after_10=1.0\n",
    "            \n",
    "            max_performance=np.max(sum_)\n",
    "            \n",
    "            min_performance=np.min(sum_)\n",
    "        \n",
    "            \n",
    "           \n",
    "            \n",
    "            if(len(mean_performances) > 5 and len(mean_performances) <10):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                \n",
    "            if(len(mean_performances)==5):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                \n",
    "            if(len(mean_performances)>=10):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                perform_after_10=mean_performances[9]\n",
    "                print(perform_after_10/max_performance)\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                rel_perform_after_10=(perform_after_10-min_performance)/(max_performance-min_performance)\n",
    "            \n",
    "\n",
    "\n",
    "            if self.strategy=='MEI (exploit)':\n",
    "                self.sigma=0\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MU (explore)':\n",
    "                self.sigma=1\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MLI (explore & exploit)':\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MEID (exploit)':\n",
    "                self.sigma=0\n",
    "            \n",
    "                \n",
    "            ##Appending Performance intensiv --> List comprehension\n",
    "            to_append=([np.mean(self.tries_list),np.std(self.tries_list),np.quantile(self.tries_list,0.90),\n",
    "                        np.quantile(self.tries_list,1),rel_perform_after_5,rel_perform_after_10,self.batch_size,self.model, self.strategy,self.sigma,self.distance,\n",
    "                        self.number_of_executions,self.init_sample_size,len(self.dataframe.index),len(confirm_features(feature_selector)),\n",
    "                        len(confirm_target(target_selection)),self.target_treshhold,\n",
    "                        confirm_features(feature_selector).tolist(),confirm_target(target_selection).tolist(),confirm_fixed_target(fixed_target_selection).tolist(),self.tries_list])\n",
    "\n",
    "####SL-Results\n",
    "            with out_results_SL: \n",
    "                    out_results_SL.clear_output(wait=True)\n",
    "                    display(Markdown('#### Performance summary:'))\n",
    "                    display(Markdown('req. development cycles with optimzation (mean):  {} '.format(\n",
    "                    np.mean(self.tries_list))))\n",
    "                    display(Markdown(\"req. development cycles  without optimzation (mean): {}\".format(np.mean(self.tries_list_rand_pick))))\n",
    "\n",
    "            with out_results_SL:\n",
    "                    \n",
    "                    display(Markdown(\" \"))\n",
    "                    display(Markdown('#### Log:'))\n",
    "                    display(Markdown(\" \"))\n",
    "                    a_series = pd.Series(to_append, index = result_df.columns)\n",
    "                    result_df= result_df.append(a_series, ignore_index=True)\n",
    "                    display(Markdown(result_df.to_markdown()))\n",
    "                    display((create_download_link(result_df,'Download Log-File','results_sl')))\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "#Plot targets\n",
    "### Fixed Targets\n",
    "            if(len(confirm_fixed_target(fixed_target_selection).values.tolist())>0):\n",
    "                    anzahl_plots=len(fixed_target_selection.value)\n",
    "                    fig3,axs_fixed = plt.subplots(anzahl_plots,figsize=(8,5*anzahl_plots),squeeze=False)\n",
    "                    axs_fixed=axs_fixed.flatten()\n",
    "                    \n",
    "                    fixed_targets_extended=extend(fixed_targets)\n",
    "                    \n",
    "                    mean_fixed_targets_extended=np.mean(fixed_targets_extended,axis=0)\n",
    "                    \n",
    "                    fixed_rand_extended=extend(self.rand_fixed_tars)\n",
    "                    \n",
    "                    mean_fixed_rand_extended=np.mean(fixed_rand_extended,axis=0)\n",
    "\n",
    "#Plot fixed targets\n",
    "                    \n",
    "                    for fixed_target in range(anzahl_plots):\n",
    "                                axs_fixed[fixed_target].set_title('Optimization progress for %s'%(confirm_fixed_target(fixed_target_selection)[fixed_target]))\n",
    "                                axs_fixed[fixed_target].set_xlabel('development cycles')\n",
    "                                axs_fixed[fixed_target].set_ylabel(\"Best sampled property\")\n",
    "                                \n",
    "                                axs_fixed[fixed_target].set_xlim([0,len(mean_fixed_targets_extended[:,0])-1])\n",
    "\n",
    "                    for one_tar in range(anzahl_plots):  \n",
    "\n",
    "                            axs_fixed[one_tar].plot(mean_fixed_targets_extended[:,one_tar],linewidth=8, alpha=0.9, color='k',label='With optimization')\n",
    "                            axs_fixed[one_tar].plot(mean_fixed_rand_extended[:,one_tar],linewidth=8, alpha=0.9, color='g',label='Without optimization')\n",
    "                            axs_fixed[one_tar].axvline(x=round(np.mean(self.tries_list)-self.init_sample_size), color='k', linestyle=':',label='Average dev. cycles to success')\n",
    "                            axs_fixed[one_tar].legend()\n",
    "\n",
    "                    for sl_run in range(len(fixed_targets)):                            \n",
    "                                for one_tar in range(anzahl_plots):\n",
    "                                            axs_fixed[one_tar].plot(fixed_targets[sl_run][:,one_tar],linewidth=2, alpha=0.1,color='k')\n",
    "                    \n",
    "                    \n",
    "                     \n",
    "                    \n",
    "            with out_results_SL:    \n",
    "\n",
    "                display(Markdown(\" \"))\n",
    "                display(Markdown('#### Result plots:'))\n",
    "                    \n",
    "                anzahl_plots=len(target_selection.value)\n",
    "                targets_extended=extend(targets)\n",
    "                mean_targets_extended=np.mean(targets_extended,axis=0)\n",
    "                fig4,axs_pred = plt.subplots(anzahl_plots,figsize=(8,5*anzahl_plots), squeeze=False)\n",
    "                \n",
    "                plt.setp(axs_pred, xlim=[0,len(mean_targets_extended[:,0])-1])\n",
    "                \n",
    "                axs_pred=axs_pred.flatten()\n",
    "                rand_extended=extend(self.rand_tars)\n",
    "                \n",
    "                mean_rand_extended=np.mean(rand_extended,axis=0)\n",
    "                \n",
    "                for pred_target in range(anzahl_plots):\n",
    "                            axs_pred[pred_target].set_title('Optimization progress for %s'%(confirm_target(target_selection)[pred_target]))\n",
    "                            axs_pred[pred_target].set_xlabel('development cycles')\n",
    "                            axs_pred[pred_target].set_ylabel(\"Best sampled property\")\n",
    "\n",
    "                \n",
    "                for pred_target in range(anzahl_plots):  \n",
    "    \n",
    "                        axs_pred[pred_target].plot(mean_targets_extended[:,pred_target],linewidth=8, alpha=0.9, color='k',label='With optimization')\n",
    "                        axs_pred[pred_target].plot(mean_rand_extended[:,pred_target],linewidth=8, alpha=0.9, color='g',label='Without optimization')\n",
    "                        axs_pred[pred_target].axvline(x=round(np.mean(self.tries_list)-self.init_sample_size), color='k', linestyle=':',label='Average dev. cycles to success')\n",
    "                        axs_pred[pred_target].legend()\n",
    "                \n",
    "                \n",
    "               \n",
    "                for sl_run in range(len(targets)):                            \n",
    "                            for one_tar in range(anzahl_plots):\n",
    "                                        axs_pred[one_tar].plot(targets[sl_run][:,one_tar],linewidth=2, alpha=0.1,color='k')      \n",
    "                                        \n",
    "                \n",
    "                \n",
    "                plt.show()\n",
    "                                        \n",
    "            \n",
    "            \n",
    "                           \n",
    "    def perform_random_pick(self,acutal_iter):\n",
    "        \n",
    "        sum_ = self.dataframe[confirm_target(target_selection)].sum(axis=1).to_frame()+self.dataframe[confirm_fixed_target(fixed_target_selection)].sum(axis=1).to_frame()\n",
    "        index_sum=sum_.index.to_numpy()\n",
    "        index_sum_randomized=np.random.choice(index_sum,len(index_sum),False)\n",
    "        targ_q_t= sum_.quantile(self.target_treshhold)\n",
    "        self.tries_list_rand_pick[acutal_iter]=1\n",
    "\n",
    "        run=0\n",
    "        \n",
    "        best_value=df_converter().iloc[index_sum_randomized[run]]\n",
    "        \n",
    "        current_fixed_rand_tars=np.array(best_value[confirm_fixed_target(fixed_target_selection)].to_numpy())\n",
    "        current_pred_rand_tars=np.array(best_value[confirm_target(target_selection)].to_numpy())\n",
    "        \n",
    "        \n",
    "        while np.any(np.in1d(index_sum_randomized[run],self.treshIdx ))== False:\n",
    "            self.tries_list_rand_pick[acutal_iter]=self.tries_list_rand_pick[acutal_iter]+1 \n",
    "            temp_index=np.argmax(sum_.iloc[index_sum_randomized[0:run+1]]) \n",
    "            max_index=index_sum_randomized[temp_index]\n",
    "            best_value=df_converter().iloc[max_index]\n",
    "            current_pred_rand_tars=np.vstack([current_pred_rand_tars,best_value[confirm_target(target_selection)].to_numpy()])\n",
    "            current_fixed_rand_tars=np.vstack([current_fixed_rand_tars,best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()])\n",
    "            run=run+1\n",
    "        \n",
    "        temp_index=np.argmax(sum_.iloc[index_sum_randomized[0:run+1]]) \n",
    "        max_index=index_sum_randomized[temp_index]\n",
    "        best_value=df_converter().iloc[max_index]\n",
    "        current_pred_rand_tars=np.vstack([current_pred_rand_tars,best_value[confirm_target(target_selection)].to_numpy()])\n",
    "        current_fixed_rand_tars=np.vstack([current_fixed_rand_tars,best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()])\n",
    "        \n",
    "        self.rand_fixed_tars.append(current_fixed_rand_tars)\n",
    "        self.rand_tars.append(current_pred_rand_tars)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #Refactor idee: Model klasse mit name und checkbox description\n",
    "    def decide_model(self,model):\n",
    "        if model== 'AI-Model (lolo Random Forrest)':\n",
    "                    self.fit_RF_wJK()\n",
    "        elif model == 'Decision Trees (DT)':\n",
    "                    self.fit_DT_wJK()\n",
    "        elif model == 'Random Forrest (RFscikit)':\n",
    "                    self.fit_TE_wJK()\n",
    "        elif model == 'Statistics based model (Gaussian Process Regression)':\n",
    "                    self.fit_GP()\n",
    "                    \n",
    "            \n",
    "    def update_strategy(self, strategy):\n",
    "        if strategy=='MEI (exploit)':\n",
    "            self.updateIndexMEI()\n",
    "        elif strategy=='MU (explore)':\n",
    "            self.updateIndexMU()\n",
    "        elif strategy=='MLI (explore & exploit)':\n",
    "            self.updateIndexMLI()\n",
    "        elif strategy=='MEID (exploit)':\n",
    "            self.updateIndexMEID()        \n",
    "        elif strategy=='MLID (explore & exploit)':\n",
    "            self.updateIndexMLID()\n",
    "        \n",
    "    \n",
    "    def updateIndexMEI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target(fixed_target_selection)].iloc[self.PredIdx].to_numpy()\n",
    "            if(len(confirm_fixed_target(fixed_target_selection))>0):\n",
    "                for weights in range(len(ft.weights)):\n",
    "                    fixed_targets_in_prediction[weights]= fixed_targets_in_prediction[weights]*ft.weights[weights].value\n",
    "\n",
    "            fixed_targets_in_prediction=fixed_targets_in_prediction.sum(axis=1)\n",
    "            \n",
    "            \n",
    "            if(self.Expected_Pred.ndim>1):\n",
    "                index_max = np.argmax(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.sum(axis=1).squeeze())\n",
    "            else:\n",
    "                index_max = np.argmax(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze())\n",
    "\n",
    "            \n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.Expected_Pred = np.delete(self.Expected_Pred.squeeze(),index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "    def updateIndexMEID(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target(fixed_target_selection)].iloc[self.PredIdx].to_numpy()\n",
    "            if(len(confirm_fixed_target(fixed_target_selection))>0):\n",
    "                for weights in range(len(ft.weights)):\n",
    "                    fixed_targets_in_prediction[weights]=fixed_targets_in_prediction[weights]*ft.weights[weights].value\n",
    "            fixed_targets_in_prediction=fixed_targets_in_prediction.sum(axis=1)\n",
    "            \n",
    "            schwellwert=np.quantile(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze(),self.distance/100)\n",
    "            Index_=np.where(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            \n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.Expected_Pred = np.delete(self.Expected_Pred.squeeze(),index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "\n",
    "\n",
    "    def updateIndexMLID(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target(fixed_target_selection)].iloc[self.PredIdx].to_numpy()\n",
    "            if(len(confirm_fixed_target(fixed_target_selection))>0):\n",
    "                for weights in range(len(ft.weights)):\n",
    "                    fixed_targets_in_prediction[weights]=fixed_targets_in_prediction[weights]*ft.weights[weights].value\n",
    "            fixed_targets_in_prediction=fixed_targets_in_prediction.sum(axis=1)\n",
    "            \n",
    "            \n",
    "            schwellwert=np.quantile((fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()),self.distance/100)\n",
    "            Index_=np.where(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.Expected_Pred = np.delete(self.Expected_Pred.squeeze(),index_max)\n",
    "            self.Uncertainty=np.delete(self.Uncertainty.squeeze(),index_max)\n",
    "            self.PredIdx=new_PredIdx              \n",
    "            \n",
    "    def updateIndexMU(self):\n",
    "            index_max = np.argmax(self.Uncertainty)\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.Expected_Pred = np.delete(self.Expected_Pred.squeeze(),index_max)\n",
    "            self.Uncertainty=np.delete(self.Uncertainty.squeeze(),index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "    def updateIndexMLI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target(fixed_target_selection)].iloc[self.PredIdx].to_numpy()\n",
    "            if(len(confirm_fixed_target(fixed_target_selection))>0):\n",
    "                for weights in range(len(ft.weights)):\n",
    "                    fixed_targets_in_prediction[weights]=fixed_targets_in_prediction[weights]*ft.weights[weights].value\n",
    "            fixed_targets_in_prediction=fixed_targets_in_prediction.sum(axis=1)\n",
    "            \n",
    "            index_max = np.argmax(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze())    \n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.Expected_Pred = np.delete(self.Expected_Pred.squeeze(),index_max)\n",
    "            self.Uncertainty = np.delete(self.Uncertainty.squeeze(),index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "                        \n",
    "            \n",
    "    def fit_DT_wJK(self):        \n",
    "        \n",
    "        td,tl=self.jk_resampling()\n",
    "        \n",
    "        self.y_pred_dtr=[]\n",
    "        for i in range(len(td)):\n",
    "            dtr = DecisionTreeRegressor()\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "            \n",
    "        \n",
    "        self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "        self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "        self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        #multiply Prediction with factor\n",
    "        \n",
    "        self.weight_Pred()\n",
    "              \n",
    "              \n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit_TE_wJK(self):\n",
    "        td,tl=self.jk_resampling()\n",
    "        self.y_pred_dtr=[]\n",
    "        \n",
    "        \n",
    "        for i in range(len(td)):\n",
    "            ## alternative Ensamble Learners below:\n",
    "            dtr = SKRFR (n_estimators=10)\n",
    "            \n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "                \n",
    "        \n",
    "        self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "        self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "        self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        self.weight_Pred()\n",
    "        return self.Expected_Pred, self.Uncertainty        \n",
    "\n",
    "    def jk_resampling(self):\n",
    "        from resample.jackknife import resample as b_resample\n",
    "        td=[x for x in b_resample(self.features_df.iloc[self.SampIdx])]\n",
    "        tl=[x for x in b_resample(self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx])]\n",
    "        \n",
    "        tl=np.array(tl)\n",
    "        td=np.array(td)\n",
    "        \n",
    "        \n",
    "        return td,tl\n",
    "                   \n",
    "    def fit_RF_wJK(self):\n",
    "        \n",
    "        dtr = RandomForestRegressor()\n",
    "        self.x=self.features_df.iloc[self.SampIdx].to_numpy()\n",
    "        self.y=self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy()\n",
    "        if self.y.shape[0]<8:\n",
    "            self.x=np.tile(self.x,(4,1))\n",
    "            self.y=np.tile(self.y,(4,1))       \n",
    "        print('X',self.x.shape[0])\n",
    "        print('Y',self.y.shape[0])\n",
    "        dtr.fit(self.x,self.y)\n",
    "        self.Expected_Pred, self.Uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx].to_numpy(), return_std=True)\n",
    "        self.weight_Pred()\n",
    "        \n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "    \n",
    "    def fit_GP(self):\n",
    "        \n",
    "        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "        dtr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty= dtr.predict(self.features_df.iloc[self.PredIdx], return_std=True)     \n",
    "        \n",
    "        self.weight_Pred()\n",
    "        \n",
    "        return self.Expected_Pred.squeeze(), self.Uncertainty.squeeze()\n",
    "\n",
    "    def weight_Pred(self):\n",
    "        if(self.Expected_Pred.ndim>2):\n",
    "            for weights in range(len(tA.weights)):\n",
    "                self.Expected_Pred[:,weights]=self.Expected_Pred[:,weights]*t.weights[weights].value\n",
    "                \n",
    "        else: \n",
    "            self.Expected_Pred=self.Expected_Pred*t.weights[0].value  \n",
    "            self.Uncertainty=self.Uncertainty*t.weights[0].value  \n",
    "        \n",
    "        \"\"\"if(self.Expected_Pred.ndim>1):\n",
    "            for weights in range(len(t.weights)):\n",
    "                self.Expected_Pred[:,weights]=self.Expected_Pred[:,weights]*t.weights[weights].value\n",
    "\n",
    "        else: \n",
    "            self.Expected_Pred=self.Expected_Pred*t.weights[0].value\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "    def create_target_idx_after_logic_criteria(self,treshholded_idx,df,sum_):\n",
    "        checked_targets=[]\n",
    "        \n",
    "        if(treshholded_idx):\n",
    "            \n",
    "                    if(t.checkboxes is not None):\n",
    "                        for row in range(len(t.checkboxes)) :\n",
    "                            if (t.checkboxes[row].value == True):\n",
    "                                checked_targets.append(t.radiobuttons[row].description)\n",
    "                                \n",
    "                    if(ft.checkboxes is not None):\n",
    "                        for row in range(len(ft.checkboxes)):\n",
    "                            if (ft.checkboxes[row].value == True):\n",
    "                                checked_targets.append(ft.radiobuttons[row].description)\n",
    "                    \n",
    "                    \n",
    "                    if (len(checked_targets)!=len(t.checkboxes)+len(ft.checkboxes)):\n",
    "                        \n",
    "                        #frage\n",
    "                        targets=confirm_target(target_selection)\n",
    "                        fixed_targets=confirm_fixed_target(fixed_target_selection)\n",
    "                        \n",
    "                        \n",
    "                        df=df[targets.tolist()+fixed_targets.tolist()]\n",
    "                        \n",
    "                        sum_without_checked_targets=df.sum(axis=1)\n",
    "                        \n",
    "                        \n",
    "                        targ_q = quantile_tar_slider.value/100\n",
    "                        targ_q_t= sum_without_checked_targets.iloc[treshholded_idx].quantile(targ_q)\n",
    "                        \n",
    "                        tempIndex=np.where(sum_without_checked_targets.iloc[treshholded_idx] >= targ_q_t )\n",
    "                        \n",
    "                        tempIndex=tempIndex[0]\n",
    "                        \n",
    "                        Index_c=sum_without_checked_targets.iloc[treshholded_idx].iloc[tempIndex].index\n",
    "                        \n",
    "                        #Sample IDX\n",
    "                        \n",
    "                        Index_samp=np.delete(sum_.index, Index_c)\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        Index_c=treshholded_idx\n",
    "                        Index_samp=np.delete(sum_.index, treshholded_idx)\n",
    "            \n",
    "        \n",
    "        elif(not treshholded_idx):\n",
    "                    #print(\"kein tresh aber minimiert\")\n",
    "                    targ_q = quantile_tar_slider.value/100\n",
    "                    targ_q_t= sum_.quantile(targ_q)\n",
    "                    \n",
    "                    Index_samp=np.where(sum_ < targ_q_t )\n",
    "                    Index_samp=Index_samp[0]\n",
    "                    \n",
    "                    Index_c=np.where(sum_ >= targ_q_t )\n",
    "                    Index_c=Index_c[0]\n",
    "                    \n",
    "                    \n",
    "        return Index_samp,Index_c\n",
    "    \n",
    "    \n",
    "    def plot_TSNE_input_space(self):\n",
    "        \n",
    "            from sklearn.manifold import TSNE\n",
    "            \n",
    "            treshholded_idx=self.check_input_variables()\n",
    "            \n",
    "            features_df,target_df,fixed_target_df,df_unnorm,df=self.load_data()\n",
    "            \n",
    "            \n",
    "            \n",
    "            target_df=decide_max_or_min(box_targets,confirm_target(target_selection),target_df)\n",
    "            \n",
    "            fixed_target_df=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),fixed_target_df)\n",
    "            \n",
    "            \n",
    "            df = decide_max_or_min(box_targets,confirm_target(target_selection),df)\n",
    "            \n",
    "            df=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),df)\n",
    "            \n",
    "            \n",
    "            \n",
    "            sum_ = target_df.sum(axis=1).to_frame()+fixed_target_df.sum(axis=1).to_frame()\n",
    "            \n",
    "            \n",
    "            tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300,random_state=1000)\n",
    "            tsne_results = tsne.fit_transform(features_df)\n",
    "                \n",
    "            Index_samp,Index_c=self.create_target_idx_after_logic_criteria(treshholded_idx,df,sum_)\n",
    "            \n",
    "            \n",
    "            \n",
    "            with out_input_space:\n",
    "                # Plot Results in reduced FS\n",
    "                out_input_space.clear_output(wait=True)\n",
    "                fig3= plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                cmap = plt.get_cmap('cool', 200)\n",
    "                cmap.set_over('lawngreen')\n",
    "                \n",
    "                if(treshholded_idx):\n",
    "                    vmax=np.max(sum_.iloc[Index_samp])\n",
    "                    sum_.iloc[Index_c]=sum_.iloc[Index_c]+1000\n",
    "                    \n",
    "                    sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, \n",
    "                                   cmap=cmap, vmax=vmax)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:      \n",
    "                    targ_q = quantile_tar_slider.value/100\n",
    "                    targ_q_t= sum_.quantile(targ_q)\n",
    "                    \n",
    "                    Index_samp=np.where(sum_ < targ_q_t )\n",
    "                    Index_samp=Index_samp[0]\n",
    "                    \n",
    "                    Index_c=np.where(sum_ >= targ_q_t )\n",
    "                    Index_c=Index_samp[0]\n",
    "                \n",
    "                    sum_.iloc[Index_c]=np.max(sum_.iloc[Index_samp])\n",
    "                    \n",
    "                    sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, \n",
    "                                   cmap=cmap, vmax=np.max(sum_.iloc[Index_samp]))\n",
    "                    \n",
    "                    \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                cbar=plt.colorbar(sc,extend='both')\n",
    "                \n",
    "                cbar.ax.set_yticklabels([ ]) \n",
    "                cbar.ax.set_ylabel('target samples (green)                normalized target property', rotation=270 ,va='center')\n",
    "\n",
    "                plt.title(\"Materials data in TSNE-coordinates: candidates and targets\")\n",
    "                plt.show()\n",
    "                \n",
    "              \n",
    "                plt.close(fig3)\n",
    "        \n",
    "        \n",
    "    def check_input_variables(self):\n",
    "        \n",
    "        from collections import Counter\n",
    "        united_idxs=t.idxs\n",
    "        if(united_idxs is not None):\n",
    "            \n",
    "            idxs_without_feature_desc= [tuple_of_feature_and_idxs[1] for tuple_of_feature_and_idxs in united_idxs] \n",
    "            \n",
    "            \n",
    "            flat_list = [item for sublist in idxs_without_feature_desc for item in sublist]\n",
    "            \n",
    "            counts = Counter(flat_list)\n",
    "            \n",
    "            compatible_idxs = [id for id in flat_list if counts[id] >= (len(idxs_without_feature_desc))]\n",
    "            \n",
    "            treshholded_idx=set(compatible_idxs)\n",
    "            \n",
    "            treshholded_idx_as_list=list(treshholded_idx)\n",
    "            \n",
    "            return treshholded_idx_as_list\n",
    "        \n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def load_data(self):\n",
    "        \n",
    "        features_df=(df_converter()[confirm_features(feature_selector)]-df_converter()[confirm_features(feature_selector)].mean())/df_converter()[confirm_features(feature_selector)].std()\n",
    "        target_df=(df_converter()[confirm_target(target_selection)]-df_converter()[confirm_target(target_selection)].mean())/df_converter()[confirm_target(target_selection)].std()       \n",
    "        fixed_target_df=(df_converter()[confirm_fixed_target(fixed_target_selection)]-df_converter()[confirm_fixed_target(fixed_target_selection)].mean())/df_converter()[confirm_fixed_target(fixed_target_selection)].std()               \n",
    "        df_unnorm=df_converter()\n",
    "        df=(df_unnorm-df_unnorm.mean())/(df_unnorm.std())\n",
    "        \n",
    "        return features_df,target_df,fixed_target_df,df_unnorm,df\n",
    "    \n",
    "    def show_input_data(self):\n",
    "        treshholded_idx=self.check_input_variables()\n",
    "            \n",
    "        features_df,target_df,fixed_target_df,df_unnorm,df=self.load_data()\n",
    "            \n",
    "        \n",
    "        \n",
    "        with out_input_space:\n",
    "            \n",
    "            display(Markdown('Target data'))\n",
    "\n",
    "            if df is not None:\n",
    "                targ_q = quantile_tar_slider.value/100\n",
    "                \n",
    "                target_df=decide_max_or_min(box_targets,confirm_target(target_selection),target_df)\n",
    "                fixed_target_df=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),fixed_target_df)\n",
    "            \n",
    "            \n",
    "                df = decide_max_or_min(box_targets,confirm_target(target_selection),df)\n",
    "                df=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),df)\n",
    "                \n",
    "                sum_ = target_df.sum(axis=1).to_frame()+fixed_target_df.sum(axis=1).to_frame()\n",
    "\n",
    "                Index_samp,Index_c=self.create_target_idx_after_logic_criteria(treshholded_idx,df,sum_)\n",
    "        \n",
    "                display(Markdown(df_unnorm.iloc[Index_c].to_markdown()))\n",
    "            else:\n",
    "                display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "        \n",
    "        \n",
    "    def main(self):\n",
    "        \n",
    "        self.apply_feature_selection_to_df(self.dataframe)\n",
    "        self.apply_target_selection_to_df(self.dataframe)\n",
    "        if(len(confirm_fixed_target(fixed_target_selection).values.tolist())>0):\n",
    "            self.target_df=self.target_df.join(self.dataframe[confirm_fixed_target(fixed_target_selection)])\n",
    "        self.standardize_data()\n",
    "        init_sample_set=self.init_sampling()\n",
    "        \n",
    "        targ_q = quantile_tar_slider.value/100\n",
    "        \n",
    "        treshholded_idx= self.check_input_variables()\n",
    "            \n",
    "        features_df,target_df,fixed_target_df,df_unnorm,df=self.load_data()\n",
    "        \n",
    "  \n",
    "        target_df=decide_max_or_min(box_targets,confirm_target(target_selection),target_df)\n",
    "        fixed_target_df=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),fixed_target_df)\n",
    "        \n",
    "        sum_ = target_df.sum(axis=1).to_frame()+fixed_target_df.sum(axis=1).to_frame()\n",
    "                      \n",
    "        treshholded_idx=self.check_input_variables()\n",
    "        Index_samp,Index_c=self.create_target_idx_after_logic_criteria(treshholded_idx,df,sum_)\n",
    "\n",
    "        \n",
    "        self.treshIdx=Index_c\n",
    "        self.start_sequential_learning()\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = sequential_learning(df_converter(),\n",
    "                        initial_sample_size_text.value,\n",
    "                        batch_size_text.value, #drin f√ºr d utilitys\n",
    "                        quantile_tar_slider.value,\n",
    "                        iterations.value,\n",
    "                        slider_of_for_std.value,#drin\n",
    "                        slider_of_for_dist.value,#driun\n",
    "                        select_model.value,\n",
    "                        confirm_strategy(),\n",
    "                        t.idxs,\n",
    "                        ft.idxs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Materials Discovery\n",
    "class learn():\n",
    "    dataframe = df_converter()\n",
    "    features_df = df_converter()\n",
    "    target_df=df_converter()\n",
    "    fixed_target_df=df_converter()\n",
    "    \n",
    "    show_df=None\n",
    "    y_pred_dtr_mean=None\n",
    "    y_pred_dtr_std=None\n",
    "    y_pred_dtr=None\n",
    "    \n",
    "    def __init__(self,dataframe,model,strategy,sigma,distance):\n",
    "        self.dataframe=dataframe\n",
    "        self.model=model\n",
    "        self.strategy=strategy\n",
    "\n",
    "        self.sigma=sigma\n",
    "        self.distance=distance\n",
    "       \n",
    "        first_selected_target=list(confirm_target(target_selection_application))[0]\n",
    "        self.PredIdx = pd.isnull(self.dataframe[[first_selected_target]]).to_numpy().nonzero()[0]\n",
    "        self.SampIdx = self.dataframe.index.difference(self.PredIdx)\n",
    "        \n",
    "        \n",
    "    def scale_data(self):\n",
    "        \n",
    "        dataframe_norm=(self.dataframe-self.dataframe.mean())/self.dataframe.std()\n",
    "        target_df_norm=(self.target_df-self.target_df.mean())/self.target_df.std()\n",
    "        features_df_norm=(self.features_df-self.features_df.mean())/self.features_df.std()\n",
    "        fixed_target_df_norm=(self.fixed_target_df-self.fixed_target_df.mean())/self.fixed_target_df.std()\n",
    "        \n",
    "        self.features_df=features_df_norm\n",
    "        self.target_df=target_df_norm\n",
    "        self.dataframe=dataframe_norm\n",
    "        self.fixed_target_df=fixed_target_df_norm\n",
    "        \n",
    "\n",
    "        \n",
    "    def start_learning(self):\n",
    "        self.dataframe=decide_max_or_min(box_targets,confirm_target(target_selection_application),self.dataframe)\n",
    "        self.dataframe=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection_application),self.dataframe)\n",
    "        \n",
    "        self.fixed_target_selection_idxs=confirm_fixed_target(fixed_target_selection_application)\n",
    "        \n",
    "        self.fixed_target_df=self.dataframe[self.fixed_target_selection_idxs]\n",
    "        \n",
    "        self.target_selection_idxs=confirm_target(target_selection_application)\n",
    "        \n",
    "        self.features_df = self.dataframe[confirm_features(feature_selector_application)]\n",
    "        self.target_df=self.dataframe[confirm_target(target_selection_application)]\n",
    "        \n",
    "        \n",
    "       \n",
    "        self.decide_model(self.model)\n",
    "\n",
    "        self.strategy='MLI (explore & exploit)'\n",
    "        util= self.update_strategy(self.strategy)\n",
    "        \n",
    "            \n",
    "            \n",
    "        distance=distance_matrix(self.features_df.iloc[self.PredIdx], self.features_df.iloc[self.SampIdx])\n",
    "        min_distances=distance.min(axis=1)\n",
    "        max_of_min_distances=min_distances.max()\n",
    "        \n",
    "        novelty_factor=min_distances*(max_of_min_distances**(-1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        with out_app:\n",
    "            out_app.clear_output()\n",
    "            \n",
    "            #normierten datafram\n",
    "            \n",
    "            df= df_converter()#.abs\n",
    "            df = df.iloc[self.PredIdx].assign(Utility=pd.Series(util).values)\n",
    "            df = df.loc[self.PredIdx].assign(Novelty=pd.Series(novelty_factor).values)\n",
    "            \n",
    "            if(self.Uncertainty.ndim>1):\n",
    "                for i in range(len(self.target_selection_idxs)):\n",
    "         \n",
    "                    df[self.target_selection_idxs[i]] = self.Expected_Pred[:,i]\n",
    "                    uncertainty_name_column='Uncertainty ('+self.target_selection_idxs[i]+' )'\n",
    "                    df[uncertainty_name_column] = self.Uncertainty[:,i].tolist()\n",
    " \n",
    "            else:\n",
    "                df[self.target_selection_idxs]=self.Expected_Pred.reshape(len(self.Expected_Pred),1)\n",
    "                uncertainty_name_column='Uncertainty ('+self.target_selection_idxs+' )'\n",
    "                df[uncertainty_name_column]=self.Uncertainty.reshape(len(self.Uncertainty),1)\n",
    "                \n",
    "                       \n",
    "            show_df=df.sort_values(by='Utility', ascending=False)\n",
    "            display(Markdown(show_df.head(20).to_markdown()))\n",
    "            display((create_download_link(show_df,'Download Prediction','show_df')))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            target_list=show_df[self.target_selection_idxs]\n",
    "            if len(self.fixed_target_selection_idxs)>0:\n",
    "                target_list=pd.concat((target_list,show_df[self.fixed_target_selection_idxs]), axis=1)\n",
    "            target_list=pd.concat((target_list, show_df['Utility']), axis=1) \n",
    "        \n",
    "            print('')\n",
    "            print('Pareto plot (predicted property trade-off)')\n",
    "            \n",
    "            g = sns.PairGrid(target_list.head(20),diag_sharey=False, corner=True,hue=\"Utility\")\n",
    "            g.map_diag(sns.histplot,hue=None, color=\".3\")\n",
    "            g.map_lower(sns.scatterplot)\n",
    "            g.add_legend()\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "    def result_df(result):\n",
    "        data=show_df\n",
    "    \n",
    "    def weight_fixed_tars(self):\n",
    "        \n",
    "        fixed_targets_in_prediction=self.fixed_target_df.iloc[self.PredIdx].to_numpy()\n",
    "        \n",
    "        for weights in range(len(ftA.weights)):\n",
    "                fixed_targets_in_prediction[weights]=fixed_targets_in_prediction[weights]*ftA.weights[weights].value\n",
    "        \n",
    "        return fixed_targets_in_prediction.sum(axis=1)\n",
    "\n",
    "                \n",
    "    def updateIndexMLI(self):\n",
    "        Uncertainty_norm = self.Uncertainty/np.array(self.target_df.iloc[self.SampIdx].std())\n",
    "        Expected_Pred_norm= (self.Expected_Pred-np.array(self.target_df.iloc[self.SampIdx].mean()))/np.array(self.target_df.iloc[self.SampIdx].std())\n",
    "\n",
    "        if(self.Expected_Pred.ndim>=2):\n",
    "            \n",
    "            for weights in range(len(tA.weights)):\n",
    "                Expected_Pred_norm[:,weights]=Expected_Pred_norm[:,weights]*tA.weights[weights].value\n",
    "                Uncertainty_norm[:,weights]=Uncertainty_norm[:,weights]*tA.weights[weights].value\n",
    "                \n",
    "        else: \n",
    "            \n",
    "            Expected_Pred_norm=Expected_Pred_norm*tA.weights[0].value  \n",
    "            Uncertainty_norm=Uncertainty_norm*tA.weights[0].value  \n",
    "\n",
    "        self.scale_data()\n",
    "        \n",
    "        if(len(confirm_fixed_target(fixed_target_selection_application))>0):\n",
    "            fixed_targets_in_prediction=self.weight_fixed_tars()\n",
    "        else:\n",
    "            fixed_targets_in_prediction=np.zeros(len(self.PredIdx))\n",
    "        \n",
    "        if(len(self.target_selection_idxs)>1):\n",
    "                util=fixed_targets_in_prediction.squeeze()+Expected_Pred_norm.sum(axis=1)+(slider_of_for_std_App.value*Uncertainty_norm.sum(axis=1))\n",
    "        else:\n",
    "                util=fixed_targets_in_prediction.squeeze()+Expected_Pred_norm.squeeze()+(slider_of_for_std_App.value*Uncertainty_norm.squeeze())\n",
    "\n",
    "                \n",
    "        \n",
    "        return util\n",
    "            \n",
    "                        \n",
    "        \n",
    "    \n",
    "    def fit_GP(self):\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.target_selection_idxs)):\n",
    "            \n",
    "            kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "            dtr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "            \n",
    "            dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.target_df[self.target_selection_idxs[i]].iloc[self.SampIdx].to_numpy())\n",
    "            pred, uncertainty= dtr.predict(self.features_df.iloc[self.PredIdx], return_std=True)\n",
    "            \n",
    "            \n",
    "            if(i==0):\n",
    "                uncertainty_stacked = uncertainty\n",
    "                pred_stacked=pred\n",
    "            else:\n",
    "                uncertainty_stacked= np.vstack((uncertainty_stacked,uncertainty))\n",
    "                pred_stacked=np.vstack((pred_stacked,pred))\n",
    "            \n",
    "            \n",
    "        self.Uncertainty=uncertainty_stacked.T\n",
    "        self.Expected_Pred=pred_stacked.T\n",
    "        \n",
    "        \n",
    "    def fit_RF_wJK(self):\n",
    "      \n",
    "        for i in range(len(self.target_selection_idxs)):\n",
    "\n",
    "      \n",
    "            dtr = RandomForestRegressor()\n",
    "            self.x=self.features_df.iloc[self.SampIdx].to_numpy()\n",
    "            self.y=self.target_df.iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy()\n",
    "            if self.y.shape[0]<8:\n",
    "                self.x=np.tile(self.x,(4,1))\n",
    "                self.y=np.tile(self.y,(4,1))       \n",
    "        \n",
    "            dtr.fit(self.x,self.y)\n",
    "            pred, uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx], return_std=True)\n",
    "            \n",
    "            \n",
    "            if(i==0):\n",
    "                uncertainty_stacked = uncertainty\n",
    "                pred_stacked=pred\n",
    "            else:\n",
    "                uncertainty_stacked= np.vstack((uncertainty_stacked,uncertainty))\n",
    "                pred_stacked=np.vstack((pred_stacked,pred))\n",
    "            \n",
    "            \n",
    "        self.Uncertainty=uncertainty_stacked.T\n",
    "        self.Expected_Pred=pred_stacked.T\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    def decide_model(self,model):\n",
    "            if model== 'AI-Model (lolo Random Forrest)':\n",
    "                        self.fit_RF_wJK()\n",
    "            elif model == 'Statistics based model (Gaussian Process Regression)':\n",
    "                        self.fit_GP()\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "    def update_strategy(self, strategy):\n",
    "        if strategy=='MEI (exploit)':\n",
    "            util=self.updateIndexMEI()\n",
    "        elif strategy=='MU (explore)':\n",
    "            util=self.updateIndexMU()\n",
    "        elif strategy=='MLI (explore & exploit)':\n",
    "            util=self.updateIndexMLI()\n",
    "        elif strategy=='MEID (exploit)':\n",
    "            util=self.updateIndexMEID()        \n",
    "        elif strategy=='MLID (explore & exploit)':\n",
    "            util=self.updateIndexMLID()\n",
    "        return util\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "def plot_TSNE_input_space():\n",
    "            #%matplotlib notebook\n",
    "\n",
    "            from sklearn.manifold import TSNE\n",
    "            \n",
    "            treshholded_idx=s.check_input_variables()\n",
    "            \n",
    "            features_df,target_df,fixed_target_df,df_unnorm,df=s.load_data()\n",
    "            \n",
    "            \n",
    "            \n",
    "            target_df=decide_max_or_min(box_targets,confirm_target(target_selection),target_df)\n",
    "            \n",
    "            fixed_target_df=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),fixed_target_df)\n",
    "            \n",
    "            \n",
    "            df = decide_max_or_min(box_targets,confirm_target(target_selection),df)\n",
    "            \n",
    "            df=decide_max_or_min(box_fixed_targets,confirm_fixed_target(fixed_target_selection),df)\n",
    "            \n",
    "            \n",
    "            \n",
    "            sum_ = target_df.sum(axis=1).to_frame()+fixed_target_df.sum(axis=1).to_frame()\n",
    "            \n",
    "            \n",
    "            tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300,random_state=1000)\n",
    "            tsne_results = tsne.fit_transform(features_df)\n",
    "                \n",
    "            Index_samp,Index_c=s.create_target_idx_after_logic_criteria(treshholded_idx,df,sum_)\n",
    "            \n",
    "            \n",
    "            \n",
    "            with out_input_space:\n",
    "                # Plot Results in reduced FS\n",
    "                out_input_space.clear_output(wait=True)\n",
    "                fig3= plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                cmap = plt.get_cmap('cool', 200)\n",
    "                cmap.set_over('lawngreen')\n",
    "                \n",
    "                if(treshholded_idx):\n",
    "                    vmax=np.max(sum_.iloc[Index_samp])\n",
    "                    sum_.iloc[Index_c]=sum_.iloc[Index_c]+1000\n",
    "                    \n",
    "                    sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, \n",
    "                                   cmap=cmap, vmax=vmax)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:      \n",
    "                    targ_q = quantile_tar_slider.value/100\n",
    "                    targ_q_t= sum_.quantile(targ_q)\n",
    "                    \n",
    "                    Index_samp=np.where(sum_ < targ_q_t )\n",
    "                    Index_samp=Index_samp[0]\n",
    "                    \n",
    "                    Index_c=np.where(sum_ >= targ_q_t )\n",
    "                    Index_c=Index_samp[0]\n",
    "                \n",
    "                    sum_.iloc[Index_c]=np.max(sum_.iloc[Index_samp])\n",
    "                    \n",
    "                    sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, \n",
    "                                   cmap=cmap, vmax=np.max(sum_.iloc[Index_samp]))\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                cbar=plt.colorbar(sc,extend='both')\n",
    "                \n",
    "                cbar.ax.set_yticklabels([ ]) \n",
    "                cbar.ax.set_ylabel('targets (green)                normalized target property', rotation=270 ,va='center')\n",
    "\n",
    "                plt.title(\"Design space in TSNE-coordinates: candidate pool and targets\")\n",
    "                plt.show()\n",
    "                \n",
    "              \n",
    "                plt.close(fig3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment_clicked(b):\n",
    "    \n",
    "    start_and_stop_sl_container.children=[button_perform_experiment]\n",
    "    s = sequential_learning(df_converter(),\n",
    "                            initial_sample_size_text.value,\n",
    "                            batch_size_text.value,\n",
    "                            quantile_tar_slider.value,\n",
    "                            iterations.value,\n",
    "                            slider_of_for_std.value,\n",
    "                            slider_of_for_dist.value,\n",
    "                            select_model.value,\n",
    "                            confirm_strategy(),\n",
    "                            t.idx,\n",
    "                            ft.idx)\n",
    "    s.main()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def apply_clicked(b):\n",
    "    \n",
    "    l = learn(df_converter(),select_model.value,confirm_strategy(),\n",
    "                  slider_of_for_std.value,slider_of_for_dist.value)\n",
    "\n",
    "    l.start_learning()\n",
    "    \n",
    "def plotterDS_clicked(b):\n",
    "    plot_TSNE_input_space()\n",
    "    \n",
    "def show_input_data(b):\n",
    "    s.show_input_data()\n",
    "    \n",
    "def on_strategy_changes(change):\n",
    "    if select_strategy.value==\"MEID (exploit)\":\n",
    "        create_slider_for_dist_quantile()\n",
    "    elif select_strategy.value==\"MLID (explore & exploit)\":  \n",
    "        create_slider_for_dist_quantile_std()\n",
    "    elif select_strategy.value==\"MLI (explore & exploit)\":\n",
    "        create_slider_for_std()\n",
    "    else:\n",
    "        strategy_container=HBox([select_strategy])\n",
    "        \n",
    "\n",
    "def display_progess_automation(actual_iter,all_comb):\n",
    "    with out_iter_aut:\n",
    "            time.sleep(0.1)\n",
    "            out_iter_aut.clear_output()\n",
    "            display(Markdown('\\n Status  {}/{} \\n'.format(\n",
    "                        actual_iter+1,all_comb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_clicked(b):\n",
    "    try:\n",
    "        preview()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def upload_clicked(b):\n",
    "    if(up._counter>1):\n",
    "        up.value.clear()\n",
    "        up._counter = 1\n",
    "    try:\n",
    "        upload()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def desc_clicked(b):\n",
    "    desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_settings_button_clicked(b):\n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        display(Markdown(settings.to_markdown()))\n",
    "        \n",
    "def confirm_import_clicked(b):\n",
    "    if(import_button._counter>1):\n",
    "        up.value.clear()\n",
    "        import_button._counter=1\n",
    "    \n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        out_settings.clear_output(wait=True)\n",
    "        display(Markdown('Your Settings got importet and look like:'))\n",
    "        display(Markdown(settings.to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter_clicked(b):\n",
    "    plot()\n",
    "\n",
    "def pairwise_clicked(b):\n",
    "    plot_pairwise()\n",
    "def heat_clicked(b):\n",
    "    plot_heat()\n",
    "def scatter_clicked(b):\n",
    "    plot_scatter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "def on_feature_selection_change(change):\n",
    "    confirm_features(feature_selector)\n",
    "\n",
    "def on_target_selection_change(change):\n",
    "    confirm_target(target_selection)\n",
    "    \n",
    "def on_app_feature_selection_change(change):\n",
    "    confirm_features(feature_selector_application)\n",
    "    \n",
    "    \n",
    "def on_app_target_selection_change(change):\n",
    "    confirm_target(target_selection_application)\n",
    "\n",
    "def on_app_fixed_target_selection_change(change):\n",
    "    confirm_fixed_target(fixed_target_selection_application)\n",
    "\n",
    "def on_fixed_target_selection_change(change):\n",
    "    confirm_fixed_target(fixed_target_selection)\n",
    "\n",
    "def on_graph_type_change(change):\n",
    "        \n",
    "    if graph_type.value ==\"Scatter\":\n",
    "        container_plot_options.children= [HBox([select_x,select_y]),\n",
    "        HBox([select_hue,select_size])]\n",
    "    elif graph_type.value ==\"Scatter Matrix\":\n",
    "        \n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "                                          \n",
    "    elif graph_type.value =='Correlation Heatmap':\n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "        \n",
    "    else: container_plot_options.children=[]\n",
    "\n",
    "\n",
    "        \n",
    "def confirm_var_clicked(b):\n",
    "    confirm_var()\n",
    "\n",
    "def confirm_options_clicked(b):\n",
    "    confirm_options()\n",
    "\n",
    "\n",
    "def on_graph_type_change(change):\n",
    "        \n",
    "    if graph_type.value ==\"Scatter\":\n",
    "        container_plot_options.children= [HBox([select_x,select_y]),\n",
    "        HBox([select_hue,select_size])]\n",
    "    elif graph_type.value ==\"Scatter Matrix\":\n",
    "        \n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "                                          \n",
    "    elif graph_type.value =='Correlation Heatmap':\n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "        \n",
    "    else: container_plot_options.children=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "button_upload.on_click(upload_clicked)\n",
    "toggle.observe(desc_clicked, 'value')\n",
    "button_preview.on_click(preview_clicked)\n",
    "button_confirm_plot_var.on_click(confirm_var_clicked)\n",
    "\n",
    "feature_selector.observe(on_feature_selection_change,names='value')\n",
    "target_selection.observe(on_target_selection_change,names='value')\n",
    "fixed_target_selection.observe(on_fixed_target_selection_change,names='value')\n",
    "\n",
    "target_selection.observe(t.on_selection_change,names='value')\n",
    "fixed_target_selection.observe(ft.on_selection_change,names='value')\n",
    "\n",
    "feature_selector_application.observe(on_app_feature_selection_change,names='value')\n",
    "target_selection_application.observe(on_app_target_selection_change,names='value')\n",
    "fixed_target_selection_application.observe(on_app_fixed_target_selection_change,names='value')\n",
    "\n",
    "target_selection_application.observe(tA.on_selection_change,names='value')\n",
    "fixed_target_selection_application.observe(ftA.on_selection_change,names='value')\n",
    "\n",
    "\n",
    "\n",
    "graph_type.observe(on_graph_type_change,names='value')\n",
    "select_strategy.observe(on_strategy_changes,names=\"value\")\n",
    "\n",
    "button_confirm_options.on_click(confirm_options_clicked)\n",
    "preview_settings_button.on_click(preview_settings_button_clicked) \n",
    "button_perform_experiment.on_click(perform_experiment_clicked)\n",
    "button_application.on_click(apply_clicked)\n",
    "confirm_import_button.on_click(confirm_import_clicked)\n",
    "button_plot.on_click(plotter_clicked)\n",
    "button_show_DS.on_click(confirm_target,confirm_fixed_target)\n",
    "button_show_DS.on_click(plotterDS_clicked)\n",
    "button_show_DS.on_click(show_input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909b072a2d1d4dd6bcbdfe14e9ec5231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Accordion(children=(FileUpload(value={}, description='Upload'), HBox(children=(Ra‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
