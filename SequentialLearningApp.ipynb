{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Learning App for Materials Discovery - *SLAMD*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from ipywidgets import Text,BoundedFloatText,Checkbox,ToggleButtons,Dropdown,VBox,HBox,Accordion,BoundedIntText,SelectMultiple,RadioButtons,FloatRangeSlider,Button,IntSlider,Label,Tab,Output,FileUpload,Layout,FloatSlider\n",
    "from IPython.display import display,Markdown,HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance_matrix\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor as SKRFR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn import preprocessing\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "from operator import add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tab\n",
    "tab =Tab() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs\n",
    "out=Output()\n",
    "out_plotting=Output()\n",
    "out_settings=Output()\n",
    "out_algo=Output()\n",
    "out_perform_experiment=Output()\n",
    "out_input_space=Output()\n",
    "out_res=Output()\n",
    "out_iter_aut=Output()\n",
    "out_fixed_targets=Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Upload\n",
    "up = FileUpload(accept=\"\", multiple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload Properties \n",
    "delim =RadioButtons(\n",
    "    options=[';', ','],\n",
    "    description='Separator: ',\n",
    "    disabled=False)\n",
    "delim_dec = RadioButtons(\n",
    "    options=[',', '.'],\n",
    "    description='Decimal Delim: ',\n",
    "    disabled=False)\n",
    "eraser = SelectMultiple(\n",
    "    options=['tab','\"',\"%\"],\n",
    "    value=['tab'],\n",
    "    #rows=10,\n",
    "    description='Eraser: ',\n",
    "    disabled=False)\n",
    "rows = IntSlider(\n",
    "    value=0,\n",
    "    step=1,\n",
    "    description='# of lines:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Info \n",
    "toggle = ToggleButtons(\n",
    "    options=['Preview  ', 'Info  ', 'Stats  '],\n",
    "    description='Options',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    icons=['search', 'info', 'tachometer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of Targets and Features\n",
    "feature_selector=SelectMultiple(\n",
    "    options=[],\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')) \n",
    "target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the Target Variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "fixed_target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the Target Variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "selector_plot_variable=SelectMultiple(\n",
    "    options=[],\n",
    "    description='Features',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "graph_type = Dropdown(\n",
    "    options=['Choose the Graph Type','Scatter', 'Scatter Matrix', 'Correlation Heatmap'],\n",
    "    value='Choose the Graph Type',\n",
    "    description='Chart Type:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "x_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='X-Axis:',\n",
    "    disabled=False)\n",
    "y_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False)\n",
    "\n",
    "select_x=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select X-Axis',\n",
    "    description='X-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_y=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select Y-Axis',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_hue=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the hue',\n",
    "    description='Hue:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_size=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the Size',\n",
    "    description='Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "box_features=VBox([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Learning Properties\n",
    "select_strategy=Dropdown(\n",
    "    options=['MEI (exploit)','MU (explore)','MLI (explore & exploit)','MEID (exploit)','MLID (explore & exploit)'],\n",
    "    value='MEI (exploit)',\n",
    "    placeholder='select the strategy',\n",
    "    description='Strategy:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_model=Dropdown(\n",
    "    options=['lolo Random Forrest (RF) - quick (requ. min 8 init. samples)','Decision Trees (DT) - quick','Random Forrest (RFscikit) - quick','Gaussian Process Regression (GPR) - quick'],\n",
    "    value='Decision Trees (DT) - quick',\n",
    "    placeholder='select the Model',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Buttons\n",
    "button_confirm_strategy=Button(\n",
    "    description='Confirm Strategy ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm selected Strategy',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_upload =Button(\n",
    "    description='Upload',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Click to Upload',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_preview = Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to Preview',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_plot = Button(\n",
    "    description='Plot',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Click to Plot',\n",
    "    icon='pencil',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "button_confirm_feature=Button(\n",
    "    description='Select Features ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm Feature Selection of Training Features',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_confirm_target=Button(\n",
    "    description='Select Target',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm the selected Target Variable',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_confirm_fixed_target=Button(\n",
    "    description='Select fixed Target',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm the selected Target Variable',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_show_DS=Button(\n",
    "    description='Visualize Settings',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Plots Design Space with candidates and targets',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_confirm_plot_var=Button(\n",
    "    description='Confirm Selection',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm the selected Target Variable',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_plot_comparision=Button(\n",
    "    description='Compare',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Simplify the Columns',\n",
    "    icon='fa-bar-chart',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_confirm_options=Button(\n",
    "    description='Confirm Options ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm options',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "                           \n",
    "button_perform_experiment=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform Experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "run_button_aut=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform Experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "run_button_aut_template=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform Experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "confirm_import_button=Button(\n",
    "    description='Confirm Import ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm selected Strategy',\n",
    "    icon='check',\n",
    "layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "preview_settings_button=Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to Preview',\n",
    "    icon='search',\n",
    "layout=Layout(width='50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Layout File Upload Tab\n",
    "\n",
    "accordion = Accordion(children=[\n",
    "    up, \n",
    "    HBox([delim, delim_dec, eraser]), \n",
    "    rows])\n",
    "\n",
    "accordion.set_title(0, 'File Selection')\n",
    "accordion.set_title(1, 'Delimiter')\n",
    "accordion.set_title(2, 'Skip Rows')\n",
    "\n",
    "\n",
    "accordion_box = VBox([\n",
    "    accordion, \n",
    "    HBox([button_preview, button_upload ]),\n",
    "    out\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Tab\n",
    "\n",
    "container_plot_options= VBox([])\n",
    "button_container=HBox([button_plot])\n",
    "\n",
    "plotting=VBox(children=[VBox( [\n",
    "        HBox([graph_type]),\n",
    "        container_plot_options,\n",
    "        button_container,\n",
    "        out_plotting\n",
    "        ]\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sequential Learning Tab \n",
    "\n",
    "slider_of_for_dist=FloatSlider(\n",
    "    value=95,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Prediction quantile for distance-based utility (smaller values recommended for weak predictors).:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "slider_of_for_std=FloatSlider(\n",
    "    value=1,\n",
    "    min=0.1,\n",
    "    max=5,\n",
    "    step=0.1,\n",
    "    description='Ïƒ Factor (to controll the weigth of uncertainty):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "quantile_tar_slider= FloatSlider(\n",
    "    value=95,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Target threshold (Quantile):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "\n",
    "quantile_sample_slider= FloatSlider(\n",
    "    value=50,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Sample threshold (Quantile):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "initial_sample_size_text=BoundedIntText(\n",
    "    value=4,\n",
    "    min=2,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Initial Sample Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "\n",
    "box_features_slider=VBox([])\n",
    "\n",
    "\n",
    "plottingDS=VBox(children=[VBox( [\n",
    "        \n",
    "        out_input_space\n",
    "    ]\n",
    ")])\n",
    "\n",
    "DataPre_sl=VBox([\n",
    "        HBox([Label(\"Feature\"),feature_selector, button_confirm_feature]),\n",
    "        HBox([Label(\"Targets\"),target_selection, button_confirm_target]),\n",
    "        box_features,\n",
    "        HBox([Label(\"Fixed Targets\"),fixed_target_selection, button_confirm_fixed_target]),\n",
    "        HBox([quantile_tar_slider,quantile_sample_slider]),\n",
    "        HBox([initial_sample_size_text,button_show_DS]),\n",
    "        plottingDS    \n",
    "])\n",
    "\n",
    "\n",
    "    \n",
    "DataPre=VBox([\n",
    "        HBox([feature_selector, button_confirm_feature ]),\n",
    "        HBox([target_selection, button_confirm_target]),\n",
    "       ])\n",
    "\n",
    "iterations=IntSlider(\n",
    "    value=30,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='# of SL runs:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "custom_container=VBox([HBox([])])\n",
    "results_container=VBox([HBox([])])\n",
    "strategy_container=HBox([select_strategy, button_confirm_strategy ])\n",
    "\n",
    "start_and_stop_sl_container=HBox([button_perform_experiment])\n",
    "\n",
    "sl_settings= VBox([\n",
    "    strategy_container,\n",
    "    custom_container,\n",
    "    HBox([select_model,iterations]),\n",
    "    start_and_stop_sl_container,\n",
    "    out_perform_experiment,\n",
    "    out_fixed_targets\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "sl_accordion=Accordion(children=[DataPre_sl,sl_settings])\n",
    "sl_accordion.set_title(0,\"Settings\")\n",
    "sl_accordion.set_title(1,\"Sequential Learning Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automation Components\n",
    "\n",
    "sl_runs_for_sl_arena=BoundedIntText(\n",
    "    value=5,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='SL-Runs:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "checkbox_gp=Checkbox(\n",
    "    value=False,\n",
    "    description='Gaussian Process Regression (GPR) - quick',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "checkbox_dt=Checkbox(\n",
    "    value=False,\n",
    "    description='Decision Trees (DT) - quick',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "checkbox_rf=Checkbox(\n",
    "    value=False,\n",
    "    description='lolo Random Forrest (RF) - quick (requ. min 8 init. samples)',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "checkbox_rf_scikit=Checkbox(\n",
    "    value=False,\n",
    "    description='Random Forrest (RFscikit) - quick',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "specify_target_treshhold=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "specify_sample_threshold=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "specify_sigma=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "specify_distance=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "specify_init_sample_size=Checkbox(\n",
    "    value=False,\n",
    "    description='Specify',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "#refactor idee : Specification class mit checkbox und textfield\n",
    "all_specify_checkboxes=[specify_target_treshhold,specify_sample_threshold,specify_sigma,specify_distance,specify_init_sample_size]\n",
    "\n",
    "\n",
    "\n",
    "start_sigma=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_sigma=BoundedFloatText(\n",
    "    value=5,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "step_sigma=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Step Size:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_tar_tresh=BoundedFloatText(\n",
    "    value=95,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=0.5,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_tar_tresh=BoundedFloatText(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=0.5,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "step_tar_tresh=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.5,\n",
    "    description='Step:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_samp_tresh=BoundedFloatText(\n",
    "    value=50,\n",
    "    min=0,\n",
    "    max=100.0,\n",
    "    step=0.5,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_samp_tresh=BoundedFloatText(\n",
    "    value=55,\n",
    "    min=0,\n",
    "    max=100.0,\n",
    "    step=0.5,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "step_samp_tresh=BoundedFloatText(\n",
    "    value=1,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.5,\n",
    "    description='Step:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_init_samp=BoundedIntText(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "stop_init_samp=BoundedIntText(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "step_init_samp=BoundedIntText(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Step: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "#\n",
    "start_distance=BoundedFloatText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_distance=BoundedFloatText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "step_distance=BoundedFloatText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Step Size:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_tar_tresh=Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 89;92;96',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_samp_tresh=Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 51;67',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_init_samp=Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 2;8;9  ',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_sigma_factor =Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 1;2 ',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "list_utility_distance =Text(\n",
    "    value='',\n",
    "    placeholder='e.g. 90;95 ',\n",
    "    description='specified values:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "start_utility_distance=BoundedFloatText(\n",
    "    value=90,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Start:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "stop_utility_distance=BoundedFloatText(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Stop:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "step_utility_distance=BoundedFloatText(\n",
    "    value=5,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Step Size:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_specify_lists=[list_tar_tresh,list_samp_tresh,list_sigma_factor,list_utility_distance,list_init_samp]\n",
    "\n",
    "\n",
    "\n",
    "sl_arena=VBox([\n",
    "        HBox([sl_runs_for_sl_arena]),\n",
    "        VBox([Label(\"Initial Sample Size:\"),\n",
    "                        HBox([start_init_samp,step_init_samp,stop_init_samp]),\n",
    "                        HBox([specify_init_sample_size,list_init_samp])]),\n",
    "    \n",
    "        VBox([Label(\"Target Threshold:\"),\n",
    "                      HBox([start_tar_tresh,step_tar_tresh,stop_tar_tresh]),\n",
    "                      HBox([specify_target_treshhold,list_tar_tresh]),\n",
    "                     ]),\n",
    "        VBox([Label(\"Sample Threshold:\"),\n",
    "                        HBox([start_samp_tresh,step_samp_tresh,stop_samp_tresh]),\n",
    "                        HBox([specify_sample_threshold,list_samp_tresh])\n",
    "                     ]),\n",
    "        VBox([Label(\"Utility Distance:\"),\n",
    "                        HBox([start_utility_distance,step_utility_distance,stop_utility_distance]),\n",
    "                        HBox([ specify_distance,list_utility_distance]),\n",
    "                     ]),\n",
    "        VBox([Label(\"Utility  sigma factor range:\"),\n",
    "                      HBox([start_sigma,step_sigma,stop_sigma]),\n",
    "                      HBox([specify_sigma,list_sigma_factor]),\n",
    "                    ]),\n",
    "        VBox([Label(\"Models:\"),\n",
    "                      HBox([checkbox_gp,checkbox_dt]),\n",
    "                      HBox([checkbox_rf,checkbox_rf_scikit])]),\n",
    "        run_button_aut,\n",
    "        out_iter_aut\n",
    "            \n",
    "])\n",
    "\n",
    "selection_aut_feature=VBox([HBox([feature_selector, button_confirm_feature]),\n",
    "        HBox([target_selection, button_confirm_target]),])\n",
    "\n",
    "\n",
    "import_button = FileUpload(accept=\"\", multiple=False,description=\"Import\",layout=Layout(width='50%'))\n",
    "\n",
    "   \n",
    "import_container=VBox([HBox([import_button,preview_settings_button,confirm_import_button,run_button_aut_template]),HBox([out_settings])])\n",
    "\n",
    "automation_accordion=Accordion(children=[selection_aut_feature,import_container,sl_arena])\n",
    "\n",
    "automation_accordion.set_title(0, 'Feature and Target Selection')\n",
    "automation_accordion.set_title(1, 'Import Settings')\n",
    "automation_accordion.set_title(2, 'Manually Configure Settings')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layout Tabs\n",
    "\n",
    "children = [\n",
    "    accordion_box, \n",
    "    VBox([toggle, out]),\n",
    "    plotting,\n",
    "    sl_accordion,\n",
    "    automation_accordion\n",
    "    \n",
    "   ]\n",
    "\n",
    "tab.children = children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Naming Tabs\n",
    "\n",
    "tab.set_title(0, \"Upload\")\n",
    "tab.set_title(1, \"Data Info\")\n",
    "tab.set_title(2, \"Design Space Explorer\")\n",
    "tab.set_title(3, \"Sequential Learning\")\n",
    "tab.set_title(4, \"Automation ðŸ¤–\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Utility Methods\n",
    "           \n",
    "def flatten_list(nested_list):\n",
    "    for sublist in nested_list:\n",
    "        flatlist=[element for element in sublist]  \n",
    "    return flatlist\n",
    "\n",
    "\n",
    "def import_settings():\n",
    "    content= content_parser(import_button)\n",
    "    settings = pd.read_csv(content, sep=',', index_col=False, decimal='.')\n",
    "         \n",
    "    return settings\n",
    "\n",
    "\n",
    "def content_parser(source):\n",
    "    if source.value == {}:\n",
    "        \"\"\"with out:\n",
    "            out.clear_output\n",
    "            display(Markdown('No CSV loaded'))\n",
    "            #print('No CSV loaded')    \"\"\"\n",
    "    else:\n",
    "        from io import StringIO\n",
    "        typ, content = \"\", \"\"\n",
    "        up_value = source.value\n",
    "        for i in up_value.keys():\n",
    "            typ = up_value[i][\"metadata\"][\"type\"]\n",
    "            if typ == \"text/csv\" or typ == \"application/vnd.ms-excel\":\n",
    "                content = up_value[i][\"content\"]\n",
    "                content_str = str(content, 'utf-8')\n",
    "\n",
    "                if eraser.value != {}: \n",
    "                    for val in eraser.value:\n",
    "                        if val == \"tab\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        elif val ==\"%\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        else:\n",
    "                            content_str = content_str.replace(val,\"\")\n",
    "                if content_str != \"\":\n",
    "                    str_io = StringIO(content_str) \n",
    "                    return str_io\n",
    "def df_converter():\n",
    "    content = content_parser(up)\n",
    "    if content is not None:\n",
    "            df = pd.read_csv(content, sep=delim.value, index_col=False, skiprows=rows.value,decimal=delim_dec.value)\n",
    "            df=df.apply(pd.to_numeric,errors=\"ignore\")\n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "            return df\n",
    "    else:\n",
    "        return None\n",
    "def preview():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is your data:'))\n",
    "        \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "            \n",
    "def upload():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is how your uploaded data looks like:'))\n",
    "       \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "            x_axis.options = df.columns\n",
    "            y_axis.options = df.columns\n",
    "            feature_selector.options= df.columns\n",
    "            \n",
    "            select_x.options=df.columns\n",
    "            select_y.options=df.columns\n",
    "            select_size.options=df.columns\n",
    "            select_hue.options=df.columns\n",
    "            selector_plot_variable.options=df.columns\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "            \n",
    "            \n",
    "def create_download_link( df, title, filename): \n",
    "    import base64\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = html_buttons = '''<html>\n",
    "    <head>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    </head>\n",
    "    <body>\n",
    "    <a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-warning\">{title}</button>\n",
    "    </a>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    html_button = html_buttons.format(payload=payload,filename=filename,title=title)\n",
    "    return HTML(html_button)\n",
    "\n",
    "            \n",
    "            \n",
    "def desc():\n",
    "    info_level = toggle.value\n",
    "    if info_level != {}:\n",
    "        df = df_converter()\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            \n",
    "            display(Markdown('\\n Data {} \\n'.format(\n",
    "                info_level)))\n",
    "            if df is not None:\n",
    "                if info_level == 'Info  ':\n",
    "                    df.info()\n",
    "                elif info_level == 'Stats  ':\n",
    "                    display(Markdown(df.describe().to_markdown()))\n",
    "                elif info_level == 'Preview  ':\n",
    "                    display(Markdown(df.head(10).to_markdown()))\n",
    "                else:\n",
    "                    display(Markdown('Configuration is wrong/missing...'))\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Methods\n",
    "import seaborn as sns\n",
    "\n",
    "def plot():\n",
    "    graph = graph_type.value\n",
    "    if graph==\"Scatter\":\n",
    "        plot_scatter()\n",
    "    elif graph==\"Correlation Heatmap\":\n",
    "            plot_heat()\n",
    "    elif graph==\"Scatter Matrix\":\n",
    "            plot_pairwise()\n",
    "          \n",
    "        \n",
    "def plot_pairwise():\n",
    "    df =confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        sns.pairplot(df)\n",
    "        plt.show()\n",
    "\n",
    "def plot_heat():\n",
    "    df = confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        corr = df.corr()\n",
    "        plt.figure(figsize=(12,7))\n",
    "        sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "        b, t = plt.ylim()\n",
    "        plt.ylim(b+0.5, t-0.5)\n",
    "        plt.title(\"Feature Correlation Heatmap\")\n",
    "        plt.show()\n",
    "            \n",
    "def plot_scatter():\n",
    "    data=df_converter()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        fig, ax = plt.subplots(figsize=(12,7))\n",
    "        #not generic\n",
    "        sns.scatterplot(y=select_y.value, x=select_x.value, hue=select_hue.value, size=select_size.value, data=data, ax=ax, sizes=(50, 300))\n",
    "        ax.set_title(select_y.value+ \"vs\"+ select_x.value)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "        plt.show()\n",
    "        plt.close(fig)  \n",
    "\n",
    "        \n",
    "def plot_TSNE_input_space():\n",
    "            from sklearn.manifold import TSNE\n",
    "            features_df=(df_converter()[confirm_features()]-df_converter()[confirm_features()].mean())/df_converter()[confirm_features()].std()\n",
    "        \n",
    "            target_df=(df_converter()[confirm_target()]-df_converter()[confirm_target()].mean())/df_converter()[confirm_target()].std()       \n",
    "\n",
    "            tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "            tsne_results = tsne.fit_transform(features_df)\n",
    "\n",
    "            with out_input_space:\n",
    "                # Plot Results in reduced FS\n",
    "                out_input_space.clear_output(wait=True)\n",
    "                fig3= plt.figure(figsize=(10, 6))\n",
    "                targ_q = quantile_tar_slider.value/100\n",
    "                samp_q = quantile_sample_slider.value/100\n",
    "                sum_ = target_df.sum(axis=1).to_frame()\n",
    "                targ_q_t= sum_.quantile(targ_q)\n",
    "                samp_q_t=sum_.quantile(samp_q)\n",
    "                \n",
    "                cmap = plt.get_cmap('cool', 200)\n",
    "                cmap.set_under('dimgray') \n",
    "                cmap.set_over('lawngreen')\n",
    "                sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, cmap=cmap, vmin=samp_q_t.values, vmax=targ_q_t.values-0.01)\n",
    "                cbar=plt.colorbar(sc,extend='both')\n",
    "                #ticklabs = cbar.ax.get_yticklabels()\n",
    "                cbar.ax.set_yticklabels([ ]) \n",
    "                cbar.ax.set_ylabel('targets (green)                to be explored            initial candidate pool (gray)', rotation=270 ,va='center')\n",
    "\n",
    "                plt.title(\"Design space in TSNE-coordinates: candidate pool and targets\")\n",
    "                plt.show()\n",
    "                        \n",
    "                plt.close(fig3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def confirm_options():\n",
    "    items=box_features_slider.children\n",
    "    df = df_converter()\n",
    "    Y = df.loc[:,df.columns.isin(target_selection.value)]\n",
    "    \n",
    "    for slider in items:\n",
    "            unt_grenz= slider.value[0]/100\n",
    "            ob_grenz= slider.value[1]/100\n",
    "            Y = Y[(Y >= Y.quantile(unt_grenz) ) & (Y <= Y.quantile(ob_grenz))]\n",
    "            Y= Y.dropna()\n",
    "    \n",
    "    return Y   \n",
    "\n",
    "\n",
    "def confirm_features():\n",
    "    df = df_converter()\n",
    "    train = feature_selector.value\n",
    "    target_selection.options=df.columns[~df.columns.isin(feature_selector.value)]\n",
    "    fixed_target_selection.options=target_selection.options\n",
    "    train = df.columns[df.columns.isin(feature_selector.value)]\n",
    "    return train\n",
    "\n",
    "\n",
    "def confirm_var():\n",
    "    df= df_converter()\n",
    "    selection = list(selector_plot_variable.value)\n",
    "    var = df[selection]\n",
    " \n",
    "    return var\n",
    "\n",
    "  \n",
    "def confirm_target():\n",
    "    df = df_converter()\n",
    "    target = df.columns[df.columns.isin(target_selection.value)]\n",
    "    if(len(box_features.children) == 0):\n",
    "        create_dynamically_checkboxes()\n",
    "    return target \n",
    "\n",
    "def confirm_fixed_target():\n",
    "    df = df_converter()\n",
    "    fixed_target = df.columns[df.columns.isin(fixed_target_selection.value)]\n",
    "    return fixed_target\n",
    "\n",
    "def confirm_strategy():\n",
    "    strategy= select_strategy.value\n",
    "    if strategy != {}:\n",
    "            custom_container.children=[]\n",
    "            return select_strategy.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slider_for_dist_quantile():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist,  button_confirm_strategy]\n",
    "    \n",
    "def create_slider_for_dist_quantile_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist, slider_of_for_std,  button_confirm_strategy]\n",
    "        \n",
    "def create_slider_for_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_std,  button_confirm_strategy]\n",
    "    \n",
    "def create_dynamically_checkboxes():\n",
    "    target= target_selection.value\n",
    "    items = [RadioButtons(\n",
    "    options=['maximize', 'minimize'],\n",
    "    value='maximize', \n",
    "    description=feature,\n",
    "    disabled=False\n",
    "    )\n",
    "    for feature in target]\n",
    "    \n",
    "    box_features.children=items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Requ. experiments (mean)','Requ. experiments (std)','Requ. experiments (90%)',\n",
    "                                  'Requ. experiments (max)','Algorithm','Utlity Function','Ïƒ Factor',\n",
    "                                  'qant. (distance utility)','# SL runs','Initial Sample','# of samples in the DS',\n",
    "                                  '# Features','# Targets', 'Target threshold','Sample threshold','Features name','Targets name',\n",
    "                                  'Req. experiments (all)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sequential_learning:\n",
    "    \n",
    "    xlabel=\"Sequential Learning Iteration\"\n",
    "    dataframe = df_converter()\n",
    "    features_df=df_converter()\n",
    "    target_df=df_converter()\n",
    "    min_distances_list=[]\n",
    "    y_pred_dtr_mean=None\n",
    "    y_pred_dtr_std=None\n",
    "    y_pred_dtr=None\n",
    "    SampIdx=None\n",
    "    PredIdx=None\n",
    "    count=0\n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "    def __init__(self,dataframe,init_sample_size,target_treshhold,number_of_executions,sample_treshold,sigma,distance,model,strategy):  #constructor\n",
    "        self.dataframe= dataframe\n",
    "        self.init_sample_size=init_sample_size\n",
    "        self.target_treshhold = target_treshhold/100\n",
    "        self.sample_treshold=sample_treshold/100\n",
    "        self.number_of_executions=number_of_executions\n",
    "        self.tries_list=np.empty(number_of_executions)\n",
    "        self.tries_list_rand_pick=np.empty(number_of_executions)\n",
    "        self.sigma=sigma\n",
    "        self.distance=distance\n",
    "        self.model=model\n",
    "        self.strategy = strategy\n",
    "        \n",
    "        \n",
    "        \n",
    "    def apply_feature_selection_to_df(self,dataframe):\n",
    "        self.features_df = self.dataframe[confirm_features()]    \n",
    "    \n",
    "    def apply_target_selection_to_df(self,dataframe):\n",
    "        self.target_df= self.dataframe[confirm_target()]    \n",
    "\n",
    "\n",
    "    #self werte return macht wenig sinn\n",
    "    def standardize_data(self):\n",
    "        dataframe_norm=(self.dataframe-self.dataframe.mean())/self.dataframe.std()\n",
    "        target_df_norm=(self.target_df-self.target_df.mean())/self.target_df.std()\n",
    "        features_df_norm=(self.features_df-self.features_df.mean())/self.features_df.std()\n",
    "        self.features_df=features_df_norm\n",
    "        self.target_df=target_df_norm\n",
    "        self.dataframe=dataframe_norm\n",
    "        return self.features_df, self.target_df, self.dataframe\n",
    "        \n",
    "\n",
    "\n",
    "    def init_sampling(self):\n",
    "        targets = confirm_target()\n",
    "        fixed_targets=confirm_fixed_target()\n",
    "        sum_ = self.dataframe[targets].sum(axis=1).to_frame()+self.dataframe[fixed_targets].sum(axis=1).to_frame()\n",
    "        samp_q_t=sum_.quantile(self.sample_treshold)\n",
    "        Index_label=np.where(sum_ < samp_q_t )\n",
    "        Index_label=Index_label[0]\n",
    "        init_sample_set = np.ones((0,self.init_sample_size))\n",
    "        \n",
    "        for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    init_sample_set=np.vstack([init_sample_set, random.choice(Index_label,self.init_sample_size)])\n",
    "       \n",
    "        return init_sample_set\n",
    "    \n",
    "    def decide_max_or_min(self):\n",
    "        max_or_min_optimizations_list=[box_features.children[decide].value for decide in range(len(self.target_df.columns))]\n",
    "        return max_or_min_optimizations_list\n",
    "            \n",
    "    def start_sequential_learning(self):\n",
    "            self.tries_list=np.empty(self.number_of_executions)\n",
    "            self.tries_list.fill(np.nan)\n",
    "            self.tries_list_rand_pick=np.empty(self.number_of_executions)\n",
    "            self.tries_list_rand_pick.fill(np.nan)\n",
    "            self.count=0\n",
    "            distances=[]\n",
    "            targt_perfs=[]\n",
    "            fixed_targets=[]\n",
    "            \n",
    "            current_distances_list=[]   \n",
    "            current_targt_perf_list=[]\n",
    "            current_fixed_target_list=[]\n",
    "\n",
    "            \n",
    "            with out_perform_experiment:\n",
    "                    display(Markdown('Sequential Learning is running...'))\n",
    "\n",
    "            init_sample_set=self.init_sampling()\n",
    "            global result_df     \n",
    "            for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    self.perform_random_pick(i)\n",
    "                    self.SampIdx=init_sample_set[i].astype(int)\n",
    "                    self.PredIdx=self.dataframe\n",
    "                    self.PredIdx = self.PredIdx.drop(self.PredIdx.index[self.SampIdx]).index\n",
    "                    self.decide_model(self.model)\n",
    "                    self.tries_list[i]=self.init_sample_size\n",
    "                    decide_optimization=self.decide_max_or_min()\n",
    "\n",
    "                    for k in decide_optimization:\n",
    "                        index_of_target = decide_optimization.index(k)\n",
    "\n",
    "                        if (k == \"minimize\"): \n",
    "                            self.target_df.iloc[:,index_of_target]*(-1)\n",
    "\n",
    "                    #fixed target selection hinzufÃ¼gen\n",
    "                    fixed_targets_index=confirm_fixed_target()\n",
    "                    sum_ = self.dataframe[confirm_target()].sum(axis=1).to_frame()+self.dataframe[fixed_targets_index].sum(axis=1).to_frame()\n",
    "                    targ_q_t= sum_.quantile(self.target_treshhold)\n",
    "\n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                    schwellwert=sum_.quantile(self.target_treshhold)\n",
    "                    Index_c=np.where(sum_ >= schwellwert )\n",
    "                    Index_c=Index_c[0]\n",
    "                    distance=distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_c])\n",
    "                    distance=distance.min()\n",
    "                    current_distances_list=[distance]\n",
    "                    \n",
    "                    #max value summe\n",
    "                    \n",
    "                    targt_perf=sum_.loc[self.SampIdx].max().values\n",
    "                    current_targt_perf_list=[targt_perf] \n",
    "\n",
    "                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                    current_fixed_target_list=[best_value]\n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "                    \n",
    "                    while sum_.loc[self.SampIdx].max().values < targ_q_t.values:\n",
    "                                    \n",
    "                                    self.update_strategy(self.strategy)\n",
    "\n",
    "                                    #Train Model\n",
    "                                    self.decide_model(self.model)\n",
    "\n",
    "                                    schwellwert=sum_.quantile(self.target_treshhold)\n",
    "                                    Index_c=np.where(sum_ >= schwellwert )\n",
    "                                    Index_c=Index_c[0]\n",
    "\n",
    "                                    distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_c])\n",
    "                                    distance=distance.min()\n",
    "                                    current_distances_list.append(distance)\n",
    "\n",
    "                                    targt_perf=sum_.loc[self.SampIdx].max().values.tolist()\n",
    "                                    targt_perf=max(targt_perf)\n",
    "                                    \n",
    "                                    \"\"\"print(\"type target perf\",type(targt_perf))\n",
    "                                    print(\"targt_perf\",targt_perf)\"\"\"\n",
    "                                    current_targt_perf_list.append(targt_perf)\n",
    "                                    \n",
    "                                    \n",
    "                                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                                    current_fixed_target_list.append(best_value)\n",
    "                                    \n",
    "                                    \n",
    "                                    self.tries_list[i]=self.tries_list[i]+1   \n",
    "\n",
    "                    distances.append(current_distances_list)\n",
    "                    targt_perfs.append(current_targt_perf_list)\n",
    "                    \"\"\"print(\"type fixed targ:\",type(fixed_targets))\n",
    "                    print(\"fixed_targets\",fixed_targets)\n",
    "                    print(\"type current_fixed_target_list\",type(current_fixed_target_list))\n",
    "                    print(\"current_fixed_target_list\",current_fixed_target_list)\"\"\"\n",
    "                    fixed_targets.append(current_fixed_target_list)\n",
    "                    \n",
    "\n",
    "                ##Distance Plot\n",
    "                \n",
    "                    with out_perform_experiment:\n",
    "                        fig1,axs = plt.subplots(1,2,figsize=(15, 6))\n",
    "                        axs[0].set_title('Progress per iteration in the input space')\n",
    "                        axs[0].set_xlabel('SL iterations')\n",
    "                        axs[0].set_ylabel(\"Minimum distance from sampled data to target\")\n",
    "                        axs[0].axhline(y=0, color='k', linestyle=':',label='Target')\n",
    "                        axs[0].legend()\n",
    "\n",
    "                        axs[1].set_title('Progress per iteration in the output space')\n",
    "                        axs[1].set_xlabel('SL iterations')\n",
    "                        axs[1].set_ylabel(\"Maximum sampled property\")\n",
    "                        axs[1].axhline(y=targ_q_t.values, color='k', linestyle=':',label='Target (normalized)')\n",
    "                        axs[1].legend()\n",
    "\n",
    "                        #Exten values of perfs\n",
    "                        lengths_of_perfs=[]\n",
    "                        for runs in range(len(targt_perfs)):\n",
    "                                        current_len_of_perf=len(targt_perfs[runs])\n",
    "                                        lengths_of_perfs.append(current_len_of_perf)\n",
    "\n",
    "                        for runs in range(len(targt_perfs)):\n",
    "                                if(len(targt_perfs[runs])!=max(lengths_of_perfs)):\n",
    "                                    size_of_values_to_add =max(lengths_of_perfs)-len(targt_perfs[runs])\n",
    "                                    targt_perfs[runs].extend(np.full(size_of_values_to_add, max(targt_perfs[runs])))\n",
    "\n",
    "\n",
    "                        #Plotting\n",
    "                        for runs in range(len(distances)):\n",
    "                            axs[0].plot(distances[runs],linewidth=8, alpha=0.4)\n",
    "\n",
    "                        for runs in range(len(targt_perfs)):\n",
    "                            axs[1].plot(targt_perfs[runs],linewidth=8, alpha=0.4)\n",
    "                            #plt.close(fig1)\n",
    "\n",
    "\n",
    "                    \"\"\"with out_fixed_targets:\n",
    "                            print(\"fixed_targets\",fixed_targets)\n",
    "                            print(\"type(fixed_targets)\",type(fixed_targets))\n",
    "                            anzahl_plots=len(fixed_target_selection.value)\n",
    "                            fig3,axs_fixed = plt.subplots(anzahl_plots)\n",
    "                            \n",
    "                            for fixed_target in range((anzahl_plots)):\n",
    "                                axs_fixed[fixed_target].plot(fixed_targets,linewidth=8, alpha=0.4)\"\"\"\n",
    "                                \n",
    "                    with out_perform_experiment:\n",
    "                            out_perform_experiment.clear_output(wait=True)\n",
    "                            time.sleep(1.0)\n",
    "                            fig2=plt.figure(figsize=(15, 5))\n",
    "                            plt.xlabel('Number of required Experiments')\n",
    "                            plt.ylabel(\"Frequency\")\n",
    "                            plt.title(\"Performance histogram for %s with strategy %s \"%(self.model,self.strategy))\n",
    "                            #plt.hist([self.tries_list,self.tries_list_rand_pick],bins=len(self.tries_list),label=['SL Tries', 'Random Pick Tries'])         \n",
    "                            plt.hist([self.tries_list_rand_pick],range=(1, len(self.features_df)),label=['Random Process'],alpha=0.4)         \n",
    "                            plt.hist([self.tries_list],label=['SL'],range=(1, len(self.features_df)),alpha=0.4)         \n",
    "                            plt.legend()\n",
    "\n",
    "                            plt.show()\n",
    "                            #plt.close(fig2)\n",
    "\n",
    "\n",
    "            if self.strategy=='MEI (exploit)':\n",
    "                self.sigma=0\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MU (explore)':\n",
    "                self.sigma=1\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MLI (explore & exploit)':\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MEID (exploit)':\n",
    "                self.sigma=0\n",
    "            \n",
    "                \n",
    "            ##Appending Performance intensiv --> List comprehension\n",
    "            to_append=([np.mean(self.tries_list),np.std(self.tries_list),np.quantile(self.tries_list,0.90),\n",
    "                        np.quantile(self.tries_list,1),self.model, self.strategy,self.sigma,self.distance,\n",
    "                        self.number_of_executions,self.init_sample_size,len(self.dataframe.index),len(confirm_features()),\n",
    "                        len(confirm_target()),self.target_treshhold,self.sample_treshold,\n",
    "                    \n",
    "                        \n",
    "                        confirm_features().tolist(),confirm_target().tolist(),self.tries_list])\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            a_series = pd.Series(to_append, index = result_df.columns)\n",
    "            result_df= result_df.append(a_series, ignore_index=True)\n",
    "            ###a\n",
    "            with out_perform_experiment:\n",
    "                        display(Markdown('Sequential Learning performed âœ…'))\n",
    "                        display(Markdown(\" \"))\n",
    "                        display(Markdown('#### Performance SL vs. RP:'))\n",
    "                        display(Markdown('requ. experiments SL (mean):  {} '.format(\n",
    "                        np.mean(self.tries_list))))\n",
    "                        display(Markdown(\"requ. experiments SL (90%): {}\".format(np.quantile(self.tries_list,0.90))))\n",
    "                        display(Markdown(\"requ. experiments RP (mean): {}\".format(np.mean(self.tries_list_rand_pick))))\n",
    "                        display(Markdown(\"requ. experiments RP (90%): {}\".format(np.quantile(self.tries_list_rand_pick,0.90))))\n",
    "                        display(Markdown(\"SL - complete list of requ. experiments in each iteration: {}\".format(self.tries_list)))\n",
    "                        display(Markdown(\"RP - complete list of requ. experiments in each iteration: {}\".format(self.tries_list_rand_pick)))\n",
    "                        display(Markdown(\" \"))\n",
    "                        display(Markdown(\" \"))\n",
    "                        display(Markdown('#### History:'))\n",
    "                        display(Markdown(\" \") )\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            with out_perform_experiment:\n",
    "                        display(Markdown(result_df.to_markdown()))\n",
    "                        display((create_download_link(result_df,'Download History','results_sl')))\n",
    "\n",
    "\n",
    "    def perform_random_pick(self,acutal_iter):\n",
    "        df_rand = self.dataframe.sample()\n",
    "        sum_ = self.dataframe[confirm_target()].sum(axis=1).to_frame()\n",
    "        targ_q_t= sum_.quantile(self.target_treshhold)\n",
    "        rand_sum=sum_.sample(frac=1).to_numpy()\n",
    "        \n",
    "        run=0\n",
    "        df_rand=np.array([-10000])       \n",
    "        self.tries_list_rand_pick[acutal_iter]=0\n",
    "        while df_rand.item() < targ_q_t.item():\n",
    "            df_rand = rand_sum[run]\n",
    "            self.tries_list_rand_pick[acutal_iter]=self.tries_list_rand_pick[acutal_iter]+1 \n",
    "            run=run+1\n",
    "        \n",
    "        \n",
    "    #Refactor idee: Model klasse mit name und checkbox description\n",
    "    def decide_model(self,model):\n",
    "        if model== 'lolo Random Forrest (RF) - quick (requ. min 8 init. samples)':\n",
    "                    Expected_Pred, Uncertainty=  self.fit_RF_wJK()\n",
    "        elif model == 'Decision Trees (DT) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_DT_wJK()\n",
    "        elif model == 'Random Forrest (RFscikit) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_TE_wJK()\n",
    "        elif model == 'Gaussian Process Regression (GPR) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_GP()\n",
    "                    \n",
    "            \n",
    "    def update_strategy(self, strategy):\n",
    "        if strategy=='MEI (exploit)':\n",
    "            self.updateIndexMEI()\n",
    "        elif strategy=='MU (explore)':\n",
    "            self.updateIndexMU()\n",
    "        elif strategy=='MLI (explore & exploit)':\n",
    "            self.updateIndexMLI()\n",
    "        elif strategy=='MEID (exploit)':\n",
    "            self.updateIndexMEID()        \n",
    "        elif strategy=='MLID (explore & exploit)':\n",
    "            self.updateIndexMLID()\n",
    "        \n",
    "    \n",
    "    def updateIndexMEI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame().T\n",
    "            index_max = np.argmax(fixed_targets_in_prediction+self.Expected_Pred)\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "            \n",
    "    def updateIndexMEID(self):\n",
    "            schwellwert=np.quantile(self.Expected_Pred,self.distance/100)\n",
    "            Index_=np.where(self.Expected_Pred>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            \n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "\n",
    "    def updateIndexMLID(self):\n",
    "        \n",
    "            schwellwert=np.quantile((self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()),self.distance/100)\n",
    "            Index_=np.where(self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx            \n",
    "            \n",
    "            \n",
    "    def updateIndexMU(self):\n",
    "            index_max = np.argmax(self.Uncertainty)\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "            \n",
    "    def updateIndexMLI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame().T\n",
    "            \n",
    "            index_max = np.argmax(fixed_targets_in_prediction+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze())\n",
    "\n",
    "            \n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "                        \n",
    "            \n",
    "    def fit_DT_wJK(self):        \n",
    "        td,tl=self.jk_resampling()\n",
    "        self.y_pred_dtr=[]\n",
    "        for i in range(len(td)):\n",
    "            dtr = DecisionTreeRegressor()\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "        \n",
    "       \n",
    "        #quick bug fix\n",
    "        if(self.strategy==\"MEID (exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        elif(self.strategy==\"MLID (explore & exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        else:\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.y_pred_dtr=self.y_pred_dtr.T\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=1)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=1)\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "        \n",
    "    def fit_TE_wJK(self):\n",
    "        td,tl=self.jk_resampling()\n",
    "        self.y_pred_dtr=[]\n",
    "        for i in range(len(td)):\n",
    "            ## alternative Ensamble Learners below:\n",
    "            dtr = SKRFR (n_estimators=10)\n",
    "            #dtr =AdaBoostRegressor(n_estimators = 10)\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "                \n",
    "        \n",
    "        #quick bug fix\n",
    "        if(self.strategy==\"MEID (exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        elif(self.strategy==\"MLID (explore & exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        else:\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.y_pred_dtr=self.y_pred_dtr.T\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=1)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=1)\n",
    "\n",
    "\n",
    "        return self.Expected_Pred, self.Uncertainty        \n",
    "\n",
    "    def jk_resampling(self):\n",
    "        from resample.jackknife import resample as b_resample\n",
    "        td=[x for x in b_resample(self.features_df.iloc[self.SampIdx])]\n",
    "        tl=[x for x in b_resample(self.target_df.iloc[self.SampIdx].sum(axis=1).to_frame())]\n",
    "        td=np.array(td)\n",
    "        tl=np.array(tl)\n",
    "        return td,tl\n",
    "                   \n",
    "    def fit_RF_wJK(self):\n",
    "        dtr = RandomForestRegressor()\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.target_df.iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx].to_numpy(), return_std=True)\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "    \n",
    "    def fit_GP(self):\n",
    "        \n",
    "        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "        dtr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.target_df.iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty= dtr.predict(self.features_df.iloc[self.PredIdx], return_std=True)      \n",
    "        return self.Expected_Pred.squeeze(), self.Uncertainty.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def main(self):\n",
    "        self.apply_feature_selection_to_df(self.dataframe)\n",
    "        self.apply_target_selection_to_df(self.dataframe)\n",
    "        self.standardize_data()\n",
    "        init_sample_set=self.init_sampling()\n",
    "        self.start_sequential_learning()\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sequential_learning(df_converter(),initial_sample_size_text.value,quantile_tar_slider.value,iterations.value,quantile_sample_slider.value,slider_of_for_std.value,slider_of_for_dist.value,select_model.value,confirm_strategy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_clicked(b):\n",
    "    try:\n",
    "        preview()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def upload_clicked(b):\n",
    "    if(up._counter>1):\n",
    "        up.value.clear()\n",
    "        up._counter = 1\n",
    "    try:\n",
    "        upload()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def desc_clicked(b):\n",
    "    desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_settings_button_clicked(b):\n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        display(Markdown(settings.to_markdown()))\n",
    "        \n",
    "def confirm_import_clicked(b):\n",
    "    if(import_button._counter>1):\n",
    "        up.value.clear()\n",
    "        import_button._counter=1\n",
    "    \n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        out_settings.clear_output(wait=True)\n",
    "        display(Markdown('Your Settings got importet and look like:'))\n",
    "        display(Markdown(settings.to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter_clicked(b):\n",
    "    plot()\n",
    "\n",
    "def pairwise_clicked(b):\n",
    "    plot_pairwise()\n",
    "def heat_clicked(b):\n",
    "    plot_heat()\n",
    "def scatter_clicked(b):\n",
    "    plot_scatter()\n",
    "    \n",
    "def plotterDS_clicked(b):\n",
    "    plot_TSNE_input_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment_clicked(b):\n",
    "    df=df_converter()\n",
    "    s = sequential_learning(df,initial_sample_size_text.value,quantile_tar_slider.value,iterations.value,quantile_sample_slider.value,slider_of_for_std.value,slider_of_for_dist.value,select_model.value,confirm_strategy())\n",
    "    start_and_stop_sl_container.children=[button_perform_experiment]\n",
    "    s.main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_value_change(change):\n",
    "    quantile_sample_slider.max=quantile_tar_slider.value\n",
    "    \n",
    "def on_strategy_changes(change):\n",
    "    if select_strategy.value==\"MEID (exploit)\":\n",
    "        create_slider_for_dist_quantile()\n",
    "    elif select_strategy.value==\"MLID (explore & exploit)\":  \n",
    "        create_slider_for_dist_quantile_std()\n",
    "    elif select_strategy.value==\"MLI (explore & exploit)\":\n",
    "        create_slider_for_std()\n",
    "        \n",
    "def display_progess_automation(actual_iter,all_comb):\n",
    "    with out_iter_aut:\n",
    "            time.sleep(0.1)\n",
    "            out_iter_aut.clear_output()\n",
    "            display(Markdown('\\n Status  {}/{} \\n'.format(\n",
    "                        actual_iter+1,all_comb)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def confirm_features_clicked(b):\n",
    "    confirm_features()\n",
    "    \n",
    "def confirm_target_clicked(b):\n",
    "    confirm_target()\n",
    "\n",
    "def confirm_fixed_target_clicked(b):\n",
    "    confirm_fixed_target()\n",
    "    \n",
    "def on_graph_type_change(change):\n",
    "        \n",
    "    if graph_type.value ==\"Scatter\":\n",
    "        container_plot_options.children= [HBox([select_x,select_y]),\n",
    "        HBox([select_hue,select_size])]\n",
    "    elif graph_type.value ==\"Scatter Matrix\":\n",
    "        \n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "                                          \n",
    "    elif graph_type.value =='Correlation Heatmap':\n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "        \n",
    "    else: container_plot_options.children=[]\n",
    "\n",
    "\n",
    "def confirm_var_clicked(b):\n",
    "    confirm_var()\n",
    "\n",
    "def confirm_options_clicked(b):\n",
    "    confirm_options()\n",
    "\n",
    "def confirm_strategy_clicked(b):\n",
    "    confirm_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_settings(settings):\n",
    "    sl_runs_for_sl_arena=settings[\"SL-Runs\"].iloc[0]\n",
    "    list_of_init_sample_sizes=settings[\"Initial Sample Sizes\"].map(lambda x: x.split(\" \"))\n",
    "    list_of_init_sample_sizes=flatten_list(list_of_init_sample_sizes)\n",
    "    list_of_init_sample_sizes=[int(x.replace(\"[\",\"\").replace(\"]\",\"\")) for x in list_of_init_sample_sizes]\n",
    "    \n",
    "    list_of_target_treshholds=settings[\"Target Treshholds\"].map(lambda x: x.split(\" \"))\n",
    "    list_of_target_treshholds=flatten_list(list_of_target_treshholds)\n",
    "    list_of_target_treshholds=[float(x.replace(\"[\",\"\").replace(\"]\",\"\")) for x in list_of_target_treshholds]\n",
    "    \n",
    "    list_of_sample_tresholds=settings[\"Sample Treshholds\"].map(lambda x: x.split(\" \"))\n",
    "    list_of_sample_tresholds=flatten_list(list_of_sample_tresholds)\n",
    "    list_of_sample_tresholds=[float(x.replace(\"[\",\"\").replace(\"]\",\"\")) for x in list_of_sample_tresholds]\n",
    "    \n",
    "    list_of_sigmas=settings[\"Ïƒ Factors\"].map(lambda x: x.split(\" \"))\n",
    "    list_of_sigmas=flatten_list(list_of_sigmas)\n",
    "    list_of_sigmas=[float(x.replace(\"[\",\"\").replace(\"]\",\"\")) for x in list_of_sigmas]\n",
    "    \n",
    "    list_of_distances=settings[\"qant. (distance utility)\"].map(lambda x: x.split(\" \"))\n",
    "    list_of_distances=flatten_list(list_of_distances)\n",
    "    list_of_distances=[x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\") for x in list_of_distances]\n",
    "    list_of_distances=list(filter(None,list_of_distances))\n",
    "    list_of_distances=[float(x) for x in list_of_distances]\n",
    "    \n",
    "    all_selected_models_with_name=list(settings[\"Models\"])\n",
    "    all_selected_models_with_name=[x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"'\",\"\") for x in all_selected_models_with_name]\n",
    "    \n",
    "    return sl_runs_for_sl_arena,list_of_init_sample_sizes,list_of_target_treshholds,list_of_sample_tresholds,list_of_sigmas,list_of_distances,all_selected_models_with_name\n",
    "    \n",
    "def perform_automated_sl_with_temp(b):\n",
    "    all_models=[checkbox_gp,checkbox_dt,checkbox_rf,checkbox_rf_scikit]\n",
    "    temp_settings=import_settings()\n",
    "    sl_runs_for_sl_arena,list_of_init_sample_sizes,list_of_target_treshholds,list_of_sample_tresholds,list_of_sigmas,list_of_distances,all_selected_models_with_name=parse_settings(temp_settings)\n",
    "    iteration=0\n",
    "    amount_combinations= len(list_of_init_sample_sizes)*len(list_of_target_treshholds)*len(list_of_sample_tresholds)*len(list_of_sigmas)*len(list_of_distances)*len(all_selected_models_with_name)\n",
    "    for current_init_sample_size in list_of_init_sample_sizes:\n",
    "        for current_tar_tresh in list_of_target_treshholds:\n",
    "            for current_samp_tresh in list_of_sample_tresholds:\n",
    "                for current_sigma in list_of_sigmas:\n",
    "                    for current_distance in list_of_distances:\n",
    "                        for current_model in all_selected_models_with_name:\n",
    "                                s_aut=sequential_learning(df_converter(),current_init_sample_size,current_tar_tresh,sl_runs_for_sl_arena,current_samp_tresh,current_sigma,current_distance,current_model,'MLID (explore & exploit)')\n",
    "                                s_aut.main()\n",
    "                                iteration=iteration+1\n",
    "                                with out_settings:\n",
    "                                    display(Markdown('\\n  {} / {} \\n'.format(iteration,amount_combinations)))\n",
    "    \n",
    "    settings_df=pd.DataFrame(columns=['SL-Runs','Initial Sample Sizes','Target Treshholds','Sample Treshholds','Ïƒ Factors','qant. (distance utility)','Models'])\n",
    "    settings_to_append=([sl_runs_for_sl_arena,list_of_init_sample_sizes,list_of_target_treshholds,list_of_sample_tresholds,list_of_sigmas,list_of_distances,all_selected_models_with_name])\n",
    "    settings_series = pd.Series(settings_to_append, index = settings_df.columns)\n",
    "    settings_df= settings_df.append(settings_series, ignore_index=True)\n",
    "    \n",
    "    with out_settings:\n",
    "        out_settings.clear_output()\n",
    "        display((create_download_link(settings_df,'Download the settings','settings')))\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "def perform_automated_sl(b):\n",
    "    all_models=[checkbox_gp,checkbox_dt,checkbox_rf,checkbox_rf_scikit]\n",
    "    \n",
    "    all_starts=[start_init_samp.value,start_tar_tresh.value,start_samp_tresh.value,start_utility_distance.value,start_sigma.value]\n",
    "    all_steps=[step_init_samp.value,step_tar_tresh.value,step_samp_tresh.value,step_utility_distance.value,step_sigma.value]\n",
    "    all_stops=[stop_init_samp.value,stop_tar_tresh.value,stop_samp_tresh.value,stop_utility_distance.value,stop_sigma.value]\n",
    "    param_matrix=np.array((all_starts,all_steps,all_stops))\n",
    "    \n",
    "    if(sl_runs_for_sl_arena.value == 0):\n",
    "                 with out_iter_aut:\n",
    "                    display(Markdown('SL Runs must be greater than 0! ðŸ’¡ '))\n",
    "    \n",
    "        \n",
    "    \n",
    "    if(specify_init_sample_size.value is False):\n",
    "        list_of_init_sample_sizes=np.arange(start_init_samp.value,stop_init_samp.value,step_init_samp.value)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        #list_of_floats = [float(item) for item in a_list]\n",
    "        list_of_init_sample_sizes=[int(item) for item in list_init_samp.value.split(';')]\n",
    "        \n",
    "    \n",
    "    \n",
    "    if(specify_target_treshhold.value is False):\n",
    "        list_of_target_treshholds=np.arange(start_tar_tresh.value,stop_tar_tresh.value+0.0001,step_tar_tresh.value)\n",
    "    else:\n",
    "        list_of_target_treshholds=[float(item) for item in list_tar_tresh.value.split(';')]\n",
    "         \n",
    "            \n",
    "            \n",
    "    if(specify_sample_threshold.value is False):\n",
    "        list_of_sample_tresholds=np.arange(start_samp_tresh.value,stop_samp_tresh.value+0.0001,step_samp_tresh.value)\n",
    "    else:\n",
    "        list_of_sample_tresholds=[float(item) for item in list_samp_tresh.value.split(';')]\n",
    "            \n",
    "            \n",
    "    if(specify_sigma.value is False):\n",
    "        list_of_sigmas=np.arange(start_sigma.value,stop_sigma.value+0.0001,step_sigma.value)\n",
    "    else:\n",
    "        list_of_sigmas=[float(item) for item in list_sigma_factor.value.split(';')]\n",
    "            \n",
    "            \n",
    "    if(specify_distance.value is False):\n",
    "        list_of_distances=np.arange(start_utility_distance.value,stop_utility_distance.value+0.0001,step_utility_distance.value)\n",
    "    else:\n",
    "        list_of_distances=[float(item) for item in list_utility_distance.value.split(';')]\n",
    "    \n",
    "    models_selected_counter=0\n",
    "    all_selected_models_with_name=[]\n",
    "    for model in all_models: \n",
    "        if(model.value is True):\n",
    "            models_selected_counter=models_selected_counter+1\n",
    "            all_selected_models_with_name.append(model.description)\n",
    "            \n",
    "    iteration=0\n",
    "    \n",
    "    amount_combinations= len(list_of_init_sample_sizes)*len(list_of_target_treshholds)*len(list_of_sample_tresholds)*len(list_of_sigmas)*len(list_of_distances)*models_selected_counter\n",
    "    \n",
    "    for current_init_sample_size in list_of_init_sample_sizes:\n",
    "        for current_tar_tresh in list_of_target_treshholds:\n",
    "            for current_samp_tresh in list_of_sample_tresholds:\n",
    "                for current_sigma in list_of_sigmas:\n",
    "                    for current_distance in list_of_distances:\n",
    "                        for current_model in all_models:\n",
    "                            if(current_model.value is True):\n",
    "                                s_aut=sequential_learning(df_converter(),current_init_sample_size,current_tar_tresh,sl_runs_for_sl_arena.value,current_samp_tresh,current_sigma,current_distance,current_model.description,'MLID (explore & exploit)')\n",
    "                                s_aut.main()\n",
    "                                iteration=iteration+1\n",
    "                                with out_iter_aut:\n",
    "                                    out_iter_aut.clear_output()\n",
    "                                    display(Markdown('\\n  {} / {} \\n'.format(iteration,amount_combinations)))\n",
    "     \n",
    "        \n",
    "    settings_df=pd.DataFrame(columns=['SL-Runs','Initial Sample Sizes','Target Treshholds','Sample Treshholds','Ïƒ Factors','qant. (distance utility)','Models'])\n",
    "    settings_to_append=([sl_runs_for_sl_arena.value,list_of_init_sample_sizes,list_of_target_treshholds,list_of_sample_tresholds,list_of_sigmas,list_of_distances,all_selected_models_with_name])\n",
    "    settings_series = pd.Series(settings_to_append, index = settings_df.columns)\n",
    "    settings_df= settings_df.append(settings_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    with out_iter_aut:\n",
    "        out_iter_aut.clear_output()\n",
    "        display((create_download_link(settings_df,'Download the settings','settings')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "button_upload.on_click(upload_clicked)\n",
    "toggle.observe(desc_clicked, 'value')\n",
    "button_preview.on_click(preview_clicked)\n",
    "\n",
    "button_confirm_plot_var.on_click(confirm_var_clicked)\n",
    "button_confirm_feature.on_click(confirm_features_clicked)\n",
    "button_confirm_target.on_click(confirm_target_clicked)\n",
    "button_confirm_fixed_target.on_click(confirm_fixed_target_clicked)\n",
    "\n",
    "graph_type.observe(on_graph_type_change,names='value')\n",
    "quantile_tar_slider.observe(on_value_change,names='value')\n",
    "\n",
    "run_button_aut.on_click(perform_automated_sl)\n",
    "run_button_aut_template.on_click(perform_automated_sl_with_temp)\n",
    "\n",
    "\n",
    "button_show_DS.on_click(confirm_target_clicked)\n",
    "select_strategy.observe(on_strategy_changes,names=\"value\")\n",
    "\n",
    "button_confirm_options.on_click(confirm_options_clicked)\n",
    "button_confirm_strategy.on_click(confirm_strategy_clicked)\n",
    "\n",
    "preview_settings_button.on_click(preview_settings_button_clicked)\n",
    "button_perform_experiment.on_click(perform_experiment_clicked)\n",
    "confirm_import_button.on_click(confirm_import_clicked)\n",
    "\n",
    "button_plot.on_click(plotter_clicked)\n",
    "button_show_DS.on_click(plotterDS_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e436800d8cb4e77aa98ae4a2c7ceabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Accordion(children=(FileUpload(value={}, description='Upload'), HBox(children=(Raâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d82e77fc0f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfirm_fixed_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-3036020a7424>\u001b[0m in \u001b[0;36mconfirm_fixed_target\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconfirm_fixed_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mfixed_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_target_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfixed_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "confirm_fixed_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
