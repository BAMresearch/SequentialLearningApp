{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### *Sequential Learning Benchmarking App*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from ipywidgets import FloatText,Checkbox,ToggleButtons,Dropdown,VBox,HBox,Accordion,BoundedIntText,SelectMultiple,RadioButtons,Button,IntSlider,Label,Tab,Output,FileUpload,Layout,FloatSlider\n",
    "from IPython.display import display,Markdown,HTML\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor as SKRFR\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Tab\n",
    "tab = Tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Outputs\n",
    "out = Output()\n",
    "out_plotting = Output()\n",
    "out_settings = Output()\n",
    "out_algo = Output()\n",
    "out_perform_experiment = Output()\n",
    "out_input_space = Output()\n",
    "out_res = Output()\n",
    "out_iter_aut = Output()\n",
    "out_results_SL = Output()\n",
    "out_app = Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#File Upload\n",
    "up = FileUpload(accept=\"\", multiple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Upload Properties \n",
    "delim = RadioButtons(\n",
    "    options=[',', ';', ' '],\n",
    "    description='Separator: ',\n",
    "    disabled=False)\n",
    "delim_dec = RadioButtons(\n",
    "    options=['.', ','],\n",
    "    description='Decimal delim: ',\n",
    "    disabled=False)\n",
    "\n",
    "eraser = SelectMultiple(\n",
    "    options=['tab', '\"', \"%\"],\n",
    "    value=['tab'],\n",
    "    #rows=10,\n",
    "    description='Eraser: ',\n",
    "    disabled=False)\n",
    "rows = IntSlider(\n",
    "    value=0,\n",
    "    step=1,\n",
    "    description='# of lines:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Data Info \n",
    "toggle = ToggleButtons(\n",
    "    options=['Preview  ', 'Info  ', 'Stats  '],\n",
    "    description='Options',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    icons=['search', 'info', 'tachometer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Selection of Targets and Features\n",
    "feature_selector = SelectMultiple(\n",
    "    options=[],\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "feature_selector_application = SelectMultiple(\n",
    "    options=[],\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "target_selection = SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "target_selection_application = SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "fixed_target_selection = SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "fixed_target_selection_application = SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "selector_plot_variable = SelectMultiple(\n",
    "    options=[],\n",
    "    description='Features',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "graph_type = Dropdown(\n",
    "    options=['Choose graph type', 'Scatter', 'Scatter Matrix', 'Correlation Heatmap'],\n",
    "    value='Choose graph type',\n",
    "    description='Graph type:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "x_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='X-Axis:',\n",
    "    disabled=False)\n",
    "y_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False)\n",
    "\n",
    "select_x = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select X-axis',\n",
    "    description='X-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_y = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select Y-axis',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_hue = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the hue',\n",
    "    description='Hue:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_size = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the size',\n",
    "    description='Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "container_checkboxes_targets = VBox([])\n",
    "container_checkboxes_fixed_targets = VBox([])\n",
    "\n",
    "container_slider_targets = VBox([])\n",
    "container_slider_fixed_targets = VBox([])\n",
    "\n",
    "box_targets = VBox([])\n",
    "box_fixed_targets = VBox([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Sequential Learning Properties\n",
    "select_strategy = Dropdown(\n",
    "    options=['MEI (exploit)', 'MLI (explore & exploit)'],\n",
    "    value='MEI (exploit)',\n",
    "    placeholder='select the strategy',\n",
    "    description='Strategy:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "slider_of_for_std_App = FloatSlider(\n",
    "    value=2,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=0.1,\n",
    "    #description='curiosity (to controll the weigth of uncertainty):',\n",
    "    tooltip='To controll the weigth of model uncertainty',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "select_model = Dropdown(\n",
    "    options=['Lolo Random Forrest', 'Gaussian Process Regression','Tuned Gauss',\n",
    "             'Tuned RF', 'Gauss with PCA', 'RF with PCA'],\n",
    "    value='Gaussian Process Regression',\n",
    "    placeholder='select the Model',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "Model_containerOne = HBox([slider_of_for_std_App])\n",
    "Model_containerTwo = HBox([select_model])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Buttons\n",
    "\n",
    "button_upload = Button(\n",
    "    description='Upload',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Click to Upload',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_preview = Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to preview',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_plot = Button(\n",
    "    description='Plot',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Click to Plot',\n",
    "    icon='pencil',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "button_show_DS = Button(\n",
    "    description='Show Input Data',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Shows you input data for the chosen dataset',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%', height='inherit'))\n",
    "\n",
    "button_confirm_plot_var = Button(\n",
    "    description='Confirm selection',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm the selected target variable',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%', height='inherit'))\n",
    "\n",
    "button_plot_comparision = Button(\n",
    "    description='Compare',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Simplify the Columns',\n",
    "    icon='fa-bar-chart',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_confirm_options = Button(\n",
    "    description='Confirm options ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm options',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%', height='inherit'))\n",
    "\n",
    "button_perform_experiment = Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "button_application = Button(\n",
    "    description='Make Prediction',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Layout File Upload Tab\n",
    "\n",
    "accordion = Accordion(children=[\n",
    "    up,\n",
    "    HBox([delim, delim_dec, eraser]),\n",
    "    rows])\n",
    "\n",
    "accordion.set_title(0, 'File Selection')\n",
    "accordion.set_title(1, 'Delimiter')\n",
    "accordion.set_title(2, 'Skip Rows')\n",
    "\n",
    "accordion_box = VBox([\n",
    "    accordion,\n",
    "    HBox([button_preview, button_upload]),\n",
    "    out\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plotting Tab\n",
    "\n",
    "container_plot_options = VBox([])\n",
    "button_container = HBox([button_plot])\n",
    "\n",
    "plotting = VBox(children=[VBox([\n",
    "    HBox([graph_type]),\n",
    "    container_plot_options,\n",
    "    button_container,\n",
    "    out_plotting\n",
    "]\n",
    ")])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Sequential Learning Tab \n",
    "\n",
    "slider_of_for_dist = FloatSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Prediction quantile for distance-based utility (smaller values recommended for weak predictors).:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "slider_of_for_std = FloatSlider(\n",
    "    value=2,\n",
    "    min=0,\n",
    "    max=5,\n",
    "    step=0.1,\n",
    "    description='Ïƒ Factor (to controll the weigth of uncertainty):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "quantile_tar_slider = FloatSlider(\n",
    "    value=95,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Target Quantile:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "initial_sample_size_text = BoundedIntText(\n",
    "    value=4,\n",
    "    min=2,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Initial Sample Set Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    "\n",
    ")\n",
    "\n",
    "batch_size_text = BoundedIntText(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Batch Size',\n",
    "    tooltip='# of simultanious experiments',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    "\n",
    ")\n",
    "\n",
    "box_features_slider = VBox([])\n",
    "\n",
    "plottingDS = VBox(children=[VBox([\n",
    "\n",
    "    out_input_space\n",
    "]\n",
    ")])\n",
    "\n",
    "DataPre_sl = VBox([\n",
    "    HBox([Label('Materials Data (Input)', font=('bold'), layout=Layout(width='50%', height='80px')),\n",
    "          (feature_selector)]),\n",
    "    HBox([Label('Target Properties', font=('bold'), layout=Layout(width='50%', height='80px')), target_selection]),\n",
    "    box_targets,\n",
    "    HBox([Label('A-priori Information', font=('bold'), layout=Layout(width='50%', height='80px')),\n",
    "          fixed_target_selection]),\n",
    "    box_fixed_targets,\n",
    "    HBox([quantile_tar_slider, button_show_DS]),\n",
    "    plottingDS\n",
    "])\n",
    "\n",
    "DataPre = VBox([\n",
    "    HBox([feature_selector]),\n",
    "    HBox([target_selection]),\n",
    "    box_targets,\n",
    "    HBox([fixed_target_selection]),\n",
    "    box_fixed_targets,\n",
    "])\n",
    "\n",
    "iterations = IntSlider(\n",
    "    value=25,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='# of SL runs:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout=Layout(width='100%')\n",
    ")\n",
    "\n",
    "custom_container = VBox([HBox([])])\n",
    "results_container = VBox([HBox([])])\n",
    "InitSampCon_container = HBox([initial_sample_size_text, batch_size_text])\n",
    "\n",
    "strategy_container = HBox([select_strategy])\n",
    "\n",
    "start_and_stop_sl_container = HBox([button_perform_experiment])\n",
    "\n",
    "sl_settings = VBox([Label('Configure Experiments'),\n",
    "                    Label(' '),\n",
    "                    iterations,\n",
    "                    InitSampCon_container,\n",
    "                    Label(' '),\n",
    "                    Label(' '),\n",
    "                    Label('Configure Algorithm'),\n",
    "                    Label(' '),\n",
    "                    custom_container,\n",
    "                    select_model,\n",
    "                    strategy_container,\n",
    "                    start_and_stop_sl_container,\n",
    "                    Label(' '),\n",
    "                    Label(' '),\n",
    "                    Label('SL Status'),\n",
    "                    out_perform_experiment,\n",
    "\n",
    "                    ])\n",
    "\n",
    "#initial_sample_size_text\n",
    "\n",
    "sl_results = VBox([\n",
    "    out_results_SL\n",
    "])\n",
    "\n",
    "sl_accordion = Accordion(children=[DataPre_sl, sl_settings, sl_results])\n",
    "sl_accordion.set_title(0, \"Configure Optimization\")\n",
    "sl_accordion.set_title(1, \"Sequential Learning\")\n",
    "sl_accordion.set_title(2, \"Results\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Layout Tabs\n",
    "\n",
    "children = [\n",
    "    accordion_box,\n",
    "    VBox([toggle, out]),\n",
    "    plotting,\n",
    "    sl_accordion,\n",
    "\n",
    "]\n",
    "\n",
    "tab.children = children"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Naming Tabs\n",
    "\n",
    "tab.set_title(0, \"ðŸ—‚ Upload\")\n",
    "tab.set_title(1, \"ðŸ”Ž Data Info\")\n",
    "tab.set_title(2, \"ðŸ“Š Design Space Explorer\")\n",
    "tab.set_title(3, \"ðŸ¤– Benchmarking\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Utility Methods\n",
    "def decide_max_or_min(source, columns, dataframe):\n",
    "    row_list = [source.children[decide].children[0].value for decide in range(len(columns))]\n",
    "\n",
    "    for column in range(len(columns)):\n",
    "        if (row_list[column] == \"minimize\"):\n",
    "            dataframe[columns[column]] = dataframe[columns[column]] * (-1)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def extend(list_of_2dms_arrays_to_extend):\n",
    "    np_array = np.array(list_of_2dms_arrays_to_extend)\n",
    "    max_cols = max(map(len, np_array))\n",
    "    result_list = []\n",
    "    for i in np_array:\n",
    "        if (len(i) == max_cols):\n",
    "            result_list.append(i)\n",
    "        elif (len(i) != max_cols):\n",
    "            how_often = max_cols - len(i)\n",
    "            matrix_to_extend = np.tile(i[:][-1], (how_often, 1))\n",
    "            i = np.concatenate((i, matrix_to_extend))\n",
    "            result_list.append(i)\n",
    "\n",
    "    return result_list\n",
    "\n",
    "\n",
    "def content_parser(source):\n",
    "    if source.value == {}:\n",
    "        \"\"\"with out:\n",
    "            out.clear_output\n",
    "            display(Markdown('No CSV loaded'))\n",
    "            #print('No CSV loaded')    \"\"\"\n",
    "    else:\n",
    "        from io import StringIO\n",
    "        typ, content = \"\", \"\"\n",
    "        up_value = source.value\n",
    "        for i in up_value.keys():\n",
    "            typ = up_value[i][\"metadata\"][\"type\"]\n",
    "\n",
    "            if typ == \"text/csv\" or typ == \"application/vnd.ms-excel\":\n",
    "                content = up_value[i][\"content\"]\n",
    "                content_str = str(content, 'utf-8')\n",
    "\n",
    "                if eraser.value != {}:\n",
    "                    for val in eraser.value:\n",
    "                        if val == \"tab\":\n",
    "                            content_str = content_str.replace(\"\\t\", \"\")\n",
    "                        elif val == \"%\":\n",
    "                            content_str = content_str.replace(\"\\t\", \"\")\n",
    "                        else:\n",
    "                            content_str = content_str.replace(val, \"\")\n",
    "                if content_str != \"\":\n",
    "                    str_io = StringIO(content_str)\n",
    "                    return str_io\n",
    "\n",
    "\n",
    "def df_converter():\n",
    "    content = content_parser(up)\n",
    "\n",
    "    up_value = up.value\n",
    "    for i in up_value.keys():\n",
    "        typ = up_value[i][\"metadata\"][\"type\"]\n",
    "        if (typ == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"):\n",
    "            main_key = list(up.value.keys())\n",
    "            if (main_key):\n",
    "                return pd.read_excel(up.value.get(main_key[0]).get('content'))\n",
    "\n",
    "        else:\n",
    "            if content is not None:\n",
    "                df = pd.read_csv(content, sep=delim.value, index_col=False, skiprows=rows.value,\n",
    "                                 decimal=delim_dec.value)\n",
    "                df = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "                return df\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "\n",
    "def preview():\n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('Selected Targets'))\n",
    "\n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "\n",
    "def upload():\n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is how your uploaded data looks like:'))\n",
    "\n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "            x_axis.options = df.columns\n",
    "            y_axis.options = df.columns\n",
    "            feature_selector.options = df.columns\n",
    "            feature_selector_application.options = df.columns\n",
    "\n",
    "            select_x.options = df.columns\n",
    "            select_y.options = df.columns\n",
    "            select_size.options = df.columns\n",
    "            select_hue.options = df.columns\n",
    "            selector_plot_variable.options = df.columns\n",
    "\n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "\n",
    "def create_download_link(df, title, filename):\n",
    "    import base64\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html_buttons = '''<html>\n",
    "    <head>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    </head>\n",
    "    <body>\n",
    "    <a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-warning\">{title}</button>\n",
    "    </a>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    html_button = html_buttons.format(payload=payload, filename=filename, title=title)\n",
    "    return HTML(html_button)\n",
    "\n",
    "\n",
    "def desc():\n",
    "    info_level = toggle.value\n",
    "    if info_level != {}:\n",
    "        df = df_converter()\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown('\\n Data {} \\n'.format(\n",
    "                info_level)))\n",
    "            if df is not None:\n",
    "                if info_level == 'Info  ':\n",
    "                    df.info()\n",
    "                elif info_level == 'Stats  ':\n",
    "                    display(Markdown(df.describe().to_markdown()))\n",
    "                elif info_level == 'Preview  ':\n",
    "                    display(Markdown(df.head(10).to_markdown()))\n",
    "                else:\n",
    "                    display(Markdown('Configuration is wrong/missing...'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Plotting Methods\n",
    "\n",
    "def plot():\n",
    "    graph = graph_type.value\n",
    "    if graph == \"Scatter\":\n",
    "        plot_scatter()\n",
    "    elif graph == \"Correlation Heatmap\":\n",
    "        plot_heat()\n",
    "    elif graph == \"Scatter Matrix\":\n",
    "        plot_pairwise()\n",
    "\n",
    "\n",
    "def plot_pairwise():\n",
    "    df = confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        sns.pairplot(df)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_heat():\n",
    "    df = confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        corr = df.corr()\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "        b, t = plt.ylim()\n",
    "        plt.ylim(b + 0.5, t - 0.5)\n",
    "        plt.title(\"Feature Correlation Heatmap\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_scatter():\n",
    "    data = df_converter()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        #not generic\n",
    "        sns.scatterplot(y=select_y.value, x=select_x.value, hue=select_hue.value, size=select_size.value, data=data,\n",
    "                        ax=ax, sizes=(50, 300))\n",
    "        ax.set_title(select_y.value + \"vs\" + select_x.value)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "        plt.show()\n",
    "        plt.close(fig)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def confirm_options():\n",
    "    items = box_features_slider.children\n",
    "    df = df_converter()\n",
    "    Y = df.loc[:, df.columns.isin(target_selection.value)]\n",
    "\n",
    "    for slider in items:\n",
    "        unt_grenz = slider.value[0] / 100\n",
    "        ob_grenz = slider.value[1] / 100\n",
    "        Y = Y[(Y >= Y.quantile(unt_grenz)) & (Y <= Y.quantile(ob_grenz))]\n",
    "        Y = Y.dropna()\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "def confirm_features(source):\n",
    "    df = df_converter()\n",
    "    train = source.value\n",
    "    target_selection.options = df.columns[~df.columns.isin(feature_selector.value)]\n",
    "\n",
    "    target_selection_application.options = df.columns[~df.columns.isin(feature_selector_application.value)]\n",
    "\n",
    "    fixed_target_selection.options = df.columns[\n",
    "        ~df.columns.isin(target_selection.value) & ~df.columns.isin(feature_selector.value)]\n",
    "    fixed_target_selection_application.options = df.columns[\n",
    "        ~df.columns.isin(target_selection_application.value) & ~df.columns.isin(feature_selector_application.value)]\n",
    "\n",
    "    train = df.columns[df.columns.isin(source.value)]\n",
    "\n",
    "    return train\n",
    "\n",
    "\n",
    "def confirm_var():\n",
    "    df = df_converter()\n",
    "    selection = list(selector_plot_variable.value)\n",
    "    var = df[selection]\n",
    "\n",
    "    return var\n",
    "\n",
    "\n",
    "def confirm_target(source):\n",
    "    #target_selection\n",
    "    df = df_converter()\n",
    "    target = df.columns[df.columns.isin(source.value)]\n",
    "\n",
    "    fixed_target_selection.options = df.columns[\n",
    "        ~df.columns.isin(source.value) & ~df.columns.isin(feature_selector.value)]\n",
    "\n",
    "    fixed_target_selection_application.options = df.columns[\n",
    "        ~df.columns.isin(target_selection_application.value) & ~df.columns.isin(feature_selector_application.value)]\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "def confirm_fixed_target(source):\n",
    "    df = df_converter()\n",
    "    fixed_target = df.columns[df.columns.isin(source.value)]\n",
    "\n",
    "    return fixed_target\n",
    "\n",
    "\n",
    "def confirm_strategy():\n",
    "    strategy = select_strategy.value\n",
    "    if strategy != {}:\n",
    "        custom_container.children = []\n",
    "        return select_strategy.value\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_slider_for_dist_quantile():\n",
    "    strategy_container.children = [select_strategy, slider_of_for_dist]\n",
    "\n",
    "\n",
    "def create_slider_for_dist_quantile_std():\n",
    "    strategy_container.children = [select_strategy, slider_of_for_dist, slider_of_for_std]\n",
    "\n",
    "\n",
    "def create_slider_for_std():\n",
    "    strategy_container.children = [select_strategy, slider_of_for_std]\n",
    "\n",
    "\n",
    "def create_dynamically_elems(targets):\n",
    "    radiobuttons = [RadioButtons(\n",
    "        options=['maximize', 'minimize'],\n",
    "        value='maximize',\n",
    "        description=feature,\n",
    "        disabled=False\n",
    "    )\n",
    "        for feature in targets]\n",
    "\n",
    "    weights = [FloatText(\n",
    "        value=1.,\n",
    "        continuous_update=True,\n",
    "        description=\"weight \" + feature,\n",
    "        disabled=False)\n",
    "        for feature in targets]\n",
    "\n",
    "    weights_np = np.array(weights)\n",
    "\n",
    "    radiobuttons_np = np.array(radiobuttons)\n",
    "\n",
    "    return radiobuttons_np, weights_np\n",
    "\n",
    "\n",
    "def create_dynamically_checkboxes(targets):\n",
    "    radiobuttons = [RadioButtons(\n",
    "        options=['maximize', 'minimize'],\n",
    "        value='maximize',\n",
    "        description=feature,\n",
    "        disabled=False\n",
    "    )\n",
    "        for feature in targets]\n",
    "\n",
    "    checkboxes = [Checkbox(\n",
    "        value=False,\n",
    "        description='Check to use threshold',\n",
    "        disabled=False,\n",
    "        indent=False\n",
    "    )\n",
    "\n",
    "        for feature in targets]\n",
    "\n",
    "    slider = [FloatText(\n",
    "        value=np.max(df_converter()[feature].to_numpy()),\n",
    "        continuous_update=True,\n",
    "        description=feature,\n",
    "        disabled=False)\n",
    "\n",
    "        for feature in targets]\n",
    "\n",
    "    weights = [FloatText(\n",
    "        value=1.,\n",
    "        continuous_update=True,\n",
    "        description=\"weight \" + feature,\n",
    "        disabled=False)\n",
    "        for feature in targets]\n",
    "\n",
    "    weights_np = np.array(weights)\n",
    "    slider_np = np.array(slider)\n",
    "    radiobuttons_np = np.array(radiobuttons)\n",
    "    checkboxes_np = np.array(checkboxes)\n",
    "\n",
    "    return radiobuttons_np, slider_np, checkboxes_np, weights_np\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Req. dev. cycle (mean)', 'Req. dev. cycle (std)', 'Req. dev. cycle (90%)',\n",
    "                                  'Req. dev. cycle (max)', '5 cycle perf.', '10 cycle perf.', 'normalized (MAE)',\n",
    "                                  'normalized (MSE)', 'R^2', 'Batch size', 'Algorithm', 'Utlity function', 'Ïƒ factor',\n",
    "                                  'qant. (distance utility)', '# SL runs', 'Initial sample', '# of samples in the DS',\n",
    "                                  '# Features', '# Targets', 'Target threshold', 'Features name', 'Targets name',\n",
    "                                  'A-priori information',\n",
    "                                  'Req. experiments (list)'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class targets():\n",
    "    checkboxes = None\n",
    "    radiobuttons = None\n",
    "    slider = None\n",
    "    not_stand_df = None\n",
    "    idx = None\n",
    "    min_at = set()\n",
    "    minimize = False\n",
    "    idxs = []\n",
    "\n",
    "    def __init__(self, container, selection, confirm_func, create_elem_func):\n",
    "        self.container = container\n",
    "        self.selection = selection\n",
    "\n",
    "        self.confirm_func = confirm_func\n",
    "        self.create_elem_func = create_elem_func\n",
    "\n",
    "    def on_selection_change(self, change):\n",
    "        self.confirm_func(self.selection)\n",
    "        self.not_stand_df = df_converter()\n",
    "        self.container.children = ()\n",
    "        selection_as_list = list(self.selection.value)\n",
    "\n",
    "        if (self.create_elem_func == create_dynamically_checkboxes):\n",
    "\n",
    "            self.radiobuttons, self.slider, self.checkboxes, self.weights = self.create_elem_func(selection_as_list)\n",
    "            for row in range(len(self.radiobuttons)):\n",
    "                self.container.children = (*self.container.children, HBox(\n",
    "                    [self.radiobuttons[row], self.checkboxes[row], self.slider[row], self.weights[row]]))\n",
    "                self.radiobuttons[row].observe(functools.partial(self.on_radiobutton_changed, row), names='value')\n",
    "                self.checkboxes[row].observe(functools.partial(self.on_checkbox_checked, row), names='value')\n",
    "                self.slider[row].observe(functools.partial(self.on_texfield_typed, row), names='value')\n",
    "        else:\n",
    "\n",
    "            self.radiobuttons, self.weights = self.create_elem_func(selection_as_list)\n",
    "\n",
    "            for row in range(len(self.radiobuttons)):\n",
    "                self.container.children = (*self.container.children, HBox([self.radiobuttons[row], self.weights[row]]))\n",
    "                self.radiobuttons[row].observe(functools.partial(self.on_radiobutton_changed, row), names='value')\n",
    "\n",
    "    def on_radiobutton_changed(self, row, change):\n",
    "\n",
    "        if (self.radiobuttons[row].value == \"minimize\"):\n",
    "\n",
    "            self.min_at.add(list(self.selection.value)[row])\n",
    "\n",
    "            self.minimize = True\n",
    "\n",
    "        else:\n",
    "            self.min_at.remove(list(self.selection.value)[row])\n",
    "\n",
    "            self.minimize = False\n",
    "\n",
    "        if (self.create_elem_func == create_dynamically_checkboxes):\n",
    "            self.on_checkbox_checked(row, change)\n",
    "\n",
    "    def on_texfield_typed(self, row, change):\n",
    "        self.checkboxes[row].value = False\n",
    "\n",
    "    def on_checkbox_checked(self, row, change):\n",
    "\n",
    "        selection_as_list = list(self.selection.value)\n",
    "        if (self.checkboxes[row].value == True):\n",
    "\n",
    "            idx = None\n",
    "\n",
    "            max_df = np.max(df_converter()[selection_as_list[row]].to_numpy())\n",
    "            min_df = np.min(df_converter()[selection_as_list[row]].to_numpy())\n",
    "\n",
    "            if (self.slider[row].value > max_df):\n",
    "                self.slider[row].value = max_df\n",
    "\n",
    "            if (self.slider[row].value < min_df):\n",
    "                self.slider[row].value = min_df\n",
    "\n",
    "            if (self.minimize == True):\n",
    "                df_mask = self.not_stand_df[selection_as_list[row]] < self.slider[row].value\n",
    "            else:\n",
    "                df_mask = self.not_stand_df[selection_as_list[row]] >= self.slider[row].value\n",
    "\n",
    "            temp = self.not_stand_df\n",
    "\n",
    "            if (len(temp[df_mask]) == 0):\n",
    "                print(\"selection false,max min for this feature in this combination is: or change other targets\")\n",
    "            else:\n",
    "                temp = self.not_stand_df[df_mask]\n",
    "                idx = temp[df_mask].index\n",
    "\n",
    "            #check if there is an old idx for this feature  \n",
    "\n",
    "            for idx_tuples in self.idxs:\n",
    "                if (idx_tuples[0] == selection_as_list[row]):\n",
    "                    self.idxs.remove(idx_tuples)\n",
    "\n",
    "            #append new idx in list\n",
    "\n",
    "            self.idxs.append((selection_as_list[row], idx))\n",
    "\n",
    "        if (self.checkboxes[row].value == False):\n",
    "            for idx_tuples in self.idxs:\n",
    "                if (idx_tuples[0] == selection_as_list[row]):\n",
    "                    self.idxs.remove(idx_tuples)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = targets(box_targets, target_selection, confirm_target, create_dynamically_checkboxes)\n",
    "ft = targets(box_fixed_targets, fixed_target_selection, confirm_fixed_target, create_dynamically_checkboxes)\n",
    "tA = targets(box_targets, target_selection_application, confirm_target, create_dynamically_elems)\n",
    "ftA = targets(box_fixed_targets, fixed_target_selection_application, confirm_fixed_target, create_dynamically_elems)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SlamdLoloRF(RandomForestRegressor):\n",
    "\n",
    "    def fit(self, X, y, weigths=None, random_seed=42):\n",
    "        if y.shape[0] < 8:\n",
    "            X = np.tile(X, (4, 1))\n",
    "            y = np.tile(y, (4, 1))\n",
    "        super().fit(X, y, weigths, random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Benchmarking\n",
    "class sequential_learning:\n",
    "    dataframe = df_converter()\n",
    "    features_df = df_converter()\n",
    "    target_df = df_converter()\n",
    "\n",
    "    min_distances_list = []\n",
    "\n",
    "    y_pred_dtr_mean = None\n",
    "    y_pred_dtr_std = None\n",
    "    y_pred_dtr = None\n",
    "    SampIdx = None\n",
    "    PredIdx = None\n",
    "    treshIdx = None\n",
    "\n",
    "    index_sum_randomized = None\n",
    "    rand_tars = []\n",
    "    rand_fixed_tars = []\n",
    "\n",
    "    def __init__(self, dataframe, init_sample_size, batch_size, target_treshhold,\n",
    "                 number_of_executions, sigma, distance,\n",
    "                 model, strategy, targets_idx, fixed_targets_idx):  #constructor\n",
    "\n",
    "        self.dataframe = dataframe\n",
    "        self.init_sample_size = init_sample_size\n",
    "        self.batch_size = batch_size\n",
    "        self.target_treshhold = target_treshhold / 100\n",
    "        self.number_of_executions = number_of_executions\n",
    "        self.tries_list = np.empty(number_of_executions)\n",
    "        self.tries_list_rand_pick = np.empty(number_of_executions)\n",
    "        self.sigma = sigma\n",
    "        self.distance = distance\n",
    "        self.model = model\n",
    "        self.strategy = strategy\n",
    "        self.targets_idx = targets_idx\n",
    "        self.fixed_targets_idx = fixed_targets_idx\n",
    "        #self.best_params = []\n",
    "\n",
    "    def apply_feature_selection_to_df(self, dataframe):\n",
    "        self.features_df = self.dataframe[confirm_features(feature_selector)]\n",
    "\n",
    "    def apply_target_selection_to_df(self, dataframe):\n",
    "        self.target_df = self.dataframe[confirm_target(target_selection)]\n",
    "\n",
    "        #self werte return macht wenig sinn\n",
    "\n",
    "    def standardize_data(self):\n",
    "        dataframe_norm = (self.dataframe - self.dataframe.mean()) / self.dataframe.std()\n",
    "        target_df_norm = (self.target_df - self.target_df.mean()) / self.target_df.std()\n",
    "        features_df_norm = (self.features_df - self.features_df.mean()) / self.features_df.std()\n",
    "        self.features_df = features_df_norm\n",
    "        self.target_df = target_df_norm\n",
    "        self.dataframe = dataframe_norm\n",
    "        return self.features_df, self.target_df, self.dataframe\n",
    "\n",
    "    def init_sampling(self):\n",
    "\n",
    "        targets = confirm_target(target_selection)\n",
    "        fixed_targets = confirm_fixed_target(fixed_target_selection)\n",
    "        df_unnorm = df_converter()\n",
    "        df = (df_unnorm - df_unnorm.mean()) / (df_unnorm.std())\n",
    "        sum_ = self.dataframe[targets].sum(axis=1).to_frame() + self.dataframe[fixed_targets].sum(axis=1).to_frame()\n",
    "        treshholded_idx = self.check_input_variables()\n",
    "        checked_targets = []\n",
    "\n",
    "        if (treshholded_idx):\n",
    "            for row in range(len(t.checkboxes)):\n",
    "                if (t.checkboxes[row].value == True):\n",
    "                    checked_targets.append(t.radiobuttons[row].description)\n",
    "\n",
    "            for row in range(len(ft.checkboxes)):\n",
    "                if (ft.checkboxes[row].value == True):\n",
    "                    checked_targets.append(ft.radiobuttons[row].description)\n",
    "\n",
    "            if not (len(checked_targets) == len(t.checkboxes) + len(ft.checkboxes)):\n",
    "                sum_without_checked_targets = df.drop(columns=checked_targets).sum(axis=1)\n",
    "                targ_q = quantile_tar_slider.value / 100\n",
    "                targ_q_t = sum_without_checked_targets.iloc[treshholded_idx].quantile(targ_q)\n",
    "                tempIndex = np.where(sum_without_checked_targets.iloc[treshholded_idx] >= targ_q_t)\n",
    "                tempIndex = tempIndex[0]\n",
    "                Index_c = sum_without_checked_targets.iloc[treshholded_idx].iloc[tempIndex].index\n",
    "                Index_samp = np.delete(sum_.index, Index_c)\n",
    "            else:\n",
    "                Index_c = treshholded_idx\n",
    "                Index_samp = np.delete(sum_.index, treshholded_idx)\n",
    "\n",
    "        else:\n",
    "            targ_q = quantile_tar_slider.value / 100\n",
    "            targ_q_t = sum_.quantile(targ_q)\n",
    "            Index_samp = np.where(sum_ < targ_q_t)\n",
    "            Index_samp = Index_samp[0]\n",
    "            Index_c = np.where(sum_ >= targ_q_t)\n",
    "            Index_c = Index_samp[0]\n",
    "\n",
    "        init_sample_set = np.ones((0, self.init_sample_size))\n",
    "        for i in range(self.number_of_executions):\n",
    "            init_sample_set = np.vstack([init_sample_set, random.choice(Index_samp, self.init_sample_size)])\n",
    "\n",
    "        return init_sample_set\n",
    "\n",
    "    def start_sequential_learning(self):\n",
    "\n",
    "        self.tries_list = np.empty(self.number_of_executions)\n",
    "        self.tries_list.fill(np.nan)\n",
    "        self.tries_list_rand_pick = np.empty(self.number_of_executions)\n",
    "        self.tries_list_rand_pick.fill(np.nan)\n",
    "\n",
    "        distances = []\n",
    "        targt_perfs = []\n",
    "        MAE = []\n",
    "        MSE = []\n",
    "        Rsqu = []\n",
    "        fixed_targets = []\n",
    "        targets = []\n",
    "\n",
    "        current_distances_list = []\n",
    "        current_targt_perf_list = []\n",
    "\n",
    "        with out_perform_experiment:\n",
    "            display(Markdown('Sequential Learning is running...'))\n",
    "\n",
    "        global result_df\n",
    "\n",
    "        self.dataframe = decide_max_or_min(box_targets, confirm_target(target_selection), self.dataframe)\n",
    "        self.dataframe = decide_max_or_min(box_fixed_targets, confirm_fixed_target(fixed_target_selection),\n",
    "                                           self.dataframe)\n",
    "\n",
    "        init_sample_set = self.init_sampling()\n",
    "        fixed_targets_index = confirm_fixed_target(fixed_target_selection)\n",
    "\n",
    "        sum_ = self.dataframe[confirm_target(target_selection)].sum(axis=1).to_frame() + self.dataframe[\n",
    "            fixed_targets_index].sum(axis=1).to_frame()\n",
    "\n",
    "        targ_q_t = sum_.quantile(self.target_treshhold)\n",
    "        schwellwert = sum_.quantile(self.target_treshhold)\n",
    "        Index_c = np.where(sum_ >= schwellwert)\n",
    "        Index_c = Index_c[0]\n",
    "\n",
    "        for i in range(self.number_of_executions):\n",
    "\n",
    "            self.perform_random_pick(i)\n",
    "            self.SampIdx = init_sample_set[i].astype(int)\n",
    "            self.PredIdx = self.dataframe\n",
    "            self.PredIdx = self.PredIdx.drop(self.PredIdx.index[self.SampIdx]).index\n",
    "            self.decide_model(self.model)\n",
    "            self.tries_list[i] = 0\n",
    "            #self.init_sample_size\n",
    "\n",
    "            distance = distance_matrix(self.dataframe.iloc[self.SampIdx], self.dataframe.iloc[self.treshIdx])\n",
    "            distance = distance.min()\n",
    "            current_distances_list = [distance]\n",
    "\n",
    "            #max value summe\n",
    "            targt_perf = sum_.loc[self.SampIdx].max().item()\n",
    "            current_targt_perf_list = [targt_perf]\n",
    "            max_targt_perf_index = np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "            Idx_of_best_value = self.SampIdx[max_targt_perf_index]\n",
    "            best_value = df_converter().iloc[Idx_of_best_value]\n",
    "            current_fixed_target_list = np.array(best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()[0])\n",
    "            current_prediction_target = np.array(best_value[confirm_target(target_selection)].to_numpy()[0])\n",
    "\n",
    "            while np.any(np.in1d(self.SampIdx, self.treshIdx)) == False:\n",
    "                batch_size = self.batch_size\n",
    "\n",
    "                for batch in range(batch_size):\n",
    "                    if (self.SampIdx.size < batch_size):\n",
    "                        batch_size = self.SampIdx.size\n",
    "                        self.update_strategy(self.strategy)\n",
    "                    else:\n",
    "                        self.update_strategy(self.strategy)\n",
    "\n",
    "                #Train Model\n",
    "                self.decide_model(self.model)\n",
    "                distance = distance_matrix(self.dataframe.iloc[self.SampIdx], self.dataframe.iloc[self.treshIdx])\n",
    "                distance = distance.min()\n",
    "                current_distances_list.append(distance)\n",
    "                targt_perf = sum_.loc[self.SampIdx].max().values.tolist()\n",
    "                targt_perf = max(targt_perf)\n",
    "                current_targt_perf_list.append(targt_perf)\n",
    "                max_targt_perf_index = np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                Idx_of_best_value = self.SampIdx[max_targt_perf_index]\n",
    "                best_value = df_converter().iloc[Idx_of_best_value]\n",
    "\n",
    "                current_prediction_target = np.vstack(\n",
    "                    [current_prediction_target, best_value[confirm_target(target_selection)].to_numpy()[0]])\n",
    "                current_fixed_target_list = np.vstack(\n",
    "                    [current_fixed_target_list, best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()[0]])\n",
    "                self.tries_list[i] = self.tries_list[i] + 1\n",
    "\n",
    "            self.Label = self.dataframe[confirm_target(target_selection)].iloc[self.PredIdx].sum(\n",
    "                axis=1).to_frame().to_numpy()\n",
    "\n",
    "            #print('pred',self.Label-self.Expected_Pred.squeeze())\n",
    "\n",
    "            MAE.append(mean_absolute_error(self.Label, self.Expected_Pred.squeeze()))\n",
    "            MSE.append(mean_squared_error(self.Label, self.Expected_Pred.squeeze()))\n",
    "            Rsqu.append(r2_score(self.Label, self.Expected_Pred.squeeze()))\n",
    "            distances.append(current_distances_list)\n",
    "            targt_perfs.append(current_targt_perf_list)\n",
    "            best_value = df_converter().iloc[self.treshIdx]\n",
    "\n",
    "            current_prediction_target = np.vstack(\n",
    "                [current_prediction_target, best_value[confirm_target(target_selection)].to_numpy()[0]])\n",
    "            current_fixed_target_list = np.vstack(\n",
    "                [current_fixed_target_list, best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()[0]])\n",
    "\n",
    "            targets.append(current_prediction_target)\n",
    "            fixed_targets.append(current_fixed_target_list)\n",
    "\n",
    "            ## Live Plots\n",
    "\n",
    "            with out_perform_experiment:\n",
    "                fig1, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "                axs[0].set_title('Optimization progress in input space')\n",
    "                axs[0].set_xlabel('development cycles')\n",
    "                axs[0].set_ylabel(\"Minimum distance from sampled data to target\")\n",
    "                axs[0].axhline(y=0, color='k', linestyle=':', label='Target')\n",
    "                axs[0].legend()\n",
    "\n",
    "                axs[1].set_title('Optimization progress in output space')\n",
    "                axs[1].set_xlabel('development cycles')\n",
    "                axs[1].set_ylabel(\"Maximum sampled property\")\n",
    "                axs[1].axhline(y=targ_q_t.values, color='k', linestyle=':', label='Target (normalized)')\n",
    "                axs[1].legend()\n",
    "\n",
    "                #Plotting\n",
    "                for runs in range(len(distances)):\n",
    "                    axs[0].plot(distances[runs], linewidth=8, alpha=0.4)\n",
    "\n",
    "            for runs in range(len(targt_perfs)):\n",
    "                axs[1].plot(targt_perfs[runs], linewidth=8, alpha=0.4)\n",
    "\n",
    "            with out_perform_experiment:\n",
    "                out_perform_experiment.clear_output(wait=True)\n",
    "                time.sleep(1.0)\n",
    "                fig2 = plt.figure(figsize=(15, 5))\n",
    "                plt.xlabel('Number of required Experiments')\n",
    "                plt.ylabel(\"Frequency\")\n",
    "                plt.title(\"Performance histogram for %s with strategy %s \" % (self.model, self.strategy))\n",
    "                #plt.hist([self.tries_list,self.tries_list_rand_pick],bins=len(self.tries_list),label=['SL Tries', 'Random Pick Tries'])\n",
    "                plt.hist([self.tries_list_rand_pick], range=(1, len(self.features_df)), label=['Random Process'],\n",
    "                         alpha=0.4)\n",
    "                plt.hist([self.tries_list], label=['SL'], range=(1, len(self.features_df)), alpha=0.4)\n",
    "                plt.legend()\n",
    "\n",
    "                plt.show()\n",
    "                #plt.close(fig2)\n",
    "\n",
    "            with out_perform_experiment:\n",
    "                display(Markdown('current iteration {}'.format(i + 1)))\n",
    "                display(Markdown(\" \"))\n",
    "\n",
    "                #self.number_of_executions\n",
    "        #Extend values of perfs\n",
    "        lengths_of_perfs = []\n",
    "        for runs in range(len(targt_perfs)):\n",
    "            current_len_of_perf = len(targt_perfs[runs])\n",
    "            lengths_of_perfs.append(current_len_of_perf)\n",
    "\n",
    "        for runs in range(len(targt_perfs)):\n",
    "            if (len(targt_perfs[runs]) != max(lengths_of_perfs)):\n",
    "                size_of_values_to_add = max(lengths_of_perfs) - len(targt_perfs[runs])\n",
    "                targt_perfs[runs].extend(np.full(size_of_values_to_add, max(targt_perfs[runs])))\n",
    "\n",
    "        targt_perfs_as_array = np.array(targt_perfs)\n",
    "        mean_performances = np.mean(targt_perfs_as_array, axis=0)\n",
    "\n",
    "        rel_perform_after_5 = 1.0\n",
    "        rel_perform_after_10 = 1.0\n",
    "\n",
    "        max_performance = np.max(sum_)\n",
    "        min_performance = np.min(sum_)\n",
    "\n",
    "        if (len(mean_performances) > 5 and len(mean_performances) < 10):\n",
    "            perform_after_5 = mean_performances[4]\n",
    "            rel_perform_after_5 = (perform_after_5 - min_performance) / (max_performance - min_performance)\n",
    "\n",
    "        if (len(mean_performances) == 5):\n",
    "            perform_after_5 = mean_performances[4]\n",
    "            rel_perform_after_5 = (perform_after_5 - min_performance) / (max_performance - min_performance)\n",
    "\n",
    "        if (len(mean_performances) >= 10):\n",
    "            perform_after_5 = mean_performances[4]\n",
    "            perform_after_10 = mean_performances[9]\n",
    "            print(perform_after_10 / max_performance)\n",
    "            rel_perform_after_5 = (perform_after_5 - min_performance) / (max_performance - min_performance)\n",
    "            rel_perform_after_10 = (perform_after_10 - min_performance) / (max_performance - min_performance)\n",
    "\n",
    "        if self.strategy == 'MEI (exploit)':\n",
    "            self.sigma = 0\n",
    "            self.distance = 0\n",
    "        elif self.strategy == 'MU (explore)':\n",
    "            self.sigma = 1\n",
    "            self.distance = 0\n",
    "        elif self.strategy == 'MLI (explore & exploit)':\n",
    "            self.distance = 0\n",
    "        elif self.strategy == 'MEID (exploit)':\n",
    "            self.sigma = 0\n",
    "\n",
    "        ##Appending Performance intensiv --> List comprehension\n",
    "        to_append = ([np.mean(self.tries_list), np.std(self.tries_list), np.quantile(self.tries_list, 0.90),\n",
    "                      np.quantile(self.tries_list, 1), rel_perform_after_5, rel_perform_after_10, np.mean(MAE),\n",
    "                      np.mean(MSE), np.mean(Rsqu), self.batch_size, self.model, self.strategy, self.sigma,\n",
    "                      self.distance,\n",
    "                      self.number_of_executions, self.init_sample_size, len(self.dataframe.index),\n",
    "                      len(confirm_features(feature_selector)),\n",
    "                      len(confirm_target(target_selection)), self.target_treshhold,\n",
    "                      confirm_features(feature_selector).tolist(), confirm_target(target_selection).tolist(),\n",
    "                      confirm_fixed_target(fixed_target_selection).tolist(), self.tries_list])\n",
    "\n",
    "        ####SL-Results\n",
    "        with out_results_SL:\n",
    "            out_results_SL.clear_output(wait=True)\n",
    "            display(Markdown('#### Performance summary:'))\n",
    "            display(Markdown('req. development cycles with optimzation (mean):  {} '.format(\n",
    "                np.mean(self.tries_list))))\n",
    "            display(Markdown(\n",
    "                \"req. development cycles  without optimzation (mean): {}\".format(np.mean(self.tries_list_rand_pick))))\n",
    "\n",
    "        with out_results_SL:\n",
    "\n",
    "            display(Markdown(\" \"))\n",
    "            display(Markdown('#### Log:'))\n",
    "            display(Markdown(\" \"))\n",
    "            a_series = pd.Series(to_append, index=result_df.columns)\n",
    "            result_df = result_df.append(a_series, ignore_index=True)\n",
    "            display(Markdown(result_df.to_markdown()))\n",
    "            display((create_download_link(result_df, 'Download Log-File', 'results_sl')))\n",
    "\n",
    "        #Plot targets\n",
    "        ### Fixed Targets\n",
    "        if (len(confirm_fixed_target(fixed_target_selection).values.tolist()) > 0):\n",
    "            anzahl_plots = len(fixed_target_selection.value)\n",
    "            fig3, axs_fixed = plt.subplots(anzahl_plots, figsize=(8, 5 * anzahl_plots), squeeze=False)\n",
    "            axs_fixed = axs_fixed.flatten()\n",
    "            fixed_targets_extended = extend(fixed_targets)\n",
    "            mean_fixed_targets_extended = np.mean(fixed_targets_extended, axis=0)\n",
    "            fixed_rand_extended = extend(self.rand_fixed_tars)\n",
    "            mean_fixed_rand_extended = np.mean(fixed_rand_extended, axis=0)\n",
    "\n",
    "            #Plot fixed targets\n",
    "\n",
    "            for fixed_target in range(anzahl_plots):\n",
    "                axs_fixed[fixed_target].set_title(\n",
    "                    'Optimization progress for %s' % (confirm_fixed_target(fixed_target_selection)[fixed_target]))\n",
    "                axs_fixed[fixed_target].set_xlabel('development cycles')\n",
    "                axs_fixed[fixed_target].set_ylabel(\"Best sampled property\")\n",
    "\n",
    "                axs_fixed[fixed_target].set_xlim([0, len(mean_fixed_targets_extended[:, 0]) - 1])\n",
    "\n",
    "            for one_tar in range(anzahl_plots):\n",
    "                axs_fixed[one_tar].plot(mean_fixed_targets_extended[:, one_tar], linewidth=8, alpha=0.9, color='k',\n",
    "                                        label='With optimization')\n",
    "                axs_fixed[one_tar].plot(mean_fixed_rand_extended[:, one_tar], linewidth=8, alpha=0.9, color='g',\n",
    "                                        label='Without optimization')\n",
    "                axs_fixed[one_tar].axvline(x=round(np.mean(self.tries_list) - self.init_sample_size), color='k',\n",
    "                                           linestyle=':', label='Average dev. cycles to success')\n",
    "                axs_fixed[one_tar].legend()\n",
    "\n",
    "            for sl_run in range(len(fixed_targets)):\n",
    "                for one_tar in range(anzahl_plots):\n",
    "                    axs_fixed[one_tar].plot(fixed_targets[sl_run][:, one_tar], linewidth=2, alpha=0.1, color='k')\n",
    "\n",
    "        with out_results_SL:\n",
    "\n",
    "            display(Markdown(\" \"))\n",
    "            display(Markdown('#### Result plots:'))\n",
    "\n",
    "            anzahl_plots = len(target_selection.value)\n",
    "            targets_extended = extend(targets)\n",
    "            mean_targets_extended = np.mean(targets_extended, axis=0)\n",
    "            fig4, axs_pred = plt.subplots(anzahl_plots, figsize=(8, 5 * anzahl_plots), squeeze=False)\n",
    "\n",
    "            plt.setp(axs_pred, xlim=[0, len(mean_targets_extended[:, 0]) - 1])\n",
    "\n",
    "            axs_pred = axs_pred.flatten()\n",
    "            rand_extended = extend(self.rand_tars)\n",
    "            mean_rand_extended = np.mean(rand_extended, axis=0)\n",
    "\n",
    "            for pred_target in range(anzahl_plots):\n",
    "                axs_pred[pred_target].set_title(\n",
    "                    'Optimization progress for %s' % (confirm_target(target_selection)[pred_target]))\n",
    "                axs_pred[pred_target].set_xlabel('development cycles')\n",
    "                axs_pred[pred_target].set_ylabel(\"Best sampled property\")\n",
    "\n",
    "            for pred_target in range(anzahl_plots):\n",
    "                axs_pred[pred_target].plot(mean_targets_extended[:, pred_target], linewidth=8, alpha=0.9, color='k',\n",
    "                                           label='With optimization')\n",
    "                axs_pred[pred_target].plot(mean_rand_extended[:, pred_target], linewidth=8, alpha=0.9, color='g',\n",
    "                                           label='Without optimization')\n",
    "                axs_pred[pred_target].axvline(x=round(np.mean(self.tries_list) - self.init_sample_size), color='k',\n",
    "                                              linestyle=':', label='Average dev. cycles to success')\n",
    "                axs_pred[pred_target].legend()\n",
    "\n",
    "            for sl_run in range(len(targets)):\n",
    "                for one_tar in range(anzahl_plots):\n",
    "                    axs_pred[one_tar].plot(targets[sl_run][:, one_tar], linewidth=2, alpha=0.1, color='k')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    def perform_random_pick(self, acutal_iter):\n",
    "\n",
    "        sum_ = self.dataframe[confirm_target(target_selection)].sum(axis=1).to_frame() + self.dataframe[\n",
    "            confirm_fixed_target(fixed_target_selection)].sum(axis=1).to_frame()\n",
    "        index_sum = sum_.index.to_numpy()\n",
    "        index_sum_randomized = np.random.choice(index_sum, len(index_sum), False)\n",
    "        targ_q_t = sum_.quantile(self.target_treshhold)\n",
    "        self.tries_list_rand_pick[acutal_iter] = 1\n",
    "        run = 0\n",
    "        best_value = df_converter().iloc[index_sum_randomized[run]]\n",
    "        current_fixed_rand_tars = np.array(best_value[confirm_fixed_target(fixed_target_selection)].to_numpy())\n",
    "        current_pred_rand_tars = np.array(best_value[confirm_target(target_selection)].to_numpy())\n",
    "\n",
    "        while np.any(np.in1d(index_sum_randomized[run], self.treshIdx)) == False:\n",
    "            self.tries_list_rand_pick[acutal_iter] = self.tries_list_rand_pick[acutal_iter] + 1\n",
    "            temp_index = np.argmax(sum_.iloc[index_sum_randomized[0:run + 1]])\n",
    "            max_index = index_sum_randomized[temp_index]\n",
    "            best_value = df_converter().iloc[max_index]\n",
    "            current_pred_rand_tars = np.vstack(\n",
    "                [current_pred_rand_tars, best_value[confirm_target(target_selection)].to_numpy()])\n",
    "            current_fixed_rand_tars = np.vstack(\n",
    "                [current_fixed_rand_tars, best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()])\n",
    "            run = run + 1\n",
    "\n",
    "        temp_index = np.argmax(sum_.iloc[index_sum_randomized[0:run + 1]])\n",
    "        max_index = index_sum_randomized[temp_index]\n",
    "        best_value = df_converter().iloc[max_index]\n",
    "        current_pred_rand_tars = np.vstack(\n",
    "            [current_pred_rand_tars, best_value[confirm_target(target_selection)].to_numpy()])\n",
    "        current_fixed_rand_tars = np.vstack(\n",
    "            [current_fixed_rand_tars, best_value[confirm_fixed_target(fixed_target_selection)].to_numpy()])\n",
    "\n",
    "        self.rand_fixed_tars.append(current_fixed_rand_tars)\n",
    "        self.rand_tars.append(current_pred_rand_tars)\n",
    "\n",
    "    def decide_model(self, model):\n",
    "        if model == 'Lolo Random Forrest':\n",
    "            self.fit_RF_wJK()\n",
    "        elif model == 'Decision Trees (DT)':\n",
    "            self.fit_DT_wJK()\n",
    "        elif model == 'Random Forrest (RFscikit)':\n",
    "            self.fit_TE_wJK()\n",
    "        elif model == 'Gaussian Process Regression':\n",
    "            self.fit_GP()\n",
    "        elif model == 'Tuned Gauss':\n",
    "            self.fit_tuned_gauss()\n",
    "        elif model == 'Tuned RF':\n",
    "            self.fit_tuned_rf()\n",
    "        elif model == 'Gauss with PCA':\n",
    "            self.fit_gauss_with_pca()\n",
    "        elif model == 'RF with PCA':\n",
    "            self.fit_rf_with_pca()\n",
    "\n",
    "    def update_strategy(self, strategy):\n",
    "        if strategy == 'MEI (exploit)':\n",
    "            self.updateIndexMEI()\n",
    "        elif strategy == 'MLI (explore & exploit)':\n",
    "            self.updateIndexMLI()\n",
    "\n",
    "    def updateIndexMEI(self):\n",
    "        fixed_targets_in_prediction = self.dataframe[confirm_fixed_target(fixed_target_selection)].iloc[\n",
    "            self.PredIdx].to_numpy()\n",
    "        if (len(confirm_fixed_target(fixed_target_selection)) > 0):\n",
    "            for weights in range(len(ft.weights)):\n",
    "                fixed_targets_in_prediction[weights] = fixed_targets_in_prediction[weights] * ft.weights[weights].value\n",
    "\n",
    "        fixed_targets_in_prediction = fixed_targets_in_prediction.sum(axis=1)\n",
    "\n",
    "        if (self.Expected_Pred.ndim > 1):\n",
    "            index_max = np.argmax(fixed_targets_in_prediction.squeeze() + self.Expected_Pred.sum(axis=1).squeeze())\n",
    "        else:\n",
    "            index_max = np.argmax(fixed_targets_in_prediction.squeeze() + self.Expected_Pred.squeeze())\n",
    "\n",
    "        new_SampIdx = np.append(self.SampIdx, self.PredIdx[index_max])\n",
    "        self.SampIdx = new_SampIdx\n",
    "        new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "        self.Expected_Pred = np.delete(self.Expected_Pred.squeeze(), index_max)\n",
    "        self.PredIdx = new_PredIdx\n",
    "\n",
    "    def updateIndexMLI(self):\n",
    "        fixed_targets_in_prediction = self.dataframe[confirm_fixed_target(fixed_target_selection)].iloc[\n",
    "            self.PredIdx].to_numpy()\n",
    "        if (len(confirm_fixed_target(fixed_target_selection)) > 0):\n",
    "            for weights in range(len(ft.weights)):\n",
    "                fixed_targets_in_prediction[weights] = fixed_targets_in_prediction[weights] * ft.weights[weights].value\n",
    "        fixed_targets_in_prediction = fixed_targets_in_prediction.sum(axis=1)\n",
    "\n",
    "        index_max = np.argmax(\n",
    "            fixed_targets_in_prediction.squeeze() + self.Expected_Pred.squeeze() + self.sigma * self.Uncertainty.squeeze())\n",
    "        new_SampIdx = np.append(self.SampIdx, self.PredIdx[index_max])\n",
    "        self.SampIdx = new_SampIdx\n",
    "        new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "        self.Expected_Pred = np.delete(self.Expected_Pred.squeeze(), index_max)\n",
    "        self.Uncertainty = np.delete(self.Uncertainty.squeeze(), index_max)\n",
    "        self.PredIdx = new_PredIdx\n",
    "\n",
    "    def fit_DT_wJK(self):\n",
    "\n",
    "        td, tl = self.jk_resampling()\n",
    "        self.y_pred_dtr = []\n",
    "        for i in range(len(td)):\n",
    "            dtr = DecisionTreeRegressor()\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "\n",
    "        self.y_pred_dtr = np.array(self.y_pred_dtr)\n",
    "        self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "        self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        #multiply Prediction with factor\n",
    "        self.weight_Pred()\n",
    "\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "\n",
    "    def fit_TE_wJK(self):\n",
    "        td, tl = self.jk_resampling()\n",
    "        self.y_pred_dtr = []\n",
    "\n",
    "        for i in range(len(td)):\n",
    "            ## alternative Ensamble Learners below:\n",
    "            dtr = SKRFR(n_estimators=10)\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "\n",
    "        self.y_pred_dtr = np.array(self.y_pred_dtr)\n",
    "        self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "        self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        self.weight_Pred()\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "\n",
    "    def jk_resampling(self):\n",
    "        from resample.jackknife import resample as b_resample\n",
    "        td = [x for x in b_resample(self.features_df.iloc[self.SampIdx])]\n",
    "        tl = [x for x in b_resample(self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx])]\n",
    "        tl = np.array(tl)\n",
    "        td = np.array(td)\n",
    "\n",
    "        return td, tl\n",
    "\n",
    "    def fit_RF_wJK(self):\n",
    "        self.x=self.features_df.iloc[self.SampIdx].to_numpy()\n",
    "        self.y=self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy()\n",
    "        dtr = SlamdLoloRF()\n",
    "        dtr.fit(self.x,self.y)\n",
    "        self.Expected_Pred, self.Uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx].to_numpy(), return_std=True)\n",
    "        self.weight_Pred()\n",
    "\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "\n",
    "    def fit_GP(self):\n",
    "        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "        dtr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=3)\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(),\n",
    "                self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx], return_std=True)\n",
    "        self.weight_Pred()\n",
    "\n",
    "    def _create_aniso_kernel(self, n_dims):\n",
    "        return ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(length_scale=[1] * n_dims)\n",
    "\n",
    "    def fit_tuned_gauss(self):\n",
    "        default_kernel = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n",
    "        # 5 and 10 for aniso\n",
    "        param_grid = [\n",
    "            {\n",
    "                'sfs__k_features': [8],\n",
    "                'sfs__estimator__kernel': [default_kernel],\n",
    "                'gp2__kernel': [default_kernel, self._create_aniso_kernel(5)]  # -> use iso and aniso\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        gauss1 = GaussianProcessRegressor(normalize_y=True, n_restarts_optimizer=3)\n",
    "        gauss2 = GaussianProcessRegressor(normalize_y=True, n_restarts_optimizer=3)\n",
    "\n",
    "        sfs_gr_testing = SFS(estimator=gauss1,\n",
    "                             forward=True,\n",
    "                             floating=False,\n",
    "                             scoring='r2',\n",
    "                             cv=None)\n",
    "\n",
    "        pipe = Pipeline([('sfs', sfs_gr_testing),\n",
    "                         ('gp2', gauss2)])\n",
    "\n",
    "        cv = KFold(n_splits=4, shuffle=True)\n",
    "        grid_search_cv = GridSearchCV(estimator=pipe,\n",
    "                                      param_grid=param_grid,\n",
    "                                      scoring='r2',\n",
    "                                      n_jobs=1,\n",
    "                                      cv=cv,\n",
    "                                      refit=False)\n",
    "        # run gridsearch\n",
    "        grid_search_cv = grid_search_cv.fit(self.features_df.iloc[self.SampIdx].to_numpy(),\n",
    "                                            self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(\n",
    "                                                axis=1).to_frame().to_numpy())\n",
    "\n",
    "        best_model = pipe.set_params(**grid_search_cv.best_params_)\n",
    "        best_model.fit(self.features_df.iloc[self.SampIdx].to_numpy(),\n",
    "                       self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(\n",
    "                           axis=1).to_frame().to_numpy())\n",
    "\n",
    "        self.Expected_Pred, self.Uncertainty = best_model.predict(self.features_df.iloc[self.PredIdx], return_std=True)\n",
    "        self.weight_Pred()\n",
    "        return self.Expected_Pred.squeeze(), self.Uncertainty.squeeze()\n",
    "\n",
    "    def fit_tuned_rf(self):\n",
    "        param_grid = {\n",
    "            'sfs__k_features': [8],\n",
    "            'rf2__max_depth': [1, 5],\n",
    "        }\n",
    "\n",
    "        rf1 = SlamdLoloRF()\n",
    "        rf2 = SlamdLoloRF()\n",
    "\n",
    "        sfs_rf_testing = SFS(estimator=rf1,\n",
    "                             forward=True,\n",
    "                             floating=False,\n",
    "                             scoring='r2',\n",
    "                             cv=None)\n",
    "\n",
    "        pipe = Pipeline([('sfs', sfs_rf_testing),\n",
    "                         ('rf2', rf2)])\n",
    "\n",
    "        cv = KFold(n_splits=4, shuffle=True)\n",
    "        grid_search_cv = GridSearchCV(estimator=pipe,\n",
    "                                      param_grid=param_grid,\n",
    "                                      scoring='r2',\n",
    "                                      n_jobs=1,\n",
    "                                      cv=cv,\n",
    "                                      refit=False)\n",
    "\n",
    "        self.x=self.features_df.iloc[self.SampIdx].to_numpy()\n",
    "        self.y=self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy()\n",
    "        # if self.y.shape[0]<8:\n",
    "        #     self.x=np.tile(self.x,(4,1))\n",
    "        #     self.y=np.tile(self.y,(4,1))\n",
    "        grid_search_cv = grid_search_cv.fit(self.features_df.iloc[self.SampIdx].to_numpy(),\n",
    "                                            self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(\n",
    "                                                axis=1).to_frame().to_numpy())\n",
    "\n",
    "        best_model = pipe.set_params(**grid_search_cv.best_params_)\n",
    "        best_model.fit(self.x, self.y)\n",
    "\n",
    "        self.Expected_Pred, self.Uncertainty = best_model.predict(self.features_df.iloc[self.PredIdx].to_numpy(), return_std=True)\n",
    "        self.weight_Pred()\n",
    "\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "\n",
    "    def fit_gauss_with_pca(self):\n",
    "        pipe = Pipeline([('pca',PCA(n_components=0.99)),('pred', GaussianProcessRegressor(n_restarts_optimizer=3))])\n",
    "        pipe.fit(self.features_df.iloc[self.SampIdx].to_numpy(),\n",
    "                 self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(\n",
    "                     axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty = pipe.predict(self.features_df.iloc[self.PredIdx], return_std=True)\n",
    "        self.weight_Pred()\n",
    "        return self.Expected_Pred.squeeze(), self.Uncertainty.squeeze()\n",
    "\n",
    "    def fit_rf_with_pca(self):\n",
    "        dtr = Pipeline([('pca',PCA(n_components=0.99)),('pred', SlamdLoloRF())])\n",
    "        self.x=self.features_df.iloc[self.SampIdx].to_numpy()\n",
    "        self.y=self.dataframe[confirm_target(target_selection)].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy()\n",
    "        print('X',self.x.shape[0])\n",
    "        print('Y',self.y.shape[0])\n",
    "        dtr.fit(self.x,self.y)\n",
    "        self.Expected_Pred, self.Uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx].to_numpy(), return_std=True)\n",
    "        self.weight_Pred()\n",
    "\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "\n",
    "    def weight_Pred(self):\n",
    "        if (self.Expected_Pred.ndim > 2):\n",
    "            for weights in range(len(tA.weights)):\n",
    "                self.Expected_Pred[:, weights] = self.Expected_Pred[:, weights] * t.weights[weights].value\n",
    "        else:\n",
    "            self.Expected_Pred = self.Expected_Pred * t.weights[0].value\n",
    "            self.Uncertainty = self.Uncertainty * t.weights[0].value\n",
    "\n",
    "    def create_target_idx_after_logic_criteria(self, treshholded_idx, df, sum_):\n",
    "        checked_targets = []\n",
    "\n",
    "        if (treshholded_idx):\n",
    "            if (t.checkboxes is not None):\n",
    "                for row in range(len(t.checkboxes)):\n",
    "                    if (t.checkboxes[row].value == True):\n",
    "                        checked_targets.append(t.radiobuttons[row].description)\n",
    "            if (ft.checkboxes is not None):\n",
    "                for row in range(len(ft.checkboxes)):\n",
    "                    if (ft.checkboxes[row].value == True):\n",
    "                        checked_targets.append(ft.radiobuttons[row].description)\n",
    "            if (len(checked_targets) != len(t.checkboxes) + len(ft.checkboxes)):\n",
    "                #frage\n",
    "                targets = confirm_target(target_selection)\n",
    "                fixed_targets = confirm_fixed_target(fixed_target_selection)\n",
    "                df = df[targets.tolist() + fixed_targets.tolist()]\n",
    "                sum_without_checked_targets = df.sum(axis=1)\n",
    "                targ_q = quantile_tar_slider.value / 100\n",
    "                targ_q_t = sum_without_checked_targets.iloc[treshholded_idx].quantile(targ_q)\n",
    "                tempIndex = np.where(sum_without_checked_targets.iloc[treshholded_idx] >= targ_q_t)\n",
    "                tempIndex = tempIndex[0]\n",
    "                Index_c = sum_without_checked_targets.iloc[treshholded_idx].iloc[tempIndex].index\n",
    "                #Sample IDX\n",
    "                Index_samp = np.delete(sum_.index, Index_c)\n",
    "\n",
    "            else:\n",
    "                Index_c = treshholded_idx\n",
    "                Index_samp = np.delete(sum_.index, treshholded_idx)\n",
    "\n",
    "        elif (not treshholded_idx):\n",
    "            #print(\"kein tresh aber minimiert\")\n",
    "            targ_q = quantile_tar_slider.value / 100\n",
    "            targ_q_t = sum_.quantile(targ_q)\n",
    "            Index_samp = np.where(sum_ < targ_q_t)\n",
    "            Index_samp = Index_samp[0]\n",
    "            Index_c = np.where(sum_ >= targ_q_t)\n",
    "            Index_c = Index_c[0]\n",
    "\n",
    "        return Index_samp, Index_c\n",
    "\n",
    "    def check_input_variables(self):\n",
    "\n",
    "        from collections import Counter\n",
    "        united_idxs = t.idxs\n",
    "        if (united_idxs is not None):\n",
    "            idxs_without_feature_desc = [tuple_of_feature_and_idxs[1] for tuple_of_feature_and_idxs in united_idxs]\n",
    "            flat_list = [item for sublist in idxs_without_feature_desc for item in sublist]\n",
    "            counts = Counter(flat_list)\n",
    "            compatible_idxs = [id for id in flat_list if counts[id] >= (len(idxs_without_feature_desc))]\n",
    "            treshholded_idx = set(compatible_idxs)\n",
    "            treshholded_idx_as_list = list(treshholded_idx)\n",
    "            return treshholded_idx_as_list\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def load_data(self):\n",
    "        features_df = (df_converter()[confirm_features(feature_selector)] - df_converter()[\n",
    "            confirm_features(feature_selector)].mean()) / df_converter()[confirm_features(feature_selector)].std()\n",
    "        target_df = (df_converter()[confirm_target(target_selection)] - df_converter()[\n",
    "            confirm_target(target_selection)].mean()) / df_converter()[confirm_target(target_selection)].std()\n",
    "        fixed_target_df = (df_converter()[confirm_fixed_target(fixed_target_selection)] - df_converter()[\n",
    "            confirm_fixed_target(fixed_target_selection)].mean()) / df_converter()[\n",
    "                              confirm_fixed_target(fixed_target_selection)].std()\n",
    "        df_unnorm = df_converter()\n",
    "        df = (df_unnorm - df_unnorm.mean()) / (df_unnorm.std())\n",
    "\n",
    "        return features_df, target_df, fixed_target_df, df_unnorm, df\n",
    "\n",
    "    def show_input_data(self):\n",
    "        treshholded_idx = self.check_input_variables()\n",
    "        features_df, target_df, fixed_target_df, df_unnorm, df = self.load_data()\n",
    "\n",
    "        with out_input_space:\n",
    "            display(Markdown('Target data'))\n",
    "            if df is not None:\n",
    "                targ_q = quantile_tar_slider.value / 100\n",
    "                target_df = decide_max_or_min(box_targets, confirm_target(target_selection), target_df)\n",
    "                fixed_target_df = decide_max_or_min(box_fixed_targets, confirm_fixed_target(fixed_target_selection),\n",
    "                                                    fixed_target_df)\n",
    "                df = decide_max_or_min(box_targets, confirm_target(target_selection), df)\n",
    "                df = decide_max_or_min(box_fixed_targets, confirm_fixed_target(fixed_target_selection), df)\n",
    "                sum_ = target_df.sum(axis=1).to_frame() + fixed_target_df.sum(axis=1).to_frame()\n",
    "                Index_samp, Index_c = self.create_target_idx_after_logic_criteria(treshholded_idx, df, sum_)\n",
    "                display(Markdown(df_unnorm.iloc[Index_c].to_markdown()))\n",
    "            else:\n",
    "                display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "    def main(self):\n",
    "\n",
    "        self.apply_feature_selection_to_df(self.dataframe)\n",
    "        self.apply_target_selection_to_df(self.dataframe)\n",
    "        if (len(confirm_fixed_target(fixed_target_selection).values.tolist()) > 0):\n",
    "            self.target_df = self.target_df.join(self.dataframe[confirm_fixed_target(fixed_target_selection)])\n",
    "        self.standardize_data()\n",
    "        init_sample_set = self.init_sampling()\n",
    "        targ_q = quantile_tar_slider.value / 100\n",
    "        treshholded_idx = self.check_input_variables()\n",
    "        features_df, target_df, fixed_target_df, df_unnorm, df = self.load_data()\n",
    "\n",
    "        target_df = decide_max_or_min(box_targets, confirm_target(target_selection), target_df)\n",
    "        fixed_target_df = decide_max_or_min(box_fixed_targets, confirm_fixed_target(fixed_target_selection),\n",
    "                                            fixed_target_df)\n",
    "\n",
    "        sum_ = target_df.sum(axis=1).to_frame() + fixed_target_df.sum(axis=1).to_frame()\n",
    "        treshholded_idx = self.check_input_variables()\n",
    "        Index_samp, Index_c = self.create_target_idx_after_logic_criteria(treshholded_idx, df, sum_)\n",
    "        self.treshIdx = Index_c\n",
    "        self.start_sequential_learning()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s = sequential_learning(df_converter(),\n",
    "                        initial_sample_size_text.value,\n",
    "                        batch_size_text.value,  #drin fÃ¼r d utilitys\n",
    "                        quantile_tar_slider.value,\n",
    "                        iterations.value,\n",
    "                        slider_of_for_std.value,  #drin\n",
    "                        slider_of_for_dist.value,  #driun\n",
    "                        select_model.value,\n",
    "                        confirm_strategy(),\n",
    "                        t.idxs,\n",
    "                        ft.idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def perform_experiment_clicked(b):\n",
    "    start_and_stop_sl_container.children = [button_perform_experiment]\n",
    "    s = sequential_learning(df_converter(),\n",
    "                            initial_sample_size_text.value,\n",
    "                            batch_size_text.value,\n",
    "                            quantile_tar_slider.value,\n",
    "                            iterations.value,\n",
    "                            slider_of_for_std.value,\n",
    "                            slider_of_for_dist.value,\n",
    "                            select_model.value,\n",
    "                            confirm_strategy(),\n",
    "                            t.idx,\n",
    "                            ft.idx)\n",
    "    s.main()\n",
    "\n",
    "\n",
    "def show_input_data(b):\n",
    "    s.show_input_data()\n",
    "\n",
    "\n",
    "def on_strategy_changes(change):\n",
    "    if select_strategy.value == \"MEID (exploit)\":\n",
    "        create_slider_for_dist_quantile()\n",
    "    elif select_strategy.value == \"MLID (explore & exploit)\":\n",
    "        create_slider_for_dist_quantile_std()\n",
    "    elif select_strategy.value == \"MLI (explore & exploit)\":\n",
    "        create_slider_for_std()\n",
    "    else:\n",
    "        strategy_container = HBox([select_strategy])\n",
    "\n",
    "\n",
    "def display_progess_automation(actual_iter, all_comb):\n",
    "    with out_iter_aut:\n",
    "        time.sleep(0.1)\n",
    "        out_iter_aut.clear_output()\n",
    "        display(Markdown('\\n Status  {}/{} \\n'.format(\n",
    "            actual_iter + 1, all_comb)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preview_clicked(b):\n",
    "    try:\n",
    "        preview()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "\n",
    "\n",
    "def upload_clicked(b):\n",
    "    if (up._counter > 1):\n",
    "        up.value.clear()\n",
    "        up._counter = 1\n",
    "    try:\n",
    "        upload()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "\n",
    "\n",
    "def desc_clicked(b):\n",
    "    desc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plotter_clicked(b):\n",
    "    plot()\n",
    "\n",
    "\n",
    "def pairwise_clicked(b):\n",
    "    plot_pairwise()\n",
    "\n",
    "\n",
    "def heat_clicked(b):\n",
    "    plot_heat()\n",
    "\n",
    "\n",
    "def scatter_clicked(b):\n",
    "    plot_scatter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def on_feature_selection_change(change):\n",
    "    confirm_features(feature_selector)\n",
    "\n",
    "\n",
    "def on_target_selection_change(change):\n",
    "    confirm_target(target_selection)\n",
    "\n",
    "\n",
    "def on_app_feature_selection_change(change):\n",
    "    confirm_features(feature_selector_application)\n",
    "\n",
    "\n",
    "def on_app_target_selection_change(change):\n",
    "    confirm_target(target_selection_application)\n",
    "\n",
    "\n",
    "def on_app_fixed_target_selection_change(change):\n",
    "    confirm_fixed_target(fixed_target_selection_application)\n",
    "\n",
    "\n",
    "def on_fixed_target_selection_change(change):\n",
    "    confirm_fixed_target(fixed_target_selection)\n",
    "\n",
    "\n",
    "def on_graph_type_change(change):\n",
    "    if graph_type.value == \"Scatter\":\n",
    "        container_plot_options.children = [HBox([select_x, select_y]),\n",
    "                                           HBox([select_hue, select_size])]\n",
    "    elif graph_type.value == \"Scatter Matrix\":\n",
    "        container_plot_options.children = [HBox([selector_plot_variable, button_confirm_plot_var])]\n",
    "    elif graph_type.value == 'Correlation Heatmap':\n",
    "        container_plot_options.children = [HBox([selector_plot_variable, button_confirm_plot_var])]\n",
    "    else:\n",
    "        container_plot_options.children = []\n",
    "\n",
    "\n",
    "def confirm_var_clicked(b):\n",
    "    confirm_var()\n",
    "\n",
    "\n",
    "def confirm_options_clicked(b):\n",
    "    confirm_options()\n",
    "\n",
    "\n",
    "def on_graph_type_change(change):\n",
    "    if graph_type.value == \"Scatter\":\n",
    "        container_plot_options.children = [HBox([select_x, select_y]),\n",
    "                                           HBox([select_hue, select_size])]\n",
    "    elif graph_type.value == \"Scatter Matrix\":\n",
    "        container_plot_options.children = [HBox([selector_plot_variable, button_confirm_plot_var])]\n",
    "    elif graph_type.value == 'Correlation Heatmap':\n",
    "        container_plot_options.children = [HBox([selector_plot_variable, button_confirm_plot_var])]\n",
    "    else:\n",
    "        container_plot_options.children = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "button_upload.on_click(upload_clicked)\n",
    "toggle.observe(desc_clicked, 'value')\n",
    "button_preview.on_click(preview_clicked)\n",
    "button_confirm_plot_var.on_click(confirm_var_clicked)\n",
    "\n",
    "feature_selector.observe(on_feature_selection_change, names='value')\n",
    "target_selection.observe(on_target_selection_change, names='value')\n",
    "fixed_target_selection.observe(on_fixed_target_selection_change, names='value')\n",
    "\n",
    "target_selection.observe(t.on_selection_change, names='value')\n",
    "fixed_target_selection.observe(ft.on_selection_change, names='value')\n",
    "\n",
    "feature_selector_application.observe(on_app_feature_selection_change, names='value')\n",
    "target_selection_application.observe(on_app_target_selection_change, names='value')\n",
    "fixed_target_selection_application.observe(on_app_fixed_target_selection_change, names='value')\n",
    "\n",
    "target_selection_application.observe(tA.on_selection_change, names='value')\n",
    "fixed_target_selection_application.observe(ftA.on_selection_change, names='value')\n",
    "\n",
    "graph_type.observe(on_graph_type_change, names='value')\n",
    "select_strategy.observe(on_strategy_changes, names=\"value\")\n",
    "\n",
    "button_confirm_options.on_click(confirm_options_clicked)\n",
    "button_perform_experiment.on_click(perform_experiment_clicked)\n",
    "button_plot.on_click(plotter_clicked)\n",
    "button_show_DS.on_click(confirm_target, confirm_fixed_target)\n",
    "button_show_DS.on_click(show_input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tab\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "b2d5c686cdb226ae4298f77b7a7828ac6db4de1dc5fb708d6bf7a47add100857"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}